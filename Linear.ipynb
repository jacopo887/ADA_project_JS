{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5ab3ca",
   "metadata": {},
   "source": [
    "<h1><center> Linear Models </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b39df",
   "metadata": {},
   "source": [
    "<center>As first we will focus on the per race model , while as last we will run the linear part for the unseen circuit</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c9295e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3bba9",
   "metadata": {},
   "source": [
    "<h1><center>Per-Race  </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Filtered_final.xlsx...\n",
      "Loaded dataset shape: (40396, 30)\n",
      "Columns: ['year', 'round', 'name', 'Grand_Prix', 'Name', 'RacingNumber', 'Team', 'lap_number', 'Position', 'is_leader', 'in_drs_range', 'in_clean_air', 'in_dirty_air', 'pushing', 'Compound', 'Stint', 'TyreLife', 'TyreAgeAtStart', 'LapTime_next', 'delta_laptime', 'cumulative_degradation', 'AirTemp', 'Humidity', 'Pressure', 'TrackTemp', 'WindSpeed', 'WindDirection', 'wind_sin', 'wind_cos', 'laptime_rolling_std_3']\n",
      "Overall split (laps):\n",
      "  Train: 28425 (70.4%)\n",
      "  Val:   5388 (13.3%)\n",
      "  Test:  6583 (16.3%)\n",
      "\n",
      "Driver-stint groups total: 2869\n",
      "Groups with n < 10 put fully in train: 1019\n",
      "\n",
      "Any non-contiguous split blocks within a driver-stint group?: False\n",
      "Any non-monotonic time ordering inside a driver-stint group?: False\n",
      "Any boundary violations (train after val/test)?: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the filtered final dataset\n",
    "print(\"Loading Filtered_final.xlsx...\")\n",
    "df_merged = pd.read_excel('csv_output/Filtered_Data/Filtered_final.xlsx')\n",
    "print(f\"Loaded dataset shape: {df_merged.shape}\")\n",
    "print(f\"Columns: {df_merged.columns.tolist()}\")\n",
    "\n",
    "df = df_merged.copy()\n",
    "\n",
    "# Stable identifiers\n",
    "\n",
    "df['race_id'] = (\n",
    "    df['year'].astype(str) + '_' +\n",
    "    df['round'].astype(str) + '_' +\n",
    "    df['Grand_Prix'].astype(str)\n",
    ")\n",
    "\n",
    "group_cols = ['race_id', 'RacingNumber', 'Stint']\n",
    "\n",
    "# Choose the best time column available inside a stint\n",
    "time_col = 'LapInStint' if 'LapInStint' in df.columns else 'lap_number'\n",
    "\n",
    "# Sort so splits are strictly chronological inside each driver-stint\n",
    "df = df.sort_values(group_cols + [time_col]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 2) Time-ordered 70/15/15 split inside each (race, driver, stint)\n",
    "#    - For very short stints, we don't create a test slice\n",
    "\n",
    "MIN_TEST = 3   # minimum laps we want in test if we create a test segment\n",
    "MIN_VAL  = 2   # minimum laps we want in val if we create a val segment\n",
    "MIN_SPLIT_N = 10  # below this, keep in train (or train+val), avoid tiny test\n",
    "\n",
    "def assign_time_split(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    n = len(g)\n",
    "\n",
    "    # Too short -> keep it in train (avoids unstable tiny val/test)\n",
    "    if n < MIN_SPLIT_N:\n",
    "        g['split'] = 'train'\n",
    "        return g\n",
    "\n",
    "    # nominal cut points\n",
    "    i1 = int(np.floor(0.70 * n))\n",
    "    i2 = int(np.floor(0.85 * n))\n",
    "\n",
    "    # enforce minimum sizes\n",
    "    # ensure test has at least MIN_TEST\n",
    "    i2 = min(i2, n - MIN_TEST)\n",
    "    # ensure val has at least MIN_VAL\n",
    "    i1 = min(i1, i2 - MIN_VAL)\n",
    "\n",
    "    # ensure train has at least 1\n",
    "    i1 = max(1, i1)\n",
    "    # ensure val non-empty\n",
    "    i2 = max(i1 + 1, i2)\n",
    "\n",
    "    split = np.array(['train'] * n, dtype=object)\n",
    "    split[i1:i2] = 'val'\n",
    "    split[i2:] = 'test'\n",
    "    g['split'] = split\n",
    "    return g\n",
    "\n",
    "df_with_split = df.groupby(group_cols, group_keys=False).apply(assign_time_split)\n",
    "\n",
    "df_train = df_with_split[df_with_split['split'] == 'train'].drop(columns=['split']).copy()\n",
    "df_val   = df_with_split[df_with_split['split'] == 'val'].drop(columns=['split']).copy()\n",
    "df_test  = df_with_split[df_with_split['split'] == 'test'].drop(columns=['split']).copy()\n",
    "\n",
    "\n",
    "# Reporting\n",
    "\n",
    "total = len(df_with_split)\n",
    "print(\"Overall split (laps):\")\n",
    "print(f\"  Train: {len(df_train)} ({len(df_train)/total*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(df_val)} ({len(df_val)/total*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(df_test)} ({len(df_test)/total*100:.1f}%)\")\n",
    "\n",
    "# How many groups were too short and went fully to train?\n",
    "group_sizes = df_with_split.groupby(group_cols).size()\n",
    "print(f\"\\nDriver-stint groups total: {len(group_sizes)}\")\n",
    "print(f\"Groups with n < {MIN_SPLIT_N} put fully in train: {(group_sizes < MIN_SPLIT_N).sum()}\")\n",
    "\n",
    "\n",
    "# HARD sanity checks (these catch subtle bugs)\n",
    "\n",
    "\n",
    "# A) Contiguity check: splits must be contiguous blocks (train -> val -> test)\n",
    "def is_noncontiguous(s):\n",
    "    # if labels change more times than the number of unique labels, it's non-contiguous\n",
    "    changes = (s != s.shift()).sum()\n",
    "    return changes > s.nunique()\n",
    "\n",
    "bad_contig = (df_with_split.groupby(group_cols)['split'].apply(is_noncontiguous))\n",
    "print(\"\\nAny non-contiguous split blocks within a driver-stint group?:\", bad_contig.any())\n",
    "\n",
    "# B) Time monotonicity check inside each group\n",
    "bad_time = (df_with_split.groupby(group_cols)[time_col].apply(lambda s: not s.is_monotonic_increasing))\n",
    "print(\"Any non-monotonic time ordering inside a driver-stint group?:\", bad_time.any())\n",
    "\n",
    "# C) “Future in train” check: max train time should be <= min val time, etc.\n",
    "def boundary_ok(g):\n",
    "    t = g.loc[g['split']=='train', time_col]\n",
    "    v = g.loc[g['split']=='val', time_col]\n",
    "    te = g.loc[g['split']=='test', time_col]\n",
    "    ok = True\n",
    "    if len(v) > 0 and len(t) > 0:\n",
    "        ok &= (t.max() <= v.min())\n",
    "    if len(te) > 0 and len(v) > 0:\n",
    "        ok &= (v.max() <= te.min())\n",
    "    if len(te) > 0 and len(t) > 0 and len(v) == 0:\n",
    "        ok &= (t.max() <= te.min())\n",
    "    return ok\n",
    "\n",
    "bad_boundary = ~(df_with_split.groupby(group_cols).apply(boundary_ok))\n",
    "print(\"Any boundary violations (train after val/test)?:\", bad_boundary.any())\n",
    "\n",
    "\n",
    "# Save\n",
    "\n",
    "df_train.to_excel('csv_output/Train_set_per_race.xlsx', index=False)\n",
    "df_val.to_excel('csv_output/Validation_set_per_race.xlsx', index=False)\n",
    "df_test.to_excel('csv_output/Test_set_per_race.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c176703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating synthetic features...\n",
      "   is_new_tyre created (1=fresh, 0=used)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nCreating synthetic features...\")\n",
    "for df_split in [df_train, df_val, df_test]:\n",
    "    df_split['is_new_tyre'] = (df_split['TyreAgeAtStart'] == 0).astype(int)\n",
    "print(f\"   is_new_tyre created (1=fresh, 0=used)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1dec69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "RACE-SPECIFIC MODELS: LINEAR BASELINES + OPTIMIZED RIDGE (Full Model Only)\n",
      "Step 1: Train LINEAR models on ALL feature sets\n",
      "Step 2: Optimize RIDGE alphas on FULL model only using VAL\n",
      "Step 3: Report best result\n",
      "====================================================================================================\n",
      "\n",
      "Phase 1: Training LINEAR baselines...\n",
      "\n",
      "[Tyre+Stint] ✓ 64 races | Test MAE: 0.6506s\n",
      "[Tyre+Stint+Weather] ✓ 64 races | Test MAE: 0.7012s\n",
      "[Full (No Driver/Team)] ✓ 64 races | Test MAE: 0.6102s\n",
      "[Full (Driver+Team+Compound)] ✓ 64 races | Test MAE: 0.4281s\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Phase 2: Optimizing RIDGE alphas on Full (No Driver/Team) model only...\n",
      "\n",
      "[Ridge α=0.01] ✓ 64 races | Val MAE: 0.3316s\n",
      "[Ridge α=0.1] ✓ 64 races | Val MAE: 0.3305s\n",
      "[Ridge α=0.5] ✓ 64 races | Val MAE: 0.3281s\n",
      "[Ridge α=1.0] ✓ 64 races | Val MAE: 0.3272s\n",
      "[Ridge α=2.0] ✓ 64 races | Val MAE: 0.3272s\n",
      "[Ridge α=5.0] ✓ 64 races | Val MAE: 0.3314s\n",
      "[Ridge α=10.0] ✓ 64 races | Val MAE: 0.3402s\n",
      "\n",
      "✓ Best α on VAL: 1.0 (MAE: 0.3272s)\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Phase 3: Testing best Ridge model...\n",
      "\n",
      "\n",
      "Full (Driver+Team+Compound) + Ridge (α=1.0)\n",
      "  [Val]  MAE: 0.3272s\n",
      "  [Test] MAE: 0.4199s, RMSE: 0.5768s, R²: 0.9966\n",
      "\n",
      "====================================================================================================\n",
      "FINAL RESULTS (TEST SET)\n",
      "====================================================================================================\n",
      "\n",
      "                                      model      MAE     RMSE       R2  n_samples test_race_coverage\n",
      "Full (Driver+Team+Compound) + Ridge (α=1.0) 0.419855 0.576785 0.996640       6583              63/63\n",
      "       Full (Driver+Team+Compound) + Linear 0.428064 0.584187 0.996553       6583              63/63\n",
      "             Full (No Driver/Team) + Linear 0.610238 0.814593 0.993298       6583              63/63\n",
      "                        Tyre+Stint + Linear 0.650637 0.841281 0.992852       6583              63/63\n",
      "                Tyre+Stint+Weather + Linear 0.701230 0.925418 0.991350       6583              63/63\n",
      "\n",
      "✓ BEST MODEL: Full (Driver+Team+Compound) + Ridge (α=1.0)\n",
      "  Test MAE: 0.4199s\n",
      "  Test RMSE: 0.5768s\n",
      "  Test R²: 0.9966\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CONFIG & FEATURE SETS\n",
    "\n",
    "TARGET = \"LapTime_next\"\n",
    "\n",
    "NUM_FEATS_FULL = [\n",
    "    \"lap_number\",\n",
    "    \"TyreLife\",\n",
    "    \"TyreAgeAtStart\",\n",
    "    \"is_leader\",\n",
    "    \"in_drs_range\",\n",
    "    \"in_clean_air\",\n",
    "    \"in_dirty_air\",\n",
    "    \"pushing\",\n",
    "    \"AirTemp\",\n",
    "    \"Humidity\",\n",
    "    \"Pressure\",\n",
    "    \"TrackTemp\",\n",
    "    \"WindSpeed\",\n",
    "    \"wind_sin\",\n",
    "    \"wind_cos\",\n",
    "    \"delta_laptime\",\n",
    "    \"cumulative_degradation\",\n",
    "    \"laptime_rolling_std_3\"\n",
    "]\n",
    "\n",
    "CAT_FEATS_FULL = [\"RacingNumber\", \"Team\", \"Compound\"]\n",
    "\n",
    "# Define feature sets for comparison\n",
    "FEATURE_SETS = {\n",
    "    \"Tyre+Stint\": {\n",
    "        \"num\": [\n",
    "            \"lap_number\",\n",
    "            \"TyreLife\",\n",
    "            \"TyreAgeAtStart\"\n",
    "        ],\n",
    "        \"cat\": [\"Compound\"]\n",
    "    },\n",
    "    \n",
    "    \"Tyre+Stint+Weather\": {\n",
    "        \"num\": [\n",
    "            \"lap_number\",\n",
    "            \"TyreLife\",\n",
    "            \"TyreAgeAtStart\",\n",
    "            \"AirTemp\",\n",
    "            \"Humidity\",\n",
    "            \"Pressure\",\n",
    "            \"TrackTemp\",\n",
    "            \"WindSpeed\",\n",
    "            \"wind_sin\",\n",
    "            \"wind_cos\"\n",
    "        ],\n",
    "        \"cat\": [\"Compound\"]\n",
    "    },\n",
    "    \n",
    "    \"Full (No Driver/Team)\": {\n",
    "        \"num\": NUM_FEATS_FULL,\n",
    "        \"cat\": [\"Compound\"]  # Only tyre compound, NO driver/team\n",
    "    },\n",
    "    \n",
    "    \"Full (Driver+Team+Compound)\": {\n",
    "        \"num\": NUM_FEATS_FULL,\n",
    "        \"cat\": CAT_FEATS_FULL  # Includes RacingNumber, Team, Compound\n",
    "    }\n",
    "}\n",
    "\n",
    "# Validation - only require WindDirection if needed\n",
    "for name, cfg in FEATURE_SETS.items():\n",
    "    all_cols = cfg[\"num\"] + cfg[\"cat\"] + [\"year\", \"round\", TARGET]\n",
    "    # Only require WindDirection if wind features are used\n",
    "    if (\"wind_sin\" in cfg[\"num\"]) or (\"wind_cos\" in cfg[\"num\"]):\n",
    "        all_cols += [\"WindDirection\"]\n",
    "    for c in all_cols:\n",
    "        if c not in df_train.columns:\n",
    "            raise ValueError(f\"Missing column in df_train: {c} (needed for {name})\")\n",
    "\n",
    "\n",
    "# FEATURE PREP\n",
    "\n",
    "def add_wind_trig(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    theta = np.deg2rad(d[\"WindDirection\"].astype(float))\n",
    "    d[\"wind_sin\"] = np.sin(theta)\n",
    "    d[\"wind_cos\"] = np.cos(theta)\n",
    "    return d\n",
    "\n",
    "def make_Xy(df: pd.DataFrame, num_feats, cat_feats, fit_cols=None, medians=None):\n",
    "    \"\"\"Make X, y matrices with dynamic feature selection.\"\"\"\n",
    "    # Only compute wind trig if wind features are used\n",
    "    need_wind = (\"wind_sin\" in num_feats) or (\"wind_cos\" in num_feats)\n",
    "    d = add_wind_trig(df) if need_wind else df.copy()\n",
    "\n",
    "    # keep only needed columns\n",
    "    X_raw = d[num_feats + cat_feats].copy()\n",
    "    y = d[TARGET].astype(float).copy()\n",
    "\n",
    "    # one-hot categorical\n",
    "    X = pd.get_dummies(X_raw, columns=cat_feats, drop_first=True)\n",
    "\n",
    "    # align columns to training set if provided\n",
    "    if fit_cols is not None:\n",
    "        X = X.reindex(columns=fit_cols, fill_value=0)\n",
    "\n",
    "    # impute using provided medians if available, otherwise compute from X (train only)\n",
    "    if medians is None:\n",
    "        medians = X.median(numeric_only=True)\n",
    "    X = X.fillna(medians)\n",
    "\n",
    "    # drop NaN target rows\n",
    "    m = y.notna()\n",
    "    return X.loc[m], y.loc[m], medians\n",
    "\n",
    "\n",
    "# TRAIN ONE MODEL PER RACE FOR A GIVEN FEATURE SET\n",
    "\n",
    "def train_race_models(df_train, num_feats, cat_feats, model_type=\"linear\", alpha=1.0, min_samples=None):\n",
    "    \"\"\"\n",
    "    Train race-specific models for given features.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "    df_train : pd.DataFrame\n",
    "        Training data\n",
    "    num_feats : list\n",
    "        Numerical features\n",
    "    cat_feats : list\n",
    "        Categorical features\n",
    "    model_type : str\n",
    "        \"linear\" for LinearRegression or \"ridge\" for Ridge\n",
    "    alpha : float\n",
    "        Regularization strength (only for Ridge)\n",
    "    min_samples : int\n",
    "        Minimum samples to train a race model. If None, use 100 or 5x num features.\n",
    "    \"\"\"\n",
    "    # Auto-calculate min_samples if not provided\n",
    "    if min_samples is None:\n",
    "        n_features = len(num_feats) + len(cat_feats)\n",
    "        min_samples = max(100, 5 * n_features)\n",
    "    \n",
    "    models = {}\n",
    "\n",
    "    for (y_, r_), d_race in df_train.groupby([\"year\", \"round\"]):\n",
    "        if len(d_race) < min_samples:\n",
    "            continue\n",
    "\n",
    "        Xtr, ytr, med = make_Xy(d_race, num_feats, cat_feats)\n",
    "        if len(Xtr) < min_samples:\n",
    "            continue\n",
    "\n",
    "        # Choose model type\n",
    "        if model_type == \"ridge\":\n",
    "            model = Ridge(alpha=alpha)\n",
    "        else:\n",
    "            model = LinearRegression()\n",
    "        \n",
    "        model.fit(Xtr, ytr)\n",
    "\n",
    "        models[(int(y_), int(r_))] = {\n",
    "            \"model\": model,\n",
    "            \"cols\": Xtr.columns,\n",
    "            \"med\": med,\n",
    "        }\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "# PREDICT & EVALUATE\n",
    "\n",
    "def eval_feature_set(df_test, models, num_feats, cat_feats, name=\"model\"):\n",
    "    \"\"\"Evaluate a feature set on test data, with coverage reporting.\"\"\"\n",
    "    preds, trues = [], []\n",
    "    covered_races = 0\n",
    "    total_races = df_test.groupby([\"year\", \"round\"]).ngroups\n",
    "\n",
    "    for (y_, r_), d_race in df_test.groupby([\"year\", \"round\"]):\n",
    "        key = (int(y_), int(r_))\n",
    "        if key not in models:\n",
    "            continue\n",
    "\n",
    "        covered_races += 1\n",
    "        fit = models[key]\n",
    "        X, y, _ = make_Xy(d_race, num_feats, cat_feats,\n",
    "                          fit_cols=fit[\"cols\"], medians=fit[\"med\"])\n",
    "        yhat = fit[\"model\"].predict(X)\n",
    "\n",
    "        preds.append(yhat)\n",
    "        trues.append(y.values)\n",
    "\n",
    "    if not preds:\n",
    "            return None\n",
    "        \n",
    "    yhat = np.concatenate(preds)\n",
    "    ytrue = np.concatenate(trues)\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"MAE\": mean_absolute_error(ytrue, yhat),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(ytrue, yhat)),\n",
    "        \"R2\": r2_score(ytrue, yhat),\n",
    "        \"n_samples\": len(yhat),\n",
    "        \"n_races_trained\": len(models),\n",
    "        \"n_races_covered\": covered_races,\n",
    "        \"test_race_coverage\": f\"{covered_races}/{total_races}\"\n",
    "    }\n",
    "\n",
    "\n",
    "# RUN COMPARISON: LINEAR BASELINES + RIDGE ON FULL MODEL ONLY\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"RACE-SPECIFIC MODELS: LINEAR BASELINES + OPTIMIZED RIDGE (Full Model Only)\")\n",
    "print(\"Step 1: Train LINEAR models on ALL feature sets\")\n",
    "print(\"Step 2: Optimize RIDGE alphas on FULL model only using VAL\")\n",
    "print(\"Step 3: Report best result\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "all_models_all = {}  # Store all trained models\n",
    "test_results = []\n",
    "\n",
    "# PHASE 1: Train LINEAR models on all feature sets\n",
    "\n",
    "print(\"\\nPhase 1: Training LINEAR baselines...\\n\")\n",
    "\n",
    "for feature_name, cfg in FEATURE_SETS.items():\n",
    "    print(f\"[{feature_name}]\", end=\" \")\n",
    "    \n",
    "    # Train linear\n",
    "    models = train_race_models(df_train, cfg[\"num\"], cfg[\"cat\"], \n",
    "                               model_type=\"linear\", alpha=None)\n",
    "    \n",
    "    model_key = f\"{feature_name} + Linear\"\n",
    "    all_models_all[model_key] = models\n",
    "    \n",
    "    print(f\"✓ {len(models)} races\", end=\"\")\n",
    "    \n",
    "    # Eval on test\n",
    "    test_res = eval_feature_set(df_test, models, cfg[\"num\"], cfg[\"cat\"], model_key)\n",
    "    if test_res:\n",
    "        print(f\" | Test MAE: {test_res['MAE']:.4f}s\")\n",
    "        test_results.append(test_res)\n",
    "\n",
    "\n",
    "# PHASE 2: Optimize Ridge ONLY on Full (Driver/Team model\n",
    "\n",
    "print(f\"\\n{'─'*100}\")\n",
    "print(\"Phase 2: Optimizing RIDGE alphas on Full (No Driver/Team) model only...\\n\")\n",
    "\n",
    "full_cfg = FEATURE_SETS[\"Full (Driver+Team+Compound)\"]\n",
    "ridge_alphas = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "val_results_ridge = {}\n",
    "\n",
    "for alpha in ridge_alphas:\n",
    "    print(f\"[Ridge α={alpha}]\", end=\" \")\n",
    "    \n",
    "    # Train ridge\n",
    "    models = train_race_models(df_train, full_cfg[\"num\"], full_cfg[\"cat\"], \n",
    "                               model_type=\"ridge\", alpha=alpha)\n",
    "    \n",
    "    model_key = f\"Full (Driver+Team+Compound) + Ridge (α={alpha})\"\n",
    "    all_models_all[model_key] = models\n",
    "    \n",
    "    print(f\"✓ {len(models)} races\", end=\"\")\n",
    "    \n",
    "    # Eval on val\n",
    "    val_res = eval_feature_set(df_val, models, full_cfg[\"num\"], full_cfg[\"cat\"], model_key)\n",
    "    if val_res:\n",
    "        val_mae = val_res['MAE']\n",
    "        val_results_ridge[alpha] = val_mae\n",
    "        print(f\" | Val MAE: {val_mae:.4f}s\")\n",
    "\n",
    "# Select best alpha\n",
    "best_alpha = min(val_results_ridge, key=val_results_ridge.get)\n",
    "best_val_mae = val_results_ridge[best_alpha]\n",
    "\n",
    "print(f\"\\n✓ Best α on VAL: {best_alpha} (MAE: {best_val_mae:.4f}s)\")\n",
    "\n",
    "# Train best ridge model and evaluate on test\n",
    "print(f\"\\n{'─'*100}\")\n",
    "print(f\"Phase 3: Testing best Ridge model...\\n\")\n",
    "\n",
    "best_models = train_race_models(df_train, full_cfg[\"num\"], full_cfg[\"cat\"], \n",
    "                                model_type=\"ridge\", alpha=best_alpha)\n",
    "\n",
    "best_model_key = f\"Full (Driver+Team+Compound) + Ridge (α={best_alpha})\"\n",
    "test_res_best = eval_feature_set(df_test, best_models, full_cfg[\"num\"], full_cfg[\"cat\"], best_model_key)\n",
    "\n",
    "if test_res_best:\n",
    "    print(f\"\\n{best_model_key}\")\n",
    "    print(f\"  [Val]  MAE: {best_val_mae:.4f}s\")\n",
    "    print(f\"  [Test] MAE: {test_res_best['MAE']:.4f}s, RMSE: {test_res_best['RMSE']:.4f}s, R²: {test_res_best['R2']:.4f}\")\n",
    "    test_results.append(test_res_best)\n",
    "\n",
    "\n",
    "# SUMMARY\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL RESULTS (TEST SET)\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "if test_results:\n",
    "    results_df = pd.DataFrame(test_results).sort_values(\"MAE\")\n",
    "    print(results_df[[\"model\", \"MAE\", \"RMSE\", \"R2\", \"n_samples\", \"test_race_coverage\"]].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n✓ BEST MODEL: {results_df.iloc[0]['model']}\")\n",
    "    print(f\"  Test MAE: {results_df.iloc[0]['MAE']:.4f}s\")\n",
    "    print(f\"  Test RMSE: {results_df.iloc[0]['RMSE']:.4f}s\")\n",
    "    print(f\"  Test R²: {results_df.iloc[0]['R2']:.4f}\")\n",
    "\n",
    "# Store best model info for feature importance analysis\n",
    "best_model_key_final = best_model_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e1fab",
   "metadata": {},
   "source": [
    "<h1><center> Per-Circuit</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461145b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "LOADING DATA FOR PER-CIRCUIT MODELS\n",
      "====================================================================================================\n",
      "\n",
      "Loading Filtered_04_with_circuit_geometry.xlsx...\n",
      "Loaded dataset shape: (40396, 43)\n",
      "Columns: ['year', 'round', 'name', 'Grand_Prix', 'type', 'Name', 'RacingNumber', 'Team', 'lap_number', 'Position', 'is_leader', 'in_drs_range', 'in_clean_air', 'in_dirty_air', 'pushing', 'Compound', 'Stint', 'TyreLife', 'TyreAgeAtStart', 'LapTime_next_vs_stint_baseline', 'delta_laptime', 'cumulative_degradation', 'LapTime', 'AirTemp', 'Humidity', 'Pressure', 'TrackTemp', 'WindSpeed', 'wind_sin', 'wind_cos', 'laptime_rolling_std_3', 'num_drs_zones', 'num_turns', 'slow_share', 'slow_cluster_max', 'straight_ratio', 'straight_len_max_m', 'n_major_straights', 'heavy_braking_zones', 'heavy_braking_mean_dv_kmh', 'hb_at_end_of_max', 'avg_corner_angle', 'drs_total_len_m']\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# SECTION 2: PER-CIRCUIT MODELS (with circuit geometry)\n",
    "###########################################################\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"LOADING DATA FOR PER-CIRCUIT MODELS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Load the filtered dataset WITH circuit geometry\n",
    "print(\"\\nLoading Filtered_04_with_circuit_geometry.xlsx...\")\n",
    "df_merged = pd.read_excel('csv_output/Filtered_Data/Filtered_04_with_circuit_geometry.xlsx')\n",
    "print(f\"Loaded dataset shape: {df_merged.shape}\")\n",
    "print(f\"Columns: {df_merged.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1ab86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ No circuit overlap across splits\n",
      "\n",
      "Split sizes (rows):\n",
      "  Train: 26,221 (64.9%) | Circuits: 15\n",
      "  Val:   7,199 (17.8%) | Circuits: 4\n",
      "  Test:  6,976 (17.3%) | Circuits: 5\n",
      "\n",
      "✓ Saved Train_set.xlsx, Validation_set.xlsx, Test_set.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df_merged.copy()\n",
    "\n",
    "# IDs\n",
    "\n",
    "df[\"circuit_id\"] = df[\"name\"].astype(str)\n",
    "\n",
    "# (Optional) stable race id if you want reporting later\n",
    "df[\"race_id\"] = (\n",
    "    df[\"year\"].astype(str) + \"_\" +\n",
    "    df[\"round\"].astype(str) + \"_\" +\n",
    "    df[\"Grand_Prix\"].astype(str)\n",
    ")\n",
    "\n",
    "\n",
    "# circuit-disjoint split (row-balanced)\n",
    "#    - No circuit appears in more than one split\n",
    "#    - Roughly 70/15/15 by number of rows (laps)\n",
    "\n",
    "counts = df.groupby(\"circuit_id\").size().sort_values(ascending=False)\n",
    "total = counts.sum()\n",
    "\n",
    "targets = {\"train\": 0.7 * total, \"val\": 0.15 * total, \"test\": 0.15 * total}\n",
    "bins = {\"train\": set(), \"val\": set(), \"test\": set()}\n",
    "bin_counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "circuits = counts.index.to_list()\n",
    "rng.shuffle(circuits)\n",
    "\n",
    "for circuit in circuits:\n",
    "    c = counts.loc[circuit]\n",
    "    best_bin = min(bins.keys(), key=lambda k: bin_counts[k] / targets[k])\n",
    "    bins[best_bin].add(circuit)\n",
    "    bin_counts[best_bin] += c\n",
    "\n",
    "df_train = df[df[\"circuit_id\"].isin(bins[\"train\"])].copy()\n",
    "df_val   = df[df[\"circuit_id\"].isin(bins[\"val\"])].copy()\n",
    "df_test  = df[df[\"circuit_id\"].isin(bins[\"test\"])].copy()\n",
    "\n",
    "\n",
    "# sanity checks\n",
    "\n",
    "train_c = set(df_train[\"circuit_id\"].unique())\n",
    "val_c   = set(df_val[\"circuit_id\"].unique())\n",
    "test_c  = set(df_test[\"circuit_id\"].unique())\n",
    "\n",
    "assert train_c.isdisjoint(val_c),  \" Train-Val circuit overlap!\"\n",
    "assert train_c.isdisjoint(test_c), \" Train-Test circuit overlap!\"\n",
    "assert val_c.isdisjoint(test_c),   \" Val-Test circuit overlap!\"\n",
    "print(\"✓ No circuit overlap across splits\")\n",
    "\n",
    "print(\"\\nSplit sizes (rows):\")\n",
    "print(f\"  Train: {len(df_train):,} ({len(df_train)/len(df)*100:.1f}%) | Circuits: {len(train_c)}\")\n",
    "print(f\"  Val:   {len(df_val):,} ({len(df_val)/len(df)*100:.1f}%) | Circuits: {len(val_c)}\")\n",
    "print(f\"  Test:  {len(df_test):,} ({len(df_test)/len(df)*100:.1f}%) | Circuits: {len(test_c)}\")\n",
    "\n",
    "\n",
    "#  Save\n",
    "\n",
    "# Keep circuit_id column if you want debugging; otherwise drop it before saving:\n",
    "df_train.drop(columns=[\"circuit_id\"], inplace=True)\n",
    "df_val.drop(columns=[\"circuit_id\"], inplace=True)\n",
    "df_test.drop(columns=[\"circuit_id\"], inplace=True)\n",
    "\n",
    "df_train.to_excel(\"csv_output/Train_set.xlsx\", index=False)\n",
    "df_val.to_excel(\"csv_output/Validation_set.xlsx\", index=False)\n",
    "df_test.to_excel(\"csv_output/Test_set.xlsx\", index=False)\n",
    "\n",
    "print(\"\\n✓ Saved Train_set.xlsx, Validation_set.xlsx, Test_set.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac551f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating synthetic features...\n",
      "   is_new_tyre created (1=fresh, 0=used)\n",
      "====================================================================================================\n",
      "CIRCUIT-BASED MODEL: nested blocks + raw geometry + GridSearchCV for optimal regularization\n",
      "====================================================================================================\n",
      "1) Tyre (Linear)                              | Test MAE 0.4533 | Test R² -0.1576 | p=48\n",
      "2) Tyre+Weather (Linear)                      | Test MAE 0.4681 | Test R² -0.2075 | p=54\n",
      "3) Tyre+Weather+State (Linear)                | Test MAE 0.3651 | Test R² 0.2386 | p=63\n",
      "4) Tyre+Weather+State+Geometry (Linear)       | Test MAE 0.6581 | Test R² -0.8873 | p=74\n",
      "\n",
      "====================================================================================================\n",
      "Gridsearch CV: Finding optimal Ridge α for Tyre+Weather+State+Geometry\n",
      "====================================================================================================\n",
      "\n",
      "Testing alphas: [0.1, 1.0, 10.0, 50.0, 100.0, 500.0, 1000.0, 5000.0]\n",
      "Train set: 26221 samples, 74 features\n",
      "Val set:   7199 samples\n",
      "  α=    0.1: Val MAE=0.7709, Val RMSE=0.9091, Val R²=-2.0079\n",
      "  α=    1.0: Val MAE=0.6047, Val RMSE=0.7266, Val R²=-0.9212\n",
      "  α=   10.0: Val MAE=0.4649, Val RMSE=0.5830, Val R²=-0.2371\n",
      "  α=   50.0: Val MAE=0.4549, Val RMSE=0.5741, Val R²=-0.1995\n",
      "  α=  100.0: Val MAE=0.4568, Val RMSE=0.5762, Val R²=-0.2082\n",
      "  α=  500.0: Val MAE=0.4654, Val RMSE=0.5844, Val R²=-0.2429\n",
      "  α= 1000.0: Val MAE=0.4670, Val RMSE=0.5852, Val R²=-0.2462\n",
      "  α= 5000.0: Val MAE=0.4522, Val RMSE=0.5691, Val R²=-0.1787\n",
      "\n",
      "✓ Best Alpha: 5000.0 (Val MAE: 0.4522)\n",
      "\n",
      "Training final Ridge model with α=5000.0 on full training data...\n",
      "  Test MAE:  0.4035\n",
      "  Test RMSE: 0.5497\n",
      "  Test R²:   0.1526\n",
      "\n",
      "====================================================================================================\n",
      "Gridsearch CV: Finding optimal Ridge α for Tyre+Weather+State\n",
      "====================================================================================================\n",
      "\n",
      "Testing alphas: [0.1, 1.0, 10.0, 50.0, 100.0, 500.0, 1000.0, 5000.0]\n",
      "Train set: 26221 samples, 63 features\n",
      "Val set:   7199 samples\n",
      "  α=    0.1: Val MAE=0.3435, Val RMSE=0.4752, Val R²=0.1781\n",
      "  α=    1.0: Val MAE=0.3435, Val RMSE=0.4752, Val R²=0.1782\n",
      "  α=   10.0: Val MAE=0.3433, Val RMSE=0.4751, Val R²=0.1784\n",
      "  α=   50.0: Val MAE=0.3429, Val RMSE=0.4748, Val R²=0.1795\n",
      "  α=  100.0: Val MAE=0.3425, Val RMSE=0.4745, Val R²=0.1807\n",
      "  α=  500.0: Val MAE=0.3408, Val RMSE=0.4725, Val R²=0.1875\n",
      "  α= 1000.0: Val MAE=0.3397, Val RMSE=0.4710, Val R²=0.1925\n",
      "  α= 5000.0: Val MAE=0.3378, Val RMSE=0.4679, Val R²=0.2033\n",
      "\n",
      "✓ Best Alpha: 5000.0 (Val MAE: 0.3378)\n",
      "\n",
      "Training final Ridge model with α=5000.0 on full training data...\n",
      "  Test MAE:  0.3753\n",
      "  Test RMSE: 0.5266\n",
      "  Test R²:   0.2224\n",
      "\n",
      "====================================================================================================\n",
      "Gridsearch: Elastic Net (alpha, l1_ratio) on Tyre+Weather+State+Geometry\n",
      "====================================================================================================\n",
      "\n",
      "Testing ElasticNet with 7 l1_ratios × 10 alphas = 70 combinations\n",
      "  l1_ratio=0.01 | alpha=  0.001 | Val MAE=0.7013 | Val R²=-1.5085\n",
      "  l1_ratio=0.01 | alpha=   0.01 | Val MAE=0.4794 | Val R²=-0.2924\n",
      "  l1_ratio=0.01 | alpha=    0.1 | Val MAE=0.3668 | Val R²=0.1180\n",
      "  l1_ratio=0.01 | alpha=      1 | Val MAE=0.3437 | Val R²=0.1688\n",
      "  l1_ratio=0.01 | alpha=      5 | Val MAE=0.3614 | Val R²=0.0709\n",
      "  l1_ratio=0.01 | alpha=     10 | Val MAE=0.3700 | Val R²=0.0280\n",
      "  l1_ratio=0.01 | alpha=     50 | Val MAE=0.3757 | Val R²=-0.0028\n",
      "  l1_ratio=0.01 | alpha=    100 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.01 | alpha=    500 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.01 | alpha=  1e+03 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.05 | alpha=  0.001 | Val MAE=0.6885 | Val R²=-1.4228\n",
      "  l1_ratio=0.05 | alpha=   0.01 | Val MAE=0.4483 | Val R²=-0.1657\n",
      "  l1_ratio=0.05 | alpha=    0.1 | Val MAE=0.3548 | Val R²=0.1567\n",
      "  l1_ratio=0.05 | alpha=      1 | Val MAE=0.3457 | Val R²=0.1588\n",
      "  l1_ratio=0.05 | alpha=      5 | Val MAE=0.3719 | Val R²=0.0187\n",
      "  l1_ratio=0.05 | alpha=     10 | Val MAE=0.3757 | Val R²=-0.0024\n",
      "  l1_ratio=0.05 | alpha=     50 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.05 | alpha=    100 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.05 | alpha=    500 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.05 | alpha=  1e+03 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.10 | alpha=  0.001 | Val MAE=0.6716 | Val R²=-1.3128\n",
      "  l1_ratio=0.10 | alpha=   0.01 | Val MAE=0.4203 | Val R²=-0.0612\n",
      "  l1_ratio=0.10 | alpha=    0.1 | Val MAE=0.3478 | Val R²=0.1782\n",
      "  l1_ratio=0.10 | alpha=      1 | Val MAE=0.3522 | Val R²=0.1232\n",
      "  l1_ratio=0.10 | alpha=      5 | Val MAE=0.3756 | Val R²=-0.0019\n",
      "  l1_ratio=0.10 | alpha=     10 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.10 | alpha=     50 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.10 | alpha=    100 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.10 | alpha=    500 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.10 | alpha=  1e+03 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.20 | alpha=  0.001 | Val MAE=0.6400 | Val R²=-1.1163\n",
      "  l1_ratio=0.20 | alpha=   0.01 | Val MAE=0.3982 | Val R²=0.0182\n",
      "  l1_ratio=0.20 | alpha=    0.1 | Val MAE=0.3409 | Val R²=0.1976\n",
      "  l1_ratio=0.20 | alpha=      1 | Val MAE=0.3618 | Val R²=0.0755\n",
      "  l1_ratio=0.20 | alpha=      5 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.20 | alpha=     10 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.20 | alpha=     50 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.20 | alpha=    100 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.20 | alpha=    500 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.20 | alpha=  1e+03 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.50 | alpha=  0.001 | Val MAE=0.5386 | Val R²=-0.5640\n",
      "  l1_ratio=0.50 | alpha=   0.01 | Val MAE=0.3775 | Val R²=0.0907\n",
      "  l1_ratio=0.50 | alpha=    0.1 | Val MAE=0.3392 | Val R²=0.2017\n",
      "  l1_ratio=0.50 | alpha=      1 | Val MAE=0.3751 | Val R²=0.0010\n",
      "  l1_ratio=0.50 | alpha=      5 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.50 | alpha=     10 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.50 | alpha=     50 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.50 | alpha=    100 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.50 | alpha=    500 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.50 | alpha=  1e+03 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.80 | alpha=  0.001 | Val MAE=0.4955 | Val R²=-0.3640\n",
      "  l1_ratio=0.80 | alpha=   0.01 | Val MAE=0.3674 | Val R²=0.1246\n",
      "  l1_ratio=0.80 | alpha=    0.1 | Val MAE=0.3390 | Val R²=0.1933\n",
      "  l1_ratio=0.80 | alpha=      1 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.80 | alpha=      5 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.80 | alpha=     10 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.80 | alpha=     50 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.80 | alpha=    100 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.80 | alpha=    500 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=0.80 | alpha=  1e+03 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=1.00 | alpha=  0.001 | Val MAE=0.4622 | Val R²=-0.2233\n",
      "  l1_ratio=1.00 | alpha=   0.01 | Val MAE=0.3621 | Val R²=0.1414\n",
      "  l1_ratio=1.00 | alpha=    0.1 | Val MAE=0.3414 | Val R²=0.1822\n",
      "  l1_ratio=1.00 | alpha=      1 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=1.00 | alpha=      5 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=1.00 | alpha=     10 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=1.00 | alpha=     50 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=1.00 | alpha=    100 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=1.00 | alpha=    500 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "  l1_ratio=1.00 | alpha=  1e+03 | Val MAE=0.3758 | Val R²=-0.0029\n",
      "\n",
      "✓ Best ElasticNet: alpha=0.1 | l1_ratio=0.8 | Val MAE=0.3390\n",
      "\n",
      "ElasticNet TEST:\n",
      "  Test MAE:  0.3747\n",
      "  Test RMSE: 0.5285\n",
      "  Test R²:   0.2167\n",
      "  Non-zero coefficients: 4/74\n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY (sorted by Test MAE)\n",
      "====================================================================================================\n",
      "                                                    model  p  val_MAE    val_R2  test_MAE  test_RMSE   test_R2  n_test\n",
      "                           3) Tyre+Weather+State (Linear) 63 0.343513  0.178113  0.365140   0.521038  0.238601    6976\n",
      "6) Tyre+Weather+State+Geometry (ElasticNet a=0.1, l1=0.8) 74 0.339030  0.193273  0.374690   0.528473  0.216715    6976\n",
      "                 5a) Tyre+Weather+State (Ridge α=5000.0✓) 63 0.337819  0.203289  0.375286   0.526561  0.222371    6976\n",
      "         5) Tyre+Weather+State+Geometry (Ridge α=5000.0✓) 74 0.452161 -0.178652  0.403456   0.549675  0.152604    6976\n",
      "                                         1) Tyre (Linear) 48 0.382226 -0.025840  0.453304   0.642453 -0.157597    6976\n",
      "                                 2) Tyre+Weather (Linear) 54 0.392290 -0.037151  0.468084   0.656166 -0.207540    6976\n",
      "                  4) Tyre+Weather+State+Geometry (Linear) 74 0.808595 -2.294882  0.658102   0.820318 -0.887288    6976\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create synthetic tyre feature \n",
    "\n",
    "print(f\"\\nCreating synthetic features...\")\n",
    "for df_split in [df_train, df_val, df_test]:\n",
    "    df_split['is_new_tyre'] = (df_split['TyreAgeAtStart'] == 0).astype(int)\n",
    "print(f\"   is_new_tyre created (1=fresh, 0=used)\")\n",
    "\n",
    "\n",
    "# Define geometry columns (if not already defined from PCA section)\n",
    "if \"geom_cols\" not in globals():\n",
    "    geom_cols_all = [\n",
    "        'num_drs_zones', 'length_m', 'num_turns',\n",
    "        'slow_share', 'slow_cluster_max',\n",
    "        'straight_ratio', 'straight_len_max_m', 'n_major_straights',\n",
    "        'heavy_braking_zones', 'heavy_braking_mean_dv_kmh', 'hb_at_end_of_max',\n",
    "        'avg_corner_angle', 'avg_corner_distance', 'drs_total_len_m'\n",
    "    ]\n",
    "    geom_cols = [col for col in geom_cols_all if col in df_train.columns]\n",
    "    print(f\"\\nGeometry columns available: {len(geom_cols)}/{len(geom_cols_all)}\")\n",
    "    print(f\"  Available: {geom_cols}\")\n",
    "\n",
    "TARGET = \"LapTime_next_vs_stint_baseline\"\n",
    "\n",
    "assert \"geom_cols\" in globals(), \"geom_cols not found. Run geometry step first.\"\n",
    "\n",
    "# Blocks \n",
    "\n",
    "NUM_TYRE = [\"is_new_tyre\", \"TyreLife\", \"TyreAgeAtStart\"]\n",
    "\n",
    "NUM_WEATHER = [\"AirTemp\", \"Humidity\", \"Pressure\", \"TrackTemp\", \"wind_sin\", \"wind_cos\"]\n",
    "\n",
    "# keep only \"safe\" state features (avoid anything that might embed the target)\n",
    "NUM_STATE = [\"is_leader\", \"in_drs_range\", \"in_clean_air\", \"in_dirty_air\", \"pushing\", 'laptime_rolling_std_3', 'delta_laptime', 'cumulative_degradation', 'LapTime']\n",
    "\n",
    "# Geometry features (raw columns, not PCA)\n",
    "# Excluding hb_at_end_of_max since it's boolean \n",
    "NUM_GEOMETRY = [col for col in geom_cols if col in df_train.columns and col != 'hb_at_end_of_max']\n",
    "\n",
    "# Circuit identity as categorical feature \n",
    "CIRCUIT_CAT = []  # (not used in this model) as we are doing circuit-disjoint splits\n",
    "\n",
    "# Driver and team as categorical features (driver skill + team effects)\n",
    "DRIVER_TEAM_CAT = [\"RacingNumber\", \"Team\"]\n",
    "\n",
    "CAT = [\"Compound\"] + DRIVER_TEAM_CAT\n",
    "\n",
    "\n",
    "# Grid search alphas\n",
    "\n",
    "ALPHAS_RIDGE = [0.1, 1.0, 10.0, 50.0, 100.0, 500.0, 1000.0, 5000.0]\n",
    "ALPHAS_EN = [0.001, 0.01, 0.1, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0, 1000.0]\n",
    "L1RATIOS = [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1.0]\n",
    "\n",
    "\n",
    "# Helpers\n",
    "\n",
    "def make_Xy(df, num_feats, cat_feats, target, fit_cols=None, medians=None):\n",
    "    X_raw = df[num_feats + cat_feats].copy()\n",
    "    y = df[target].astype(float).copy()\n",
    "\n",
    "    X = pd.get_dummies(X_raw, columns=cat_feats, drop_first=True)\n",
    "\n",
    "    if fit_cols is not None:\n",
    "        X = X.reindex(columns=fit_cols, fill_value=0)\n",
    "\n",
    "    if medians is None:\n",
    "        medians = X.median(numeric_only=True)\n",
    "    X = X.fillna(medians)\n",
    "\n",
    "    m = y.notna()\n",
    "    return X.loc[m], y.loc[m], X.columns, medians\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "def fit_eval(model, num_feats, label):\n",
    "    # train\n",
    "    Xtr, ytr, cols, meds = make_Xy(df_train, num_feats, CAT, TARGET)\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    # val\n",
    "    Xva, yva, _, _ = make_Xy(df_val, num_feats, CAT, TARGET, fit_cols=cols, medians=meds)\n",
    "    yva_hat = model.predict(Xva)\n",
    "\n",
    "    # test\n",
    "    Xte, yte, _, _ = make_Xy(df_test, num_feats, CAT, TARGET, fit_cols=cols, medians=meds)\n",
    "    yte_hat = model.predict(Xte)\n",
    "\n",
    "    return {\n",
    "        \"model\": label,\n",
    "        \"n_features\": Xtr.shape[1],\n",
    "        \"val\": metrics(yva, yva_hat),\n",
    "        \"test\": metrics(yte, yte_hat),\n",
    "        \"n_test\": len(Xte),\n",
    "    }\n",
    "\n",
    "\n",
    "# NESTED FEATURE LADDER\n",
    "\n",
    "FEAT_TYRE = NUM_TYRE\n",
    "FEAT_TYRE_WEATHER = NUM_TYRE + NUM_WEATHER\n",
    "FEAT_TYRE_WEATHER_STATE = NUM_TYRE + NUM_WEATHER + NUM_STATE\n",
    "FEAT_TYRE_WEATHER_STATE_GEOM = NUM_TYRE + NUM_WEATHER + NUM_STATE + NUM_GEOMETRY\n",
    "\n",
    "EXPERIMENTS = [\n",
    "    (\"1) Tyre (Linear)\", LinearRegression(), FEAT_TYRE),\n",
    "    (\"2) Tyre+Weather (Linear)\", LinearRegression(), FEAT_TYRE_WEATHER),\n",
    "    (\"3) Tyre+Weather+State (Linear)\", LinearRegression(), FEAT_TYRE_WEATHER_STATE),\n",
    "    (\"4) Tyre+Weather+State+Geometry (Linear)\", LinearRegression(), FEAT_TYRE_WEATHER_STATE_GEOM),\n",
    "]\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"CIRCUIT-BASED MODEL: nested blocks + raw geometry + GridSearchCV for optimal regularization\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "rows = []\n",
    "for label, model, feats in EXPERIMENTS:\n",
    "    res = fit_eval(model, feats, label)\n",
    "    print(f\"{label:<45} | Test MAE {res['test']['MAE']:.4f} | Test R² {res['test']['R2']:.4f} | p={res['n_features']}\")\n",
    "    rows.append({\n",
    "        \"model\": res[\"model\"],\n",
    "        \"p\": res[\"n_features\"],\n",
    "        \"val_MAE\": res[\"val\"][\"MAE\"],\n",
    "        \"val_R2\": res[\"val\"][\"R2\"],\n",
    "        \"test_MAE\": res[\"test\"][\"MAE\"],\n",
    "        \"test_RMSE\": res[\"test\"][\"RMSE\"],\n",
    "        \"test_R2\": res[\"test\"][\"R2\"],\n",
    "        \"n_test\": res[\"n_test\"],\n",
    "    })\n",
    "\n",
    "\n",
    "# Gridsearch CV for Ridge alpha on full features\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Gridsearch CV: Finding optimal Ridge α for Tyre+Weather+State+Geometry\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Prepare data\n",
    "Xtr, ytr, cols, meds = make_Xy(df_train, FEAT_TYRE_WEATHER_STATE_GEOM, CAT, TARGET)\n",
    "Xva, yva, _, _ = make_Xy(df_val, FEAT_TYRE_WEATHER_STATE_GEOM, CAT, TARGET, fit_cols=cols, medians=meds)\n",
    "\n",
    "# Grid search on validation set\n",
    "print(f\"\\nTesting alphas: {ALPHAS_RIDGE}\")\n",
    "print(f\"Train set: {Xtr.shape[0]} samples, {Xtr.shape[1]} features\")\n",
    "print(f\"Val set:   {Xva.shape[0]} samples\")\n",
    "\n",
    "grid_results = []\n",
    "for alpha in ALPHAS_RIDGE:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(Xtr, ytr)\n",
    "    yva_hat = ridge.predict(Xva)\n",
    "    \n",
    "    mae = mean_absolute_error(yva, yva_hat)\n",
    "    rmse = np.sqrt(mean_squared_error(yva, yva_hat))\n",
    "    r2 = r2_score(yva, yva_hat)\n",
    "    \n",
    "    grid_results.append({\n",
    "        \"alpha\": alpha,\n",
    "        \"val_MAE\": mae,\n",
    "        \"val_RMSE\": rmse,\n",
    "        \"val_R2\": r2,\n",
    "    })\n",
    "    print(f\"  α={alpha:7.1f}: Val MAE={mae:.4f}, Val RMSE={rmse:.4f}, Val R²={r2:.4f}\")\n",
    "\n",
    "# Find best alpha\n",
    "grid_df = pd.DataFrame(grid_results)\n",
    "best_idx = grid_df[\"val_MAE\"].idxmin()\n",
    "best_alpha = grid_df.loc[best_idx, \"alpha\"]\n",
    "best_mae = grid_df.loc[best_idx, \"val_MAE\"]\n",
    "\n",
    "print(f\"\\n✓ Best Alpha: {best_alpha:.1f} (Val MAE: {best_mae:.4f})\")\n",
    "\n",
    "# Train on full dataset + best alpha and evaluate on test\n",
    "print(f\"\\nTraining final Ridge model with α={best_alpha:.1f} on full training data...\")\n",
    "ridge_best = Ridge(alpha=best_alpha)\n",
    "ridge_best.fit(Xtr, ytr)\n",
    "\n",
    "Xte, yte, _, _ = make_Xy(df_test, FEAT_TYRE_WEATHER_STATE_GEOM, CAT, TARGET, fit_cols=cols, medians=meds)\n",
    "yte_hat = ridge_best.predict(Xte)\n",
    "\n",
    "best_ridge_metrics = metrics(yte, yte_hat)\n",
    "print(f\"  Test MAE:  {best_ridge_metrics['MAE']:.4f}\")\n",
    "print(f\"  Test RMSE: {best_ridge_metrics['RMSE']:.4f}\")\n",
    "print(f\"  Test R²:   {best_ridge_metrics['R2']:.4f}\")\n",
    "\n",
    "rows.append({\n",
    "    \"model\": f\"5) Tyre+Weather+State+Geometry (Ridge α={best_alpha:.1f}✓)\",\n",
    "    \"p\": Xtr.shape[1],\n",
    "    \"val_MAE\": grid_df.loc[best_idx, \"val_MAE\"],\n",
    "    \"val_R2\": grid_df.loc[best_idx, \"val_R2\"],\n",
    "    \"test_MAE\": best_ridge_metrics[\"MAE\"],\n",
    "    \"test_RMSE\": best_ridge_metrics[\"RMSE\"],\n",
    "    \"test_R2\": best_ridge_metrics[\"R2\"],\n",
    "    \"n_test\": len(Xte),\n",
    "})\n",
    "\n",
    "# Gridsearch CV for Ridge alpha on TYRE+WEATHER+STATE\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Gridsearch CV: Finding optimal Ridge α for Tyre+Weather+State\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Prepare data\n",
    "Xtr_tws, ytr_tws, cols_tws, meds_tws = make_Xy(df_train, FEAT_TYRE_WEATHER_STATE, CAT, TARGET)\n",
    "Xva_tws, yva_tws, _, _ = make_Xy(df_val, FEAT_TYRE_WEATHER_STATE, CAT, TARGET, fit_cols=cols_tws, medians=meds_tws)\n",
    "\n",
    "# Grid search on validation set\n",
    "print(f\"\\nTesting alphas: {ALPHAS_RIDGE}\")\n",
    "print(f\"Train set: {Xtr_tws.shape[0]} samples, {Xtr_tws.shape[1]} features\")\n",
    "print(f\"Val set:   {Xva_tws.shape[0]} samples\")\n",
    "\n",
    "grid_results_tws = []\n",
    "for alpha in ALPHAS_RIDGE:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(Xtr_tws, ytr_tws)\n",
    "    yva_hat = ridge.predict(Xva_tws)\n",
    "    \n",
    "    mae = mean_absolute_error(yva_tws, yva_hat)\n",
    "    rmse = np.sqrt(mean_squared_error(yva_tws, yva_hat))\n",
    "    r2 = r2_score(yva_tws, yva_hat)\n",
    "    \n",
    "    grid_results_tws.append({\n",
    "        \"alpha\": alpha,\n",
    "        \"val_MAE\": mae,\n",
    "        \"val_RMSE\": rmse,\n",
    "        \"val_R2\": r2,\n",
    "    })\n",
    "    print(f\"  α={alpha:7.1f}: Val MAE={mae:.4f}, Val RMSE={rmse:.4f}, Val R²={r2:.4f}\")\n",
    "\n",
    "# Find best alpha\n",
    "grid_df_tws = pd.DataFrame(grid_results_tws)\n",
    "best_idx_tws = grid_df_tws[\"val_MAE\"].idxmin()\n",
    "best_alpha_tws = grid_df_tws.loc[best_idx_tws, \"alpha\"]\n",
    "best_mae_tws = grid_df_tws.loc[best_idx_tws, \"val_MAE\"]\n",
    "\n",
    "print(f\"\\n✓ Best Alpha: {best_alpha_tws:.1f} (Val MAE: {best_mae_tws:.4f})\")\n",
    "\n",
    "# Train on full dataset + best alpha and evaluate on test\n",
    "print(f\"\\nTraining final Ridge model with α={best_alpha_tws:.1f} on full training data...\")\n",
    "ridge_best_tws = Ridge(alpha=best_alpha_tws)\n",
    "ridge_best_tws.fit(Xtr_tws, ytr_tws)\n",
    "\n",
    "Xte_tws, yte_tws, _, _ = make_Xy(df_test, FEAT_TYRE_WEATHER_STATE, CAT, TARGET, fit_cols=cols_tws, medians=meds_tws)\n",
    "yte_hat_tws = ridge_best_tws.predict(Xte_tws)\n",
    "\n",
    "best_ridge_metrics_tws = metrics(yte_tws, yte_hat_tws)\n",
    "print(f\"  Test MAE:  {best_ridge_metrics_tws['MAE']:.4f}\")\n",
    "print(f\"  Test RMSE: {best_ridge_metrics_tws['RMSE']:.4f}\")\n",
    "print(f\"  Test R²:   {best_ridge_metrics_tws['R2']:.4f}\")\n",
    "\n",
    "rows.append({\n",
    "    \"model\": f\"5a) Tyre+Weather+State (Ridge α={best_alpha_tws:.1f}✓)\",\n",
    "    \"p\": Xtr_tws.shape[1],\n",
    "    \"val_MAE\": grid_df_tws.loc[best_idx_tws, \"val_MAE\"],\n",
    "    \"val_R2\": grid_df_tws.loc[best_idx_tws, \"val_R2\"],\n",
    "    \"test_MAE\": best_ridge_metrics_tws[\"MAE\"],\n",
    "    \"test_RMSE\": best_ridge_metrics_tws[\"RMSE\"],\n",
    "    \"test_R2\": best_ridge_metrics_tws[\"R2\"],\n",
    "    \"n_test\": len(Xte_tws),\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Gridsearch: Elastic Net (alpha, l1_ratio)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Gridsearch: Elastic Net (alpha, l1_ratio) on Tyre+Weather+State+Geometry\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Build raw matrices with your exact alignment\n",
    "Xtr_raw, ytr_en, cols_en, meds_en = make_Xy(df_train, FEAT_TYRE_WEATHER_STATE_GEOM, CAT, TARGET)\n",
    "Xva_raw, yva_en, _, _              = make_Xy(df_val,   FEAT_TYRE_WEATHER_STATE_GEOM, CAT, TARGET, fit_cols=cols_en, medians=meds_en)\n",
    "Xte_raw, yte_en, _, _              = make_Xy(df_test,  FEAT_TYRE_WEATHER_STATE_GEOM, CAT, TARGET, fit_cols=cols_en, medians=meds_en)\n",
    "\n",
    "# Scale using TRAIN only\n",
    "scaler = StandardScaler()\n",
    "Xtr_scaled = scaler.fit_transform(Xtr_raw)\n",
    "Xva_scaled = scaler.transform(Xva_raw)\n",
    "Xte_scaled = scaler.transform(Xte_raw)\n",
    "\n",
    "best_en = {\"val_MAE\": np.inf, \"alpha\": None, \"l1_ratio\": None, \"model\": None, \"val_R2\": None}\n",
    "\n",
    "print(f\"\\nTesting ElasticNet with {len(L1RATIOS)} l1_ratios × {len(ALPHAS_EN)} alphas = {len(L1RATIOS)*len(ALPHAS_EN)} combinations\")\n",
    "for l1 in L1RATIOS:\n",
    "    for a in ALPHAS_EN:\n",
    "        en = ElasticNet(alpha=a, l1_ratio=l1, max_iter=50000, tol=1e-4, random_state=42)\n",
    "        en.fit(Xtr_scaled, ytr_en)\n",
    "        yva_hat = en.predict(Xva_scaled)\n",
    "\n",
    "        mae = mean_absolute_error(yva_en, yva_hat)\n",
    "        r2  = r2_score(yva_en, yva_hat)\n",
    "\n",
    "        if mae < best_en[\"val_MAE\"]:\n",
    "            best_en.update({\"val_MAE\": mae, \"val_R2\": r2, \"alpha\": a, \"l1_ratio\": l1, \"model\": en})\n",
    "\n",
    "        print(f\"  l1_ratio={l1:>4.2f} | alpha={a:>7.3g} | Val MAE={mae:.4f} | Val R²={r2:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ Best ElasticNet: alpha={best_en['alpha']} | l1_ratio={best_en['l1_ratio']} | Val MAE={best_en['val_MAE']:.4f}\")\n",
    "\n",
    "# Test evaluation (once)\n",
    "yte_hat_en = best_en[\"model\"].predict(Xte_scaled)\n",
    "en_test = metrics(yte_en, yte_hat_en)\n",
    "\n",
    "n_nonzero = int(np.sum(best_en[\"model\"].coef_ != 0))\n",
    "print(\"\\nElasticNet TEST:\")\n",
    "print(f\"  Test MAE:  {en_test['MAE']:.4f}\")\n",
    "print(f\"  Test RMSE: {en_test['RMSE']:.4f}\")\n",
    "print(f\"  Test R²:   {en_test['R2']:.4f}\")\n",
    "print(f\"  Non-zero coefficients: {n_nonzero}/{Xtr_raw.shape[1]}\")\n",
    "\n",
    "rows.append({\n",
    "    \"model\": f\"6) Tyre+Weather+State+Geometry (ElasticNet a={best_en['alpha']}, l1={best_en['l1_ratio']})\",\n",
    "    \"p\": Xtr_raw.shape[1],\n",
    "    \"val_MAE\": best_en[\"val_MAE\"],\n",
    "    \"val_R2\": best_en[\"val_R2\"],\n",
    "    \"test_MAE\": en_test[\"MAE\"],\n",
    "    \"test_RMSE\": en_test[\"RMSE\"],\n",
    "    \"test_R2\": en_test[\"R2\"],\n",
    "    \"n_test\": len(Xte_raw),\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY (sorted by Test MAE)\")\n",
    "print(\"=\"*100)\n",
    "summary = pd.DataFrame(rows).sort_values(\"test_MAE\")\n",
    "print(summary.to_string(index=False))  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Formula1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
