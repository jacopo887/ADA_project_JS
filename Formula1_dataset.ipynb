{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9a4f4c",
   "metadata": {},
   "source": [
    "difficolta che trovi nei dati scrivile poi nel report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26525eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fastf1\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import scipy as sp\n",
    "import scipy.spatial\n",
    "from scipy.spatial import cKDTree\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bac4af",
   "metadata": {},
   "source": [
    "In the code below we use the open source database available here (https://github.com/f1db/f1db/tree/main)\n",
    "\n",
    "\n",
    "To download the repo, run on the terminal the following commands : \n",
    "\n",
    "- wget https://github.com/f1db/f1db/archive/refs/heads/main.zip\n",
    "\n",
    "\n",
    "- unzip main.zip -d f1db_data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa92f2",
   "metadata": {},
   "source": [
    "# From F1DB repo, download the circuits datas. \n",
    "\n",
    "- Convert the yml into csv\n",
    "\n",
    "- Drop unnecessary columns \n",
    "\n",
    "- Check manuallly how many drs zones there are for track , and add it to the dataframe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e807fa52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "circuitRef",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "countryId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "turns",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "drs_zones",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "width_m",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8b139039-0607-4a47-a7ad-9f0de59c6467",
       "rows": [
        [
         "0",
         "east-london",
         "Prince George",
         "south-africa",
         "3.92",
         "9",
         null,
         null,
         "RACE"
        ],
        [
         "1",
         "nivelles",
         "Nivelles-Baulers",
         "belgium",
         "3.724",
         "7",
         null,
         null,
         "RACE"
        ],
        [
         "2",
         "monsanto",
         "Monsanto",
         "portugal",
         "5.44",
         "9",
         null,
         null,
         "STREET"
        ],
        [
         "3",
         "yas-marina",
         "Yas Marina",
         "united-arab-emirates",
         "5.281",
         "16",
         null,
         null,
         "RACE"
        ],
        [
         "4",
         "austin",
         "Americas",
         "united-states-of-america",
         "5.513",
         "20",
         null,
         null,
         "RACE"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circuitRef</th>\n",
       "      <th>name</th>\n",
       "      <th>countryId</th>\n",
       "      <th>length_km</th>\n",
       "      <th>turns</th>\n",
       "      <th>drs_zones</th>\n",
       "      <th>width_m</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>east-london</td>\n",
       "      <td>Prince George</td>\n",
       "      <td>south-africa</td>\n",
       "      <td>3.920</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>RACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nivelles</td>\n",
       "      <td>Nivelles-Baulers</td>\n",
       "      <td>belgium</td>\n",
       "      <td>3.724</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>RACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monsanto</td>\n",
       "      <td>Monsanto</td>\n",
       "      <td>portugal</td>\n",
       "      <td>5.440</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>STREET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yas-marina</td>\n",
       "      <td>Yas Marina</td>\n",
       "      <td>united-arab-emirates</td>\n",
       "      <td>5.281</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>RACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>austin</td>\n",
       "      <td>Americas</td>\n",
       "      <td>united-states-of-america</td>\n",
       "      <td>5.513</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>RACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    circuitRef              name                 countryId  length_km  turns  \\\n",
       "0  east-london     Prince George              south-africa      3.920      9   \n",
       "1     nivelles  Nivelles-Baulers                   belgium      3.724      7   \n",
       "2     monsanto          Monsanto                  portugal      5.440      9   \n",
       "3   yas-marina        Yas Marina      united-arab-emirates      5.281     16   \n",
       "4       austin          Americas  united-states-of-america      5.513     20   \n",
       "\n",
       "  drs_zones width_m    type  \n",
       "0      None    None    RACE  \n",
       "1      None    None    RACE  \n",
       "2      None    None  STREET  \n",
       "3      None    None    RACE  \n",
       "4      None    None    RACE  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Path to the 'circuits' folder inside the F1DB repo\n",
    "circuits_folder = \"/Users/jacoposinigaglia/Desktop/svizzera/terzo_semestre/Advanced_Data_Analysis/Progetto/f1db-main/src/data/circuits\"\n",
    "\n",
    "data = []\n",
    "\n",
    "for file_name in os.listdir(circuits_folder):\n",
    "    if file_name.endswith(\".yml\"):\n",
    "        with open(os.path.join(circuits_folder, file_name), 'r') as f:\n",
    "            circuit = yaml.safe_load(f)\n",
    "        \n",
    "        # Extract only the fields you need, handle missing safely\n",
    "        data.append({\n",
    "            \"circuitRef\": circuit.get(\"id\"),\n",
    "            \"name\": circuit.get(\"name\"),\n",
    "            \"countryId\": circuit.get(\"countryId\"),\n",
    "            \"length_km\": circuit.get(\"length\"),\n",
    "            \"turns\": circuit.get(\"turns\"),\n",
    "            \"drs_zones\": circuit.get(\"drsZones\"),\n",
    "            \"width_m\": circuit.get(\"width\"),\n",
    "            \"type\": circuit.get(\"type\")\n",
    "        })\n",
    "\n",
    "circuit_specs = pd.DataFrame(data)\n",
    "#circuit_specs.rename(columns={\"countryId\": \"country\"}, inplace=True)\n",
    "# numeric_cols = [\"length_km\", \"turns\", \"drs_zones\", \"width_m\"]\n",
    "# circuit_specs[numeric_cols] = circuit_specs[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# save to csv\n",
    "circuit_specs.to_csv(\"csv_output/circuit_specs.csv\", index=False)\n",
    "\n",
    "circuit_specs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075744fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your existing circuit specs file\n",
    "circuit_specs = pd.read_csv(\"csv_output/circuit_specs.csv\")\n",
    "\n",
    "# --- DRS zone counts (fill these manually as you check each circuit) ---\n",
    "drs_zones = {\n",
    "    \"adelaide\": 2,\n",
    "    \"aida\": 0,\n",
    "    \"ain-diab\": 0,\n",
    "    \"aintree\": 0,\n",
    "    \"andertorp\": 0,\n",
    "    \"austin\": 2,\n",
    "    \"avus\": 0,\n",
    "    \"bahrain\": 3,\n",
    "    \"baku\": 2, \n",
    "    \"brands-hatch\": 0,\n",
    "    \"bremgarten\": 0,\n",
    "    \"buddh\":0, \n",
    "    \"buenos-aires\": 0,\n",
    "    \"bugatti\": 0,\n",
    "    \"caesars-palace\": 0,\n",
    "    \"catalunya\": 2,\n",
    "    \"clermont-ferrand\": 0,\n",
    "    \"dallas\": 0,\n",
    "    \"detroit\": 0,\n",
    "    \"dijon\": 0,\n",
    "    \"donington\": 0,\n",
    "    \"east-london\": 0,\n",
    "    \"estoril\": 0,\n",
    "    \"fuji\": 0,\n",
    "    \"hockenheimring\": 2,\n",
    "    \"hungaroring\": 2,\n",
    "    \"imola\": 1,\n",
    "    \"indianapolis\": 0,\n",
    "    \"interlagos\": 2,\n",
    "    \"istanbul\": 2,\n",
    "    \"jacarepagua\": 0,\n",
    "    \"jerema\":0,\n",
    "    \"jerez\": 0,\n",
    "    \"jeddah\": 3,\n",
    "    \"kyalami\": 0,\n",
    "    \"las-vegas\": 2,\n",
    "    \"long-beach\": 0,\n",
    "    \"lusail\": 1,\n",
    "    \"magny-cours\": 0,\n",
    "    \"marina-bay\": 4,\n",
    "    \"melbourne\": 4,\n",
    "    \"mexico-city\": 3,\n",
    "    \"monaco\": 1,\n",
    "    \"miami\": 3,\n",
    "    \"monsanto\": 0,\n",
    "    \"mont-tremblant\": 0,\n",
    "    \"montjuic\": 0,\n",
    "    \"montereal\": 3,\n",
    "    \"monza\": 2,\n",
    "    \"mosport\": 0,\n",
    "    \"mugello\": 1,\n",
    "    \"nivelles\": 0,\n",
    "    \"nurburgring\": 1,\n",
    "    \"paul-ricard\": 2,\n",
    "    \"pedralbes\": 0,\n",
    "    \"pescara\": 0,\n",
    "    \"phoenix\": 0,\n",
    "    \"portimao\": 2,\n",
    "    \"porto\":2, \n",
    "    \"reims\": 0,\n",
    "    \"rouen\": 0,\n",
    "    \"sepang\": 2,\n",
    "    \"shanghai\": 2,\n",
    "    \"silverstone\": 2,\n",
    "    \"sochi\": 2,\n",
    "    \"spa-francorchamps\": 2,\n",
    "    \"spielberg\": 3,\n",
    "    \"suzuka\": 1,\n",
    "    \"valencia\": 1,\n",
    "    \"watkins-glen\": 0,\n",
    "    \"yas-marina\": 2,\n",
    "    \"yeongam\": 2,\n",
    "    \"zandvoort\": 2,\n",
    "    \"zeltweg\": 0,\n",
    "    \"zolder\":  0,\n",
    "    \"sebring\":  0, \n",
    "    \"jarama\":  0,\n",
    "    \"montreal\":  3, \n",
    "    \"anderstorp\":  0,\n",
    "    \"riverside\":  0}\n",
    "\n",
    "# Add the new column \n",
    "circuit_specs[\"num_drs_zones\"] = circuit_specs[\"circuitRef\"].map(drs_zones)\n",
    "\n",
    "circuit_specs.drop(columns=[\"drs_zones\", \"width_m\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e551230",
   "metadata": {},
   "source": [
    "# From fastf1 download the available dataset\n",
    "\n",
    "Get the race schedule: \n",
    "\n",
    "- For given season , take  Circuitref , Year , round\n",
    "\n",
    "- Merge it with ciurcuit_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d46b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Australian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Year: 2025\n",
      "============================================================\n",
      "[ 1] Australian Grand Prix                    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '87'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '30'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core        WARNING \tDriver 4 completed the race distance 00:00.022000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '63', '12', '23', '18', '27', '16', '81', '44', '10', '22', '31', '87', '30', '5', '14', '55', '7', '6']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '4'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '1', '63', '22', '23', '16', '44', '10', '55', '6', '14', '18', '7', '5', '12', '27', '30', '31', '87']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ 2] Chinese Grand Prix                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '63', '1', '31', '12', '23', '87', '18', '55', '6', '30', '7', '5', '27', '22', '14', '16', '44', '10']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '63', '4', '1', '44', '16', '6', '12', '22', '23', '31', '27', '14', '18', '55', '10', '87', '7', '5', '30']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ 3] Japanese Grand Prix                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '16', '63', '12', '44', '6', '23', '87', '14', '22', '10', '55', '7', '27', '30', '31', '5', '18']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '16', '63', '12', '6', '44', '23', '87', '10', '55', '14', '30', '22', '27', '5', '31', '7', '18']\n",
      "core           INFO \tLoading data for Bahrain Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ 4] Bahrain Grand Prix                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '63', '4', '16', '44', '1', '10', '31', '22', '87', '12', '23', '6', '7', '14', '30', '18', '5', '55', '27']\n",
      "core           INFO \tLoading data for Bahrain Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '63', '16', '12', '10', '4', '1', '55', '44', '22', '7', '6', '14', '31', '23', '27', '30', '5', '18', '87']\n",
      "core           INFO \tLoading data for Saudi Arabian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ 5] Saudi Arabian Grand Prix                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '1', '16', '4', '63', '12', '44', '55', '23', '6', '14', '30', '87', '31', '27', '18', '7', '5', '22', '10']\n",
      "core           INFO \tLoading data for Saudi Arabian Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '81', '63', '16', '12', '55', '44', '22', '10', '4', '23', '30', '14', '6', '87', '18', '7', '27', '31', '5']\n",
      "core           INFO \tLoading data for Miami Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '6'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '31'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '18'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ 6] Miami Grand Prix                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core        WARNING \tDriver 81 completed the race distance 00:00.036000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '63', '1', '23', '12', '16', '44', '55', '22', '6', '31', '10', '27', '14', '18', '30', '5', '87', '7']\n",
      "core           INFO \tLoading data for Miami Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '12', '81', '63', '55', '23', '16', '31', '22', '6', '44', '5', '7', '30', '27', '14', '10', '18', '87']\n",
      "core           INFO \tLoading data for Emilia Romagna Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ 7] Emilia Romagna Grand Prix                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '44', '23', '16', '63', '55', '6', '22', '14', '27', '10', '30', '18', '43', '87', '5', '12', '31']\n",
      "core           INFO \tLoading data for Emilia Romagna Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '1', '63', '4', '14', '55', '23', '18', '6', '10', '16', '44', '12', '5', '43', '30', '27', '31', '87', '22']\n",
      "core           INFO \tLoading data for Monaco Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ 8] Monaco Grand Prix                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '16', '81', '1', '44', '6', '31', '30', '23', '55', '63', '87', '43', '5', '18', '27', '22', '12', '14', '10']\n",
      "core           INFO \tLoading data for Monaco Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '16', '81', '44', '1', '6', '14', '31', '30', '23', '55', '22', '27', '63', '12', '5', '87', '10', '18', '43']\n",
      "core           INFO \tLoading data for Spanish Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ 9] Spanish Grand Prix                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 19 drivers: ['81', '4', '16', '63', '27', '44', '6', '10', '14', '1', '30', '5', '22', '55', '43', '31', '87', '12', '23']\n",
      "core           INFO \tLoading data for Spanish Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '1', '63', '44', '12', '16', '10', '6', '14', '23', '5', '30', '18', '87', '27', '31', '55', '43', '22']\n",
      "core           INFO \tLoading data for Canadian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[10] Canadian Grand Prix                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '1', '12', '81', '16', '44', '14', '27', '31', '55', '87', '22', '43', '5', '10', '6', '18', '4', '30', '23']\n",
      "core           INFO \tLoading data for Canadian Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '1', '81', '12', '44', '14', '4', '16', '6', '23', '22', '43', '27', '87', '31', '5', '55', '18', '30', '10']\n",
      "core           INFO \tLoading data for Austrian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[11] Austrian Grand Prix                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '16', '44', '63', '30', '14', '5', '27', '31', '87', '6', '10', '18', '43', '22', '23', '1', '12', '55']\n",
      "core           INFO \tLoading data for Austrian Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '16'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '1'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '12'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '10'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '14'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '23'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '6'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '16', '81', '44', '63', '30', '1', '5', '12', '10', '14', '23', '6', '43', '87', '18', '31', '22', '55', '27']\n",
      "core           INFO \tLoading data for British Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[12] British Grand Prix                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '27', '44', '1', '10', '18', '23', '14', '63', '87', '55', '31', '16', '22', '12', '6', '5', '30', '43']\n",
      "core           INFO \tLoading data for British Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '81', '4', '63', '44', '16', '12', '87', '14', '10', '55', '22', '6', '23', '31', '30', '5', '18', '27', '43']\n",
      "core           INFO \tLoading data for Belgian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '81'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '4'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '16'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '1'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '63'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '23'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '44'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[13] Belgian Grand Prix                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tFixed incorrect tyre stint information for driver '30'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '10'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '87'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '27'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '22'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '18'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '31'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '12'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '14'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '55'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '43'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '6'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '16', '1', '63', '23', '44', '30', '5', '10', '87', '27', '22', '18', '31', '12', '14', '55', '43', '6']\n",
      "core           INFO \tLoading data for Belgian Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '16', '1', '23', '63', '22', '6', '30', '5', '31', '87', '10', '27', '55', '44', '43', '12', '14', '18']\n",
      "core           INFO \tLoading data for Hungarian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[14] Hungarian Grand Prix                     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '63', '16', '14', '5', '18', '30', '1', '12', '6', '44', '27', '55', '23', '31', '22', '43', '10', '87']\n",
      "core           INFO \tLoading data for Hungarian Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '81', '4', '63', '14', '18', '5', '1', '30', '6', '87', '44', '55', '43', '12', '22', '10', '31', '27', '23']\n",
      "core           INFO \tLoading data for Dutch Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[15] Dutch Grand Prix                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '1', '6', '63', '23', '87', '18', '14', '22', '31', '43', '30', '55', '27', '5', '12', '10', '4', '16', '44']\n",
      "core           INFO \tLoading data for Dutch Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '1', '6', '63', '16', '44', '30', '55', '14', '12', '22', '5', '10', '23', '43', '27', '31', '87', '18']\n",
      "core           INFO \tLoading data for Italian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[16] Italian Grand Prix                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '16', '63', '44', '23', '5', '12', '6', '55', '87', '22', '30', '31', '10', '43', '18', '14', '27']\n",
      "core           INFO \tLoading data for Italian Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '16', '44', '63', '12', '5', '14', '22', '87', '27', '55', '23', '31', '6', '18', '43', '10', '30']\n",
      "core           INFO \tLoading data for Azerbaijan Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[17] Azerbaijan Grand Prix                    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core        WARNING \tDriver 1 completed the race distance 00:00.015000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '63', '55', '12', '30', '22', '4', '44', '16', '6', '5', '87', '23', '31', '14', '27', '18', '10', '43', '81']\n",
      "core           INFO \tLoading data for Azerbaijan Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '55', '30', '12', '63', '22', '4', '6', '81', '16', '14', '44', '5', '18', '87', '43', '27', '10', '23', '31']\n",
      "core           INFO \tLoading data for Singapore Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[18] Singapore Grand Prix                     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '1', '4', '81', '12', '16', '14', '44', '87', '55', '6', '22', '18', '23', '30', '43', '5', '31', '10', '27']\n",
      "core           INFO \tLoading data for Singapore Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '1', '81', '12', '4', '44', '16', '6', '87', '14', '27', '30', '22', '5', '18', '43', '31', '10', '23', '55']\n",
      "events      WARNING \tCorrecting user input 'United States Grand Prix' to 'United States Grand Prix'\n",
      "core           INFO \tLoading data for United States Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[19] United States Grand Prix                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '16', '44', '81', '63', '22', '27', '87', '14', '30', '18', '12', '23', '31', '6', '43', '5', '10', '55']\n",
      "events      WARNING \tCorrecting user input 'United States Grand Prix' to 'United States Grand Prix'\n",
      "core           INFO \tLoading data for United States Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '16', '63', '44', '81', '12', '87', '55', '14', '27', '30', '22', '10', '43', '5', '31', '18', '23', '6']\n",
      "core           INFO \tLoading data for Mexico City Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[20] Mexico City Grand Prix                   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '16', '1', '87', '81', '12', '63', '44', '31', '5', '22', '23', '6', '18', '10', '43', '55', '14', '27', '30']\n",
      "core           INFO \tLoading data for Mexico City Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '16', '44', '63', '1', '12', '55', '81', '6', '87', '22', '31', '27', '14', '30', '5', '23', '10', '18', '43']\n",
      "core           INFO \tLoading data for São Paulo Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[21] São Paulo Grand Prix                     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core        WARNING \tDriver 4 completed the race distance 00:00.010000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '12', '1', '63', '81', '87', '30', '6', '27', '10', '23', '31', '55', '14', '43', '18', '22', '44', '16', '5']\n",
      "core           INFO \tLoading data for São Paulo Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tNo lap data for driver 5\n",
      "core        WARNING \tFailed to perform lap accuracy check - all laps marked as inaccurate (driver 5)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '12', '16', '81', '6', '63', '30', '87', '10', '27', '14', '23', '44', '18', '55', '1', '31', '43', '22', '5']\n",
      "core           INFO \tLoading data for Las Vegas Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '63'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[22] Las Vegas Grand Prix                     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '63', '12', '16', '55', '6', '27', '44', '31', '87', '14', '22', '10', '30', '43', '23', '5', '18', '4', '81']\n",
      "core           INFO \tLoading data for Las Vegas Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '55', '63', '81', '30', '14', '6', '16', '10', '27', '18', '31', '87', '43', '23', '12', '5', '22', '44']\n",
      "events      WARNING \tCorrecting user input 'Qatar Grand Prix' to 'Qatar Grand Prix'\n",
      "core           INFO \tLoading data for Qatar Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[23] Qatar Grand Prix                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '81', '55', '4', '12', '63', '14', '16', '30', '22', '23', '44', '5', '43', '31', '10', '18', '6', '87', '27']\n",
      "events      WARNING \tCorrecting user input 'Qatar Grand Prix' to 'Qatar Grand Prix'\n",
      "core           INFO \tLoading data for Qatar Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '1', '63', '12', '6', '55', '14', '10', '16', '27', '30', '87', '5', '23', '22', '31', '44', '18', '43']\n",
      "core           INFO \tLoading data for Abu Dhabi Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[24] Abu Dhabi Grand Prix                     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '81', '4', '16', '63', '14', '31', '44', '27', '18', '5', '87', '55', '22', '12', '23', '6', '30', '10', '43']\n",
      "core           INFO \tLoading data for Abu Dhabi Grand Prix - Qualifying [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '63', '16', '14', '5', '31', '6', '22', '87', '55', '30', '12', '18', '44', '23', '27', '10', '43']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "\n",
      " Done! Time: 0:00:47.221994\n"
     ]
    }
   ],
   "source": [
    "# THIS SECTION HAS ALREADY BEEN EXECUTED - DATA IS IN ./cache FOLDER\n",
    "# The download was split into multiple parts due to API limitations\n",
    "# All data for 2018-2025 is now cached and ready to use\n",
    "# \n",
    "\n",
    "'''\n",
    "# Enable cache\n",
    "fastf1.Cache.enable_cache(\"./cache\")\n",
    "\n",
    "# Download data for 2018-2024\n",
    "YEARS = range(2025, 2026)\n",
    "start = datetime.now()\n",
    "\n",
    "for year in YEARS:\n",
    "    print(f\"\\n{'='*60}\\nYear: {year}\\n{'='*60}\")\n",
    "    schedule = fastf1.get_event_schedule(year)\n",
    "    races = schedule[schedule['RoundNumber'] >= 1]\n",
    "    \n",
    "    for idx, race in races.iterrows():\n",
    "        try:\n",
    "            print(f\"[{race['RoundNumber']:2d}] {race['EventName']:40s}\", end=\" \")\n",
    "            \n",
    "            # Download Race + Qualifying\n",
    "            fastf1.get_session(year, race['EventName'], 'R').load()\n",
    "            fastf1.get_session(year, race['EventName'], 'Q').load()\n",
    "            \n",
    "            print(\"✓\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {str(e)[:40]}\")\n",
    "\n",
    "print(f\"\\n Done! Time: {datetime.now() - start}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664cedcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configured to process years: [2023, 2024, 2025]\n",
      "To process more years, check your cache folder and update SCHEDULE_YEARS\n",
      "\n",
      "Reading cache for 2023...\n",
      "  ✓ Found 22 race folders\n",
      "  ✓ Mapped 22/22 races to circuits\n",
      "\n",
      "Reading cache for 2024...\n",
      "  ✓ Found 24 race folders\n",
      "  ✓ Mapped 24/24 races to circuits\n",
      "\n",
      "Reading cache for 2025...\n",
      "  ✓ Found 24 race folders\n",
      "  ✓ Mapped 24/24 races to circuits\n",
      "\n",
      "✓ Schedule file saved: csv_output/circuit_specs_with_rounds_2023_2025.csv\n",
      "  Total race entries: 70\n",
      "  Years: 2023-2025\n",
      "  Unique circuits: 24\n"
     ]
    }
   ],
   "source": [
    "# Build race schedule with circuitRef for multiple years (2018-2024)\n",
    "# Since schedule metadata isn't cached, we build it from cache folder structure\n",
    "\n",
    "def get_race_schedule_from_cache(year: int, cache_dir: str = \"./cache\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build race schedule by reading the cache folder structure directly.\n",
    "    This avoids needing to download schedule data from the API.\n",
    "    \"\"\"\n",
    "    year_path = os.path.join(cache_dir, str(year))\n",
    "    \n",
    "    if not os.path.exists(year_path):\n",
    "        print(f\"No cache folder found for {year}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    schedules = []\n",
    "    for folder_name in sorted(os.listdir(year_path)):\n",
    "        if not os.path.isdir(os.path.join(year_path, folder_name)):\n",
    "            continue\n",
    "            \n",
    "        # Folder format: \"YYYY-MM-DD_Event_Name\"\n",
    "        parts = folder_name.split(\"_\", 1)\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "            \n",
    "        date_str, event_name = parts\n",
    "        \n",
    "        # Extract round number and clean event name\n",
    "        # Event name might be like \"03_Australian_Grand_Prix\" or just \"Australian_Grand_Prix\"\n",
    "        event_parts = event_name.split(\"_\")\n",
    "        if event_parts[0].isdigit():\n",
    "            round_num = int(event_parts[0])\n",
    "            event_clean = \" \".join(event_parts[1:])\n",
    "        else:\n",
    "            # Try to infer round number from folder order\n",
    "            round_num = len(schedules) + 1\n",
    "            event_clean = \" \".join(event_parts)\n",
    "        \n",
    "        # Try to extract location from event name\n",
    "        # Most events end with \"Grand Prix\", location is usually before that\n",
    "        if \"Grand Prix\" in event_clean or \"Grand_Prix\" in event_name:\n",
    "            location = event_clean.replace(\"Grand Prix\", \"\").strip()\n",
    "        else:\n",
    "            location = event_clean\n",
    "        \n",
    "        schedules.append({\n",
    "            \"event_name\": event_clean,\n",
    "            \"round\": round_num,\n",
    "            \"location\": location,\n",
    "            \"year\": year,\n",
    "            \"folder_name\": folder_name\n",
    "        })\n",
    "    \n",
    "    if not schedules:\n",
    "        print(f\"No race folders found in {year_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(schedules)\n",
    "    # Ensure proper round numbering based on date order\n",
    "    df = df.sort_values(\"folder_name\").reset_index(drop=True)\n",
    "    df[\"round\"] = range(1, len(df) + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    return s.strip().lower()\n",
    "\n",
    "# Unified mapping: Event names, locations, and variations → circuitRef\n",
    "\n",
    "NAME_TO_CIRCUIT = { _norm(k): v for k, v in {\n",
    "    # === GRAND PRIX EVENT NAMES ===\n",
    "    \"australian grand prix\": \"melbourne\",\n",
    "    \"bahrain grand prix\": \"bahrain\",\n",
    "    \"chinese grand prix\": \"shanghai\",\n",
    "    \"azerbaijan grand prix\": \"baku\",\n",
    "    \"azerbaijani grand prix\": \"baku\",\n",
    "    \"spanish grand prix\": \"catalunya\",\n",
    "    \"monaco grand prix\": \"monaco\",\n",
    "    \"canadian grand prix\": \"montreal\",\n",
    "    \"french grand prix\": \"paul-ricard\",\n",
    "    \"austrian grand prix\": \"spielberg\",\n",
    "    \"british grand prix\": \"silverstone\",\n",
    "    \"german grand prix\": \"hockenheimring\",\n",
    "    \"hungarian grand prix\": \"hungaroring\",\n",
    "    \"belgian grand prix\": \"spa-francorchamps\",\n",
    "    \"italian grand prix\": \"monza\",\n",
    "    \"singapore grand prix\": \"marina-bay\",\n",
    "    \"russian grand prix\": \"sochi\",\n",
    "    \"japanese grand prix\": \"suzuka\",\n",
    "    \"united states grand prix\": \"austin\",\n",
    "    \"mexican grand prix\": \"mexico-city\",\n",
    "    \"mexico city grand prix\": \"mexico-city\",\n",
    "    \"brazilian grand prix\": \"interlagos\",\n",
    "    \"abu dhabi grand prix\": \"yas-marina\",\n",
    "    \"saudi arabian grand prix\": \"jeddah\",\n",
    "    \"miami grand prix\": \"miami\",\n",
    "    \"dutch grand prix\": \"zandvoort\",\n",
    "    \"qatar grand prix\": \"lusail\",\n",
    "    \"las vegas grand prix\": \"las-vegas\",\n",
    "    \n",
    "    \"70th anniversary grand prix\": \"silverstone\",\n",
    "    \"styrian grand prix\": \"spielberg\",\n",
    "    \"eifel grand prix\": \"nurburgring\",\n",
    "    \"tuscan grand prix\": \"mugello\",\n",
    "    \"emilia romagna grand prix\": \"imola\",\n",
    "    \"portuguese grand prix\": \"portimao\",\n",
    "    \"turkish grand prix\": \"istanbul\",\n",
    "    \"sakhir grand prix\": \"bahrain\",  \n",
    "    # === LOCATION/CITY NAMES ===\n",
    "    \"melbourne\": \"melbourne\",\n",
    "    \"sakhir\": \"bahrain\",\n",
    "    \"bahrain\": \"bahrain\",\n",
    "    \"shanghai\": \"shanghai\",\n",
    "    \"baku\": \"baku\",\n",
    "    \"barcelona\": \"catalunya\",\n",
    "    \"monaco\": \"monaco\",\n",
    "    \"montreal\": \"montreal\",\n",
    "    \"le castellet\": \"paul-ricard\",\n",
    "    \"spielberg\": \"spielberg\",\n",
    "    \"silverstone\": \"silverstone\",\n",
    "    \"hockenheim\": \"hockenheimring\",\n",
    "    \"budapest\": \"hungaroring\",\n",
    "    \"spa-francorchamps\": \"spa-francorchamps\",\n",
    "    \"zandvoort\": \"zandvoort\",\n",
    "    \"monza\": \"monza\",\n",
    "    \"marina bay\": \"marina-bay\",\n",
    "    \"sochi\": \"sochi\",\n",
    "    \"suzuka\": \"suzuka\",\n",
    "    \"austin\": \"austin\",\n",
    "    \"mexico city\": \"mexico-city\",\n",
    "    \"sao paulo\": \"interlagos\",\n",
    "    \"las vegas\": \"las-vegas\",\n",
    "    \"jeddah\": \"jeddah\",\n",
    "    \"miami\": \"miami\",\n",
    "    \"imola\": \"imola\",\n",
    "    \"portimao\": \"portimao\",\n",
    "    \"istanbul\": \"istanbul\",\n",
    "    \"mugello\": \"mugello\",\n",
    "    \"nurburg\": \"nurburgring\",\n",
    "    \"nuerburg\": \"nurburgring\",\n",
    "    \"lusail\": \"lusail\",\n",
    "    \"yas island\": \"yas-marina\",\n",
    "    \"australian\": \"melbourne\",\n",
    "    \"chinese\": \"shanghai\",\n",
    "    \"hanoi\": \"hanoi\",\n",
    "    \"sepang\": \"sepang\",\n",
    "    \"yeongam\": \"yeongam\",\n",
    "    \"buddh\": \"buddh\",\n",
    "}.items() }\n",
    "\n",
    "# Build schedules for all years 2018-2024 and attach circuitRef\n",
    "# CONFIGURE WHICH YEARS TO PROCESS BASED ON YOUR CACHE\n",
    "# Based on cache analysis: 2018-2021 seem to have complete data\n",
    "# Adjust this range based on what's actually in your cache folder\n",
    "\n",
    "SCHEDULE_YEARS = range(2023, 2026)  # Only process years with complete cache\n",
    "print(f\"\\nConfigured to process years: {list(SCHEDULE_YEARS)}\")\n",
    "print(\"To process more years, check your cache folder and update SCHEDULE_YEARS\")\n",
    "\n",
    "all_schedules = []\n",
    "\n",
    "for year in SCHEDULE_YEARS:\n",
    "    print(f\"\\nReading cache for {year}...\")\n",
    "    schedule = get_race_schedule_from_cache(year, cache_dir=\"./cache\")\n",
    "    \n",
    "    if schedule.empty:\n",
    "        print(f\"No races found for {year}, skipping\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"  ✓ Found {len(schedule)} race folders\")\n",
    "    \n",
    "    # Map using event names first, then try location as fallback\n",
    "    schedule[\"event_norm\"] = schedule[\"event_name\"].map(_norm)\n",
    "    schedule[\"circuitRef\"] = schedule[\"event_norm\"].map(NAME_TO_CIRCUIT)\n",
    "    \n",
    "    # For unmapped, try location\n",
    "    schedule[\"loc_norm\"] = schedule[\"location\"].map(_norm)\n",
    "    schedule[\"circuitRef\"] = schedule[\"circuitRef\"].fillna(\n",
    "        schedule[\"loc_norm\"].map(NAME_TO_CIRCUIT)\n",
    "    )\n",
    "    \n",
    "    # Count how many circuits were successfully mapped\n",
    "    mapped_count = schedule[\"circuitRef\"].notna().sum()\n",
    "    print(f\"  ✓ Mapped {mapped_count}/{len(schedule)} races to circuits\")\n",
    "    \n",
    "    # Show unmapped races for debugging\n",
    "    unmapped = schedule[schedule[\"circuitRef\"].isna()]\n",
    "    if not unmapped.empty:\n",
    "        print(f\"Could not map {len(unmapped)} races:\")\n",
    "        for _, row in unmapped.head(3).iterrows():\n",
    "            print(f\"      Event: '{row['event_name']}' → normalized: '{_norm(row['event_name'])}'\")\n",
    "            print(f\"      Location: '{row['location']}' → normalized: '{_norm(row['location'])}'\")\n",
    "            print(f\"      (Add one of these to NAME_TO_CIRCUIT mapping)\")\n",
    "    \n",
    "    all_schedules.append(schedule)\n",
    "\n",
    "# Concatenate all schedules\n",
    "if not all_schedules:\n",
    "    print(\"\\nERROR: No race schedules found in cache!\")\n",
    "    print(\"Please check:\")\n",
    "    print(\"  1. Cache folder exists: ./cache\")\n",
    "    print(\"  2. Year folders exist (e.g., ./cache/2018/)\")\n",
    "    print(\"  3. Race folders inside year folders\")\n",
    "    raise ValueError(\"No race data found in cache. Cannot proceed.\")\n",
    "\n",
    "schedules_all_years = pd.concat(all_schedules, ignore_index=True)\n",
    "\n",
    "# One row per (year, round)\n",
    "race_keys_all_years = (\n",
    "    schedules_all_years[[\"circuitRef\", \"year\", \"round\"]]\n",
    "      .dropna(subset=[\"circuitRef\"])\n",
    "      .drop_duplicates(subset=[\"year\", \"round\"], keep=\"first\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Drop duplicates to ensure unique circuitRef in specs\n",
    "circuit_specs = circuit_specs.drop_duplicates(subset=[\"circuitRef\"], keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "# Merge with your circuit_specs\n",
    "merged_all_years = pd.merge(circuit_specs, race_keys_all_years, on=\"circuitRef\", how=\"inner\")\n",
    "\n",
    "# Save\n",
    "os.makedirs(\"csv_output\", exist_ok=True)\n",
    "\n",
    "# Reorder & sort by year and round\n",
    "ordered_cols = [\"circuitRef\", \"year\", \"round\"] + [c for c in merged_all_years.columns if c not in [\"circuitRef\", \"year\", \"round\"]]\n",
    "merged_all_years = merged_all_years[ordered_cols].sort_values([\"year\", \"round\"]).reset_index(drop=True)\n",
    "\n",
    "# Create filename based on actual years in data\n",
    "min_year = int(merged_all_years[\"year\"].min())\n",
    "max_year = int(merged_all_years[\"year\"].max())\n",
    "schedule_filename = f\"csv_output/circuit_specs_with_rounds_{min_year}_{max_year}.csv\"\n",
    "merged_all_years.to_csv(schedule_filename, index=False)\n",
    "\n",
    "print(f\"\\n✓ Schedule file saved: {schedule_filename}\")\n",
    "print(f\"  Total race entries: {len(merged_all_years)}\")\n",
    "print(f\"  Years: {min_year}-{max_year}\")\n",
    "print(f\"  Unique circuits: {merged_all_years['circuitRef'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13173d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "circuitRef",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "round",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "countryId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "turns",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_drs_zones",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "71c908ec-6982-4df3-9d03-ae25a7ec24b1",
       "rows": [
        [
         "0",
         "bahrain",
         "2023",
         "1",
         "Bahrain",
         "bahrain",
         "5.412",
         "15",
         "RACE",
         "3"
        ],
        [
         "1",
         "jeddah",
         "2023",
         "2",
         "Jeddah",
         "saudi-arabia",
         "6.174",
         "27",
         "STREET",
         "3"
        ],
        [
         "2",
         "melbourne",
         "2023",
         "3",
         "Melbourne",
         "australia",
         "5.278",
         "14",
         "STREET",
         "4"
        ],
        [
         "3",
         "baku",
         "2023",
         "4",
         "Baku",
         "azerbaijan",
         "6.003",
         "20",
         "STREET",
         "2"
        ],
        [
         "4",
         "miami",
         "2023",
         "5",
         "Miami",
         "united-states-of-america",
         "5.412",
         "19",
         "STREET",
         "3"
        ],
        [
         "5",
         "monaco",
         "2023",
         "6",
         "Monaco",
         "monaco",
         "3.337",
         "19",
         "STREET",
         "1"
        ],
        [
         "6",
         "catalunya",
         "2023",
         "7",
         "Catalunya",
         "spain",
         "4.657",
         "14",
         "RACE",
         "2"
        ],
        [
         "7",
         "montreal",
         "2023",
         "8",
         "Gilles Villeneuve",
         "canada",
         "4.361",
         "13",
         "STREET",
         "3"
        ],
        [
         "8",
         "spielberg",
         "2023",
         "9",
         "Red Bull Ring",
         "austria",
         "4.326",
         "10",
         "RACE",
         "3"
        ],
        [
         "9",
         "silverstone",
         "2023",
         "10",
         "Silverstone",
         "united-kingdom",
         "5.891",
         "18",
         "RACE",
         "2"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circuitRef</th>\n",
       "      <th>year</th>\n",
       "      <th>round</th>\n",
       "      <th>name</th>\n",
       "      <th>countryId</th>\n",
       "      <th>length_km</th>\n",
       "      <th>turns</th>\n",
       "      <th>type</th>\n",
       "      <th>num_drs_zones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bahrain</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>bahrain</td>\n",
       "      <td>5.412</td>\n",
       "      <td>15</td>\n",
       "      <td>RACE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jeddah</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>saudi-arabia</td>\n",
       "      <td>6.174</td>\n",
       "      <td>27</td>\n",
       "      <td>STREET</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>australia</td>\n",
       "      <td>5.278</td>\n",
       "      <td>14</td>\n",
       "      <td>STREET</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baku</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>Baku</td>\n",
       "      <td>azerbaijan</td>\n",
       "      <td>6.003</td>\n",
       "      <td>20</td>\n",
       "      <td>STREET</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miami</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Miami</td>\n",
       "      <td>united-states-of-america</td>\n",
       "      <td>5.412</td>\n",
       "      <td>19</td>\n",
       "      <td>STREET</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>monaco</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>monaco</td>\n",
       "      <td>3.337</td>\n",
       "      <td>19</td>\n",
       "      <td>STREET</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>catalunya</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>Catalunya</td>\n",
       "      <td>spain</td>\n",
       "      <td>4.657</td>\n",
       "      <td>14</td>\n",
       "      <td>RACE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>montreal</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>Gilles Villeneuve</td>\n",
       "      <td>canada</td>\n",
       "      <td>4.361</td>\n",
       "      <td>13</td>\n",
       "      <td>STREET</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spielberg</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>Red Bull Ring</td>\n",
       "      <td>austria</td>\n",
       "      <td>4.326</td>\n",
       "      <td>10</td>\n",
       "      <td>RACE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>silverstone</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>Silverstone</td>\n",
       "      <td>united-kingdom</td>\n",
       "      <td>5.891</td>\n",
       "      <td>18</td>\n",
       "      <td>RACE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    circuitRef  year  round               name                 countryId  \\\n",
       "0      bahrain  2023      1            Bahrain                   bahrain   \n",
       "1       jeddah  2023      2             Jeddah              saudi-arabia   \n",
       "2    melbourne  2023      3          Melbourne                 australia   \n",
       "3         baku  2023      4               Baku                azerbaijan   \n",
       "4        miami  2023      5              Miami  united-states-of-america   \n",
       "5       monaco  2023      6             Monaco                    monaco   \n",
       "6    catalunya  2023      7          Catalunya                     spain   \n",
       "7     montreal  2023      8  Gilles Villeneuve                    canada   \n",
       "8    spielberg  2023      9      Red Bull Ring                   austria   \n",
       "9  silverstone  2023     10        Silverstone            united-kingdom   \n",
       "\n",
       "   length_km  turns    type  num_drs_zones  \n",
       "0      5.412     15    RACE              3  \n",
       "1      6.174     27  STREET              3  \n",
       "2      5.278     14  STREET              4  \n",
       "3      6.003     20  STREET              2  \n",
       "4      5.412     19  STREET              3  \n",
       "5      3.337     19  STREET              1  \n",
       "6      4.657     14    RACE              2  \n",
       "7      4.361     13  STREET              3  \n",
       "8      4.326     10    RACE              3  \n",
       "9      5.891     18    RACE              2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_all_years.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b05b7",
   "metadata": {},
   "source": [
    "# Computing needed metrix to add to the Circuit-specs dataset \n",
    "\n",
    "=> goal is to have a dataset with \n",
    "\n",
    "- Circuitref | year | round | Nane(place) | type of the race | lenghtkm | turns | number of drs zone | slow corners | medium corners | fast corners | averege speed | minimum speed | maximum speed | strraight ratio | corner density | average corner angle | total corner angle | average corner distance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e20ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast F1 cache setup\n",
    "# Use ONLY cached data - no downloads during execution\n",
    "os.makedirs(\"./cache\", exist_ok=True)\n",
    "fastf1.Cache.enable_cache(\"./cache\")\n",
    "\n",
    "# Set offline mode to prevent any network requests\n",
    "# FastF1 will only use data already in the cache\n",
    "\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings about missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b5eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to pick clean fastest lap \n",
    "\n",
    "def _pick_session_fastest_lap(session):\n",
    "    \"\"\"\n",
    "    Return a clean fastest lap (any driver).\n",
    "    - Drops in-/out-laps\n",
    "    - Prefers fully green ('1') laps if TrackStatus exists\n",
    "    \"\"\"\n",
    "    laps = session.laps\n",
    "    if laps is None or laps.empty:\n",
    "        return None\n",
    "\n",
    "    # remove out-/in-laps\n",
    "    laps = laps[(laps[\"PitOutTime\"].isna()) & (laps[\"PitInTime\"].isna())]\n",
    "\n",
    "    # prefer fully green laps if available\n",
    "    if \"TrackStatus\" in laps.columns:\n",
    "        green = laps[\"TrackStatus\"].fillna(\"\").astype(str).str.fullmatch(\"1\")\n",
    "        if green.any():\n",
    "            laps = laps[green]\n",
    "\n",
    "    try:\n",
    "        lap = laps.pick_fastest()\n",
    "        if lap is not None and (\"LapTime\" in lap) and pd.notna(lap[\"LapTime\"]):\n",
    "            return lap\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0484a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_apex_features(tel, corners):\n",
    "    \"\"\"\n",
    "    Compute per-corner apex and classification features.\n",
    "    Returns a DataFrame (apex_geom) with one row per corner.\n",
    "    \n",
    "    Corner classification uses quantile-based thresholds for era-robustness:\n",
    "    - slow:   bottom third of apex speeds\n",
    "    - medium: middle third of apex speeds\n",
    "    - fast:   top third of apex speeds\n",
    "    - flat:   special case for nearly-flat corners (minimal braking, low lateral g)\n",
    "    \"\"\"\n",
    "    CIRCLE_WIN = 35\n",
    "    ENTRY_WIN  = (-180, -15)\n",
    "    EXIT_WIN   = (15, 180)\n",
    "    MIN_WIN    = (-120, 120)\n",
    "    \n",
    "    # Flat corner detection thresholds (relative to max speed)\n",
    "    FLAT_RELATIVE_SPEED = 0.92  # 92% of max lap speed\n",
    "    FLAT_DROP  = 10.0           # Max speed drop (km/h)\n",
    "    FLAT_GMAX  = 2.0            # Max lateral g\n",
    "    \n",
    "    # Quantile boundaries for slow/medium/fast classification\n",
    "    SLOW_QUANTILE = 0.33\n",
    "    FAST_QUANTILE = 0.67\n",
    "\n",
    "    def _scale_xy_to_meters(df):\n",
    "        x, y = df[\"X\"].to_numpy(), df[\"Y\"].to_numpy()\n",
    "        L_xy = np.sum(np.hypot(np.diff(x), np.diff(y)))\n",
    "        L_m  = float(df[\"Distance\"].iloc[-1] - df[\"Distance\"].iloc[0])\n",
    "        scale = L_m / max(L_xy, 1e-9)\n",
    "        df[\"X_m\"] = df[\"X\"] * scale\n",
    "        df[\"Y_m\"] = df[\"Y\"] * scale\n",
    "        return df\n",
    "\n",
    "    def _curvature(df):\n",
    "        s = df[\"Distance\"].to_numpy()\n",
    "        xm = df[\"X_m\"].to_numpy(); ym = df[\"Y_m\"].to_numpy()\n",
    "        dx = np.gradient(xm, s); dy = np.gradient(ym, s)\n",
    "        ddx = np.gradient(dx, s); ddy = np.gradient(dy, s)\n",
    "        kap = (dx*ddy - dy*ddx) / (np.power(dx*dx + dy*dy, 1.5) + 1e-12)\n",
    "        df[\"kap_smooth\"] = pd.Series(kap).rolling(5, center=True, min_periods=1).median()\n",
    "        return df\n",
    "\n",
    "    def _nearest_indices_by_xy(tel, corners):\n",
    "        try:\n",
    "            from scipy.spatial import cKDTree\n",
    "            tree = cKDTree(np.c_[tel[\"X\"], tel[\"Y\"]])\n",
    "            idx0 = [int(tree.query([float(r.X), float(r.Y)], k=1)[1]) for r in corners.itertuples()]\n",
    "        except Exception:\n",
    "            XY = np.c_[tel[\"X\"].to_numpy(), tel[\"Y\"].to_numpy()]\n",
    "            idx0 = [int(np.argmin(np.hypot(XY[:,0]-float(r.X), XY[:,1]-float(r.Y)))) for r in corners.itertuples()]\n",
    "        return pd.DataFrame({\"Number\": corners[\"Number\"].astype(int).to_numpy(), \"idx0\": np.array(idx0)})\n",
    "\n",
    "    def _segment_bounds(idx0, n, pad=150):\n",
    "        b = np.zeros(len(idx0)+1, dtype=int)\n",
    "        b[1:-1] = np.round((idx0[:-1] + idx0[1:]) / 2).astype(int)\n",
    "        b[0] = max(0, idx0[0] - pad)\n",
    "        b[-1] = min(n-1, idx0[-1] + pad)\n",
    "        return b\n",
    "\n",
    "    def _circle_radius(xm, ym):\n",
    "        xm = np.asarray(xm); ym = np.asarray(ym)\n",
    "        x0, y0 = xm.mean(), ym.mean()\n",
    "        X, Y = xm - x0, ym - y0\n",
    "        Z = X*X + Y*Y\n",
    "        A = np.c_[2*X, 2*Y, np.ones_like(X)]\n",
    "        cx, cy, c0 = np.linalg.lstsq(A, Z, rcond=None)[0]\n",
    "        return float(np.sqrt(cx*cx + cy*cy + c0))\n",
    "\n",
    "    def _slice(tel, s0, a, b):\n",
    "        m = (tel[\"Distance\"] >= s0 + a) & (tel[\"Distance\"] <= s0 + b)\n",
    "        return tel.loc[m, [\"Speed\", \"X_m\", \"Y_m\"]]\n",
    "\n",
    "    # Preprocess telemetry\n",
    "    tel = (tel[[\"Distance\", \"Speed\", \"X\", \"Y\"]]\n",
    "           .dropna()\n",
    "           .assign(Speed=lambda d: d[\"Speed\"].rolling(3, center=True, min_periods=1).median()))\n",
    "    tel = _scale_xy_to_meters(tel)\n",
    "    tel = _curvature(tel)\n",
    "    \n",
    "    max_lap_speed = float(tel[\"Speed\"].max())\n",
    "\n",
    "    # Corner segmentation\n",
    "    corner_idx = _nearest_indices_by_xy(tel, corners)\n",
    "    idxs = corner_idx[\"idx0\"].to_numpy()\n",
    "    bounds = _segment_bounds(idxs, len(tel))\n",
    "\n",
    "    # First pass: collect apex data\n",
    "    rows = []\n",
    "    for k in range(len(idxs)):\n",
    "        lo, hi = bounds[k], bounds[k+1]\n",
    "        seg = tel.iloc[lo:hi]\n",
    "        if seg.empty:\n",
    "            continue\n",
    "\n",
    "        idx = seg[\"kap_smooth\"].abs().idxmax()\n",
    "        s_apex = float(tel.at[idx, \"Distance\"])\n",
    "        v_kmh  = float(tel.at[idx, \"Speed\"])\n",
    "\n",
    "        span = _slice(tel, s_apex, -CIRCLE_WIN, CIRCLE_WIN)\n",
    "        if len(span) >= 6:\n",
    "            R = _circle_radius(span[\"X_m\"].to_numpy(), span[\"Y_m\"].to_numpy())\n",
    "            lat_g = ((v_kmh/3.6)**2) / (R * 9.80665)\n",
    "        else:\n",
    "            lat_g = np.nan\n",
    "\n",
    "        ent = _slice(tel, s_apex, *ENTRY_WIN)\n",
    "        exi = _slice(tel, s_apex, *EXIT_WIN)\n",
    "        minw = _slice(tel, s_apex, *MIN_WIN)\n",
    "\n",
    "        entry_speed = float(np.nanpercentile(ent[\"Speed\"], 95)) if not ent.empty else np.nan\n",
    "        exit_speed  = float(np.nanpercentile(exi[\"Speed\"], 95)) if not exi.empty else np.nan\n",
    "        min_speed   = float(minw[\"Speed\"].min()) if not minw.empty else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"Number\": int(corner_idx.iloc[k][\"Number\"]),\n",
    "            \"Distance_apex\": s_apex,\n",
    "            \"apex_speed_kmh\": v_kmh,\n",
    "            \"apex_lateral_g\": lat_g,\n",
    "            \"entry_speed_kmh\": entry_speed,\n",
    "            \"min_speed_kmh\": min_speed,\n",
    "            \"exit_speed_kmh\": exit_speed,\n",
    "        })\n",
    "    \n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"Number\", \"Distance_apex\", \"apex_speed_kmh\", \"apex_lateral_g\",\n",
    "            \"entry_speed_kmh\", \"min_speed_kmh\", \"exit_speed_kmh\", \"corner_type_speed\"\n",
    "        ])\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Second pass: compute quantile-based classification\n",
    "    apex_speeds = df[\"apex_speed_kmh\"].to_numpy()\n",
    "    q_slow = np.nanpercentile(apex_speeds, SLOW_QUANTILE * 100)\n",
    "    q_fast = np.nanpercentile(apex_speeds, FAST_QUANTILE * 100)\n",
    "    flat_threshold = max_lap_speed * FLAT_RELATIVE_SPEED\n",
    "    \n",
    "    def _classify_corner(row):\n",
    "        v = row[\"apex_speed_kmh\"]\n",
    "        entry = row[\"entry_speed_kmh\"]\n",
    "        min_spd = row[\"min_speed_kmh\"]\n",
    "        lat_g = row[\"apex_lateral_g\"]\n",
    "        \n",
    "        # Check for flat corner (taken nearly flat-out with minimal braking)\n",
    "        if (v >= flat_threshold and \n",
    "            np.isfinite(min_spd) and np.isfinite(entry) and\n",
    "            (entry - min_spd) <= FLAT_DROP and \n",
    "            lat_g < FLAT_GMAX):\n",
    "            return \"flat\"\n",
    "        \n",
    "        # Quantile-based classification\n",
    "        if v <= q_slow:\n",
    "            return \"slow\"\n",
    "        elif v >= q_fast:\n",
    "            return \"fast\"\n",
    "        else:\n",
    "            return \"medium\"\n",
    "    \n",
    "    df[\"corner_type_speed\"] = df.apply(_classify_corner, axis=1)\n",
    "    \n",
    "    return df.sort_values(\"Number\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98f8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute circuit summary features\n",
    "\n",
    "def summarize_circuit(year, circuit_name, official_length_km=None, curvature_threshold=0.0010):\n",
    "    \"\"\"\n",
    "    Uses race fastest lap (any driver); if none usable, falls back to qualifying fastest.\n",
    "    - straights via curvature-based detection (geometrically correct)\n",
    "    - wrap-around spacing (last -> start/finish)\n",
    "    - robust lap distance via Distance diffs\n",
    "    \n",
    "    NOTE: This function expects data to be pre-cached. It will use ONLY cached data.\n",
    "    \n",
    "    Args:\n",
    "        curvature_threshold: Sections with |curvature| < threshold are considered straights.\n",
    "                           Default 0.0010 m^-1 corresponds to radius > 1000m\n",
    "    \"\"\"\n",
    "    \n",
    "    def _compute_curvature(tel):\n",
    "        \"\"\"Compute curvature from X,Y coordinates scaled to meters.\"\"\"\n",
    "        # Scale X,Y to meters\n",
    "        x, y = tel[\"X\"].to_numpy(), tel[\"Y\"].to_numpy()\n",
    "        L_xy = np.sum(np.hypot(np.diff(x), np.diff(y)))\n",
    "        L_m = float(tel[\"Distance\"].iloc[-1] - tel[\"Distance\"].iloc[0])\n",
    "        scale = L_m / max(L_xy, 1e-9)\n",
    "        \n",
    "        xm = x * scale\n",
    "        ym = y * scale\n",
    "        s = tel[\"Distance\"].to_numpy()\n",
    "        \n",
    "        # Compute curvature: κ = |x'y'' - y'x''| / (x'^2 + y'^2)^(3/2)\n",
    "        dx = np.gradient(xm, s)\n",
    "        dy = np.gradient(ym, s)\n",
    "        ddx = np.gradient(dx, s)\n",
    "        ddy = np.gradient(dy, s)\n",
    "        \n",
    "        kap = (dx * ddy - dy * ddx) / (np.power(dx*dx + dy*dy, 1.5) + 1e-12)\n",
    "        \n",
    "        # Smooth to reduce noise\n",
    "        kap_smooth = pd.Series(np.abs(kap)).rolling(7, center=True, min_periods=1).median()\n",
    "        \n",
    "        return kap_smooth.to_numpy()\n",
    "    \n",
    "    # Race session - load from cache only\n",
    "    try:\n",
    "        session = fastf1.get_session(year, circuit_name, \"R\")\n",
    "        session.load(telemetry=True, weather=False, messages=False)\n",
    "        fastest_lap = _pick_session_fastest_lap(session)\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not load race session from cache for {circuit_name} {year}: {e}\")\n",
    "        fastest_lap = None\n",
    "\n",
    "    # Fallback to qualifying if needed\n",
    "    if fastest_lap is None:\n",
    "        try:\n",
    "            session_q = fastf1.get_session(year, circuit_name, \"Q\")\n",
    "            session_q.load(telemetry=True, weather=False, messages=False)\n",
    "            fastest_lap = _pick_session_fastest_lap(session_q)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not load qualifying session from cache for {circuit_name} {year}: {e}\")\n",
    "\n",
    "    if fastest_lap is None:\n",
    "        raise RuntimeError(f\"No usable lap found in cache for {circuit_name} {year}. Make sure data is pre-cached.\")\n",
    "\n",
    "    # Telemetry + robust distance\n",
    "    try:\n",
    "        tel = fastest_lap.get_telemetry()\n",
    "        if tel is None or tel.empty:\n",
    "            raise RuntimeError(f\"Telemetry data is empty for {circuit_name} {year}\")\n",
    "        tel = tel.add_distance()\n",
    "    except AttributeError as e:\n",
    "        raise RuntimeError(f\"Failed to get telemetry for {circuit_name} {year}: fastest_lap is None or invalid\")\n",
    "    tel = tel[[\"Distance\", \"Speed\", \"X\", \"Y\"]].dropna().reset_index(drop=True)\n",
    "    \n",
    "    d_step = tel[\"Distance\"].diff().clip(lower=0).fillna(0.0)\n",
    "    lap_distance_m = float(d_step.sum())\n",
    "\n",
    "    telemetry_length_km = lap_distance_m / 1000.0\n",
    "    length_km = float(official_length_km) if official_length_km is not None else telemetry_length_km\n",
    "\n",
    "    # Straights by curvature (geometrically correct)\n",
    "    curvature = _compute_curvature(tel)\n",
    "    is_straight = curvature < curvature_threshold\n",
    "    straight_distance_m = float(d_step.where(is_straight).sum())\n",
    "    straight_ratio = straight_distance_m / lap_distance_m if lap_distance_m > 0 else 0.0\n",
    "    \n",
    "    # Identify contiguous straight segments\n",
    "    MIN_STRAIGHT_LEN = 70.0  # meters - drop noise segments shorter than this\n",
    "    MAJOR_STRAIGHT_THRESHOLD = 700.0  # meters\n",
    "    \n",
    "    s = tel[\"Distance\"].to_numpy()\n",
    "    mask = is_straight.to_numpy() if isinstance(is_straight, pd.Series) else is_straight\n",
    "    \n",
    "    # Find transitions in the mask\n",
    "    changes = np.where(np.diff(mask.astype(int)) != 0)[0] + 1\n",
    "    starts = np.concatenate([[0], changes])\n",
    "    ends = np.concatenate([changes, [len(s)]])\n",
    "    \n",
    "    # Keep only straight segments (where mask is True at segment start)\n",
    "    straight_segments = []\n",
    "    for i in range(len(starts)):\n",
    "        if mask[starts[i]]:\n",
    "            seg_start_idx = starts[i]\n",
    "            seg_end_idx = ends[i] - 1  # inclusive end\n",
    "            seg_len = s[seg_end_idx] - s[seg_start_idx]\n",
    "            if seg_len >= MIN_STRAIGHT_LEN:  # filter out noise\n",
    "                straight_segments.append({\n",
    "                    'start_idx': seg_start_idx,\n",
    "                    'end_idx': seg_end_idx,\n",
    "                    'start_dist': s[seg_start_idx],\n",
    "                    'end_dist': s[seg_end_idx],\n",
    "                    'length': seg_len\n",
    "                })\n",
    "    \n",
    "    # Handle wrap-around: if lap starts and ends on a straight, merge them\n",
    "    if len(straight_segments) >= 2 and mask[0] and mask[-1]:\n",
    "        first_seg = straight_segments[0]\n",
    "        last_seg = straight_segments[-1]\n",
    "        \n",
    "        # Merged length spans end of lap to start\n",
    "        wrap_length = (s[-1] - last_seg['start_dist']) + (first_seg['end_dist'] - s[0])\n",
    "        \n",
    "        if wrap_length >= MIN_STRAIGHT_LEN:\n",
    "            # Replace first and last with merged segment\n",
    "            merged_seg = {\n",
    "                'start_idx': last_seg['start_idx'],\n",
    "                'end_idx': first_seg['end_idx'],\n",
    "                'start_dist': last_seg['start_dist'],\n",
    "                'end_dist': first_seg['end_dist'],\n",
    "                'length': wrap_length,\n",
    "                'is_wraparound': True\n",
    "            }\n",
    "            straight_segments = [merged_seg] + straight_segments[1:-1]\n",
    "        else:\n",
    "            # If merged segment too short, drop both\n",
    "            straight_segments = straight_segments[1:-1]\n",
    "    \n",
    "    # Compute metrics\n",
    "    if straight_segments:\n",
    "        lengths = np.array([seg['length'] for seg in straight_segments])\n",
    "        straight_len_max_m = float(np.max(lengths))\n",
    "        n_major_straights = int(np.sum(lengths >= MAJOR_STRAIGHT_THRESHOLD))\n",
    "        \n",
    "        # Find longest straight for potential future use (DRS, heavy braking)\n",
    "        idx_longest = int(np.argmax(lengths))\n",
    "        longest_straight = straight_segments[idx_longest]\n",
    "    else:\n",
    "        straight_len_max_m = 0.0\n",
    "        n_major_straights = 0\n",
    "        longest_straight = None\n",
    "\n",
    "    # Corner info\n",
    "    try:\n",
    "        circuit_info = session.get_circuit_info()\n",
    "        corners = circuit_info.corners.copy()\n",
    "        if not corners.empty:\n",
    "            corners = corners.sort_values(\"Distance\").reset_index(drop=True)\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not load circuit info for {circuit_name} {year}: {e}\")\n",
    "        corners = pd.DataFrame()\n",
    "\n",
    "    if corners.empty:\n",
    "        raise RuntimeError(f\"No corner data available for {circuit_name} {year}\")\n",
    "    \n",
    "    apex_geom = extract_apex_features(tel, corners)\n",
    "    counts = apex_geom[\"corner_type_speed\"].value_counts()\n",
    "    slow = int(counts.get(\"slow\", 0))\n",
    "    medium = int(counts.get(\"medium\", 0))\n",
    "    fast = int(counts.get(\"fast\", 0))\n",
    "    flat = int(counts.get(\"flat\", 0))\n",
    "    \n",
    "    # Slow corner cluster analysis (longest consecutive slow section)\n",
    "    if not apex_geom.empty and slow > 0:\n",
    "        # Sort by lap position\n",
    "        apex_sorted = apex_geom.sort_values(\"Distance_apex\").reset_index(drop=True)\n",
    "        corner_types = apex_sorted[\"corner_type_speed\"].to_numpy()\n",
    "        \n",
    "        # Find runs of consecutive \"slow\" corners\n",
    "        is_slow = (corner_types == \"slow\")\n",
    "        \n",
    "        # Detect run boundaries\n",
    "        changes = np.concatenate([[0], np.where(np.diff(is_slow.astype(int)) != 0)[0] + 1, [len(is_slow)]])\n",
    "        \n",
    "        slow_runs = []\n",
    "        for i in range(len(changes) - 1):\n",
    "            start_idx = changes[i]\n",
    "            end_idx = changes[i + 1]\n",
    "            if is_slow[start_idx]:  # This run is slow corners\n",
    "                run_length = end_idx - start_idx\n",
    "                slow_runs.append(run_length)\n",
    "        \n",
    "        # Handle wrap-around: if lap starts AND ends with slow, merge those runs\n",
    "        if len(slow_runs) >= 2 and is_slow[0] and is_slow[-1]:\n",
    "            # First and last runs are both slow and should be merged\n",
    "            wrapped_run = slow_runs[0] + slow_runs[-1]\n",
    "            slow_runs = [wrapped_run] + slow_runs[1:-1]\n",
    "        \n",
    "        slow_cluster_max = int(max(slow_runs)) if slow_runs else 0\n",
    "    else:\n",
    "        slow_cluster_max = 0\n",
    "\n",
    "    # Heavy-braking analysis\n",
    "    HEAVY_BRAKE_THRESHOLD = 110.0  # km/h\n",
    "    BRAKE_ZONE_PROXIMITY = 80.0    # meters after straight end\n",
    "    \n",
    "    if not apex_geom.empty:\n",
    "        # Compute delta-v for each corner\n",
    "        apex_geom[\"delta_v\"] = apex_geom[\"entry_speed_kmh\"] - apex_geom[\"min_speed_kmh\"]\n",
    "        \n",
    "        # Identify heavy braking corners\n",
    "        hb_mask = apex_geom[\"delta_v\"] >= HEAVY_BRAKE_THRESHOLD\n",
    "        hb_corners = apex_geom[hb_mask].copy()\n",
    "        \n",
    "        heavy_braking_zones = int(hb_mask.sum())\n",
    "        \n",
    "        if heavy_braking_zones > 0:\n",
    "            heavy_braking_mean_dv_kmh = float(hb_corners[\"delta_v\"].mean())\n",
    "            \n",
    "            # Spacing between heavy-brake corners (with wrap-around)\n",
    "            hb_distances = np.sort(hb_corners[\"Distance_apex\"].to_numpy())\n",
    "            if len(hb_distances) >= 2:\n",
    "                hb_spacings = np.diff(np.r_[hb_distances, hb_distances[0] + lap_distance_m])\n",
    "                hb_spacing_std_m = float(np.std(hb_spacings))\n",
    "            else:\n",
    "                hb_spacing_std_m = np.nan\n",
    "            \n",
    "            # Check if heavy-brake follows longest straight\n",
    "            hb_at_end_of_max = False\n",
    "            if longest_straight is not None:\n",
    "                straight_end = longest_straight['end_dist']\n",
    "                # Handle wrap-around case\n",
    "                if longest_straight.get('is_wraparound', False):\n",
    "                    # Wrapped straight: check both near end_dist and near start (distance 0)\n",
    "                    for hb_dist in hb_distances:\n",
    "                        # Check proximity to end of wrapped segment (which is near start)\n",
    "                        dist_from_end = min(\n",
    "                            abs(hb_dist - straight_end),\n",
    "                            abs(hb_dist - straight_end + lap_distance_m),\n",
    "                            abs(hb_dist - straight_end - lap_distance_m)\n",
    "                        )\n",
    "                        if dist_from_end <= BRAKE_ZONE_PROXIMITY:\n",
    "                            hb_at_end_of_max = True\n",
    "                            break\n",
    "                else:\n",
    "                    # Normal straight: simple check with wrap\n",
    "                    for hb_dist in hb_distances:\n",
    "                        dist_from_end = hb_dist - straight_end\n",
    "                        # Handle wrap-around: if straight ends near finish line\n",
    "                        if dist_from_end < 0:\n",
    "                            dist_from_end += lap_distance_m\n",
    "                        if 0 <= dist_from_end <= BRAKE_ZONE_PROXIMITY:\n",
    "                            hb_at_end_of_max = True\n",
    "                            break\n",
    "        else:\n",
    "            heavy_braking_mean_dv_kmh = np.nan\n",
    "            hb_spacing_std_m = np.nan\n",
    "            hb_at_end_of_max = False\n",
    "    else:\n",
    "        heavy_braking_zones = 0\n",
    "        heavy_braking_mean_dv_kmh = np.nan\n",
    "        hb_spacing_std_m = np.nan\n",
    "        hb_at_end_of_max = False\n",
    "\n",
    "    total_angle = float(corners[\"Angle\"].sum()) if not corners.empty else np.nan\n",
    "    avg_angle = float(corners[\"Angle\"].mean()) if not corners.empty else np.nan\n",
    "\n",
    "    # Corner density (turns per kilometer)\n",
    "    corner_density_tpkm = len(corners) / length_km if (not corners.empty and length_km > 0) else np.nan\n",
    "    \n",
    "    # Wrap-around spacing\n",
    "    if not corners.empty and lap_distance_m > 0:\n",
    "        s = np.sort(corners[\"Distance\"].to_numpy(dtype=float))\n",
    "        spacings = np.diff(np.r_[s, s[0] + lap_distance_m])  # include last -> start/finish\n",
    "        avg_corner_distance = float(np.mean(spacings))\n",
    "    else:\n",
    "        avg_corner_distance = np.nan\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        \"circuitRef\": circuit_name.lower(),\n",
    "        \"length_km\": round(length_km, 3),\n",
    "        \"num_turns\": int(len(corners)),\n",
    "        \"slow_corners\": slow,\n",
    "        \"medium_corners\": medium,\n",
    "        \"fast_corners\": fast,\n",
    "        \"flat_corners\": flat,\n",
    "        \"slow_cluster_max\": slow_cluster_max,\n",
    "        \"straight_distance_m\": round(straight_distance_m, 1),\n",
    "        \"straight_ratio\": round(straight_ratio, 3),\n",
    "        \"straight_len_max_m\": round(straight_len_max_m, 1),\n",
    "        \"n_major_straights\": n_major_straights,\n",
    "        \"heavy_braking_zones\": heavy_braking_zones,\n",
    "        \"heavy_braking_mean_dv_kmh\": round(heavy_braking_mean_dv_kmh, 1) if np.isfinite(heavy_braking_mean_dv_kmh) else np.nan,\n",
    "        \"hb_spacing_std_m\": round(hb_spacing_std_m, 1) if np.isfinite(hb_spacing_std_m) else np.nan,\n",
    "        \"hb_at_end_of_max\": hb_at_end_of_max,\n",
    "        \"corner_density_tpkm\": round(corner_density_tpkm, 2) if np.isfinite(corner_density_tpkm) else np.nan,\n",
    "        \"avg_corner_angle\": round(avg_angle, 1) if np.isfinite(avg_angle) else np.nan,\n",
    "        \"total_corner_angle\": round(total_angle, 1) if np.isfinite(total_angle) else np.nan,\n",
    "        \"avg_corner_distance\": round(avg_corner_distance, 1) if np.isfinite(avg_corner_distance) else np.nan\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c669ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROCESSING CACHED DATA - No downloads will occur\n",
      "======================================================================\n",
      "\n",
      "[1/66] Processing: 2023 Round  1 - Bahrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Bahrain Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '14', '55', '44', '18', '63', '77', '10', '23', '22', '2', '20', '21', '27', '24', '4', '31', '16', '81']\n",
      "core           INFO \tLoading data for Saudi Arabian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[2/66] Processing: 2023 Round  2 - Jeddah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 11 completed the race distance 00:00.035000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['11', '1', '14', '63', '44', '55', '16', '31', '10', '20', '22', '27', '24', '21', '81', '2', '4', '77', '23', '18']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[3/66] Processing: 2023 Round  3 - Melbourne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '44', '14', '18', '11', '4', '27', '81', '24', '22', '77', '55', '10', '31', '21', '2', '20', '63', '23', '16']\n",
      "core           INFO \tLoading data for Azerbaijan Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[4/66] Processing: 2023 Round  4 - Baku\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['11', '1', '16', '14', '55', '44', '18', '63', '4', '22', '81', '23', '20', '10', '31', '2', '27', '77', '24', '21']\n",
      "core           INFO \tLoading data for Miami Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[5/66] Processing: 2023 Round  5 - Miami\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '14', '63', '55', '44', '16', '10', '31', '20', '22', '18', '77', '23', '27', '24', '4', '21', '81', '2']\n",
      "core           INFO \tLoading data for Monaco Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[6/66] Processing: 2023 Round  6 - Monaco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '14', '31', '44', '63', '16', '10', '55', '4', '81', '77', '21', '24', '23', '22', '11', '27', '2', '20', '18']\n",
      "events      WARNING \tCorrecting user input 'Catalunya' to 'Italian Grand Prix'\n",
      "core           INFO \tLoading data for Italian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[7/66] Processing: 2023 Round  7 - Catalunya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 1 completed the race distance 06:25.888000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 11 completed the race distance 06:19.824000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 55 completed the race distance 06:14.695000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 16 completed the race distance 06:14.511000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 63 completed the race distance 06:07.860000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 44 completed the race distance 05:48.209000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 23 completed the race distance 05:40.782000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 4 completed the race distance 05:40.439000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 14 completed the race distance 05:39.594000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '55', '16', '63', '44', '23', '4', '14', '77', '40', '81', '2', '24', '10', '18', '27', '20', '31', '22']\n",
      "events      WARNING \tCorrecting user input 'Montreal' to 'Canadian Grand Prix'\n",
      "core           INFO \tLoading data for Canadian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '22'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[8/66] Processing: 2023 Round  8 - Gilles Villeneuve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '14', '44', '16', '55', '11', '23', '31', '18', '77', '81', '10', '4', '22', '27', '24', '20', '21', '63', '2']\n",
      "core           INFO \tLoading data for Austrian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[9/66] Processing: 2023 Round  9 - Red Bull Ring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '16', '11', '4', '14', '55', '63', '44', '18', '10', '23', '24', '2', '31', '77', '81', '21', '20', '22', '27']\n",
      "core           INFO \tLoading data for British Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[10/66] Processing: 2023 Round 10 - Silverstone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '44', '81', '63', '11', '14', '23', '16', '55', '2', '77', '27', '18', '24', '22', '21', '10', '20', '31']\n",
      "events      WARNING \tCorrecting user input 'Hungaroring' to 'Hungarian Grand Prix'\n",
      "core           INFO \tLoading data for Hungarian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[11/66] Processing: 2023 Round 11 - Hungaroring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '11', '44', '81', '63', '16', '55', '14', '18', '23', '77', '3', '27', '22', '24', '20', '2', '31', '10']\n",
      "core           INFO \tLoading data for Belgian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[12/66] Processing: 2023 Round 12 - Spa-Francorchamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '16', '44', '14', '63', '4', '31', '18', '22', '10', '77', '24', '23', '20', '3', '2', '27', '55', '81']\n",
      "core           INFO \tLoading data for Dutch Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[13/66] Processing: 2023 Round 13 - Zandvoort\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 1 completed the race distance 00:02.059000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '14', '10', '11', '55', '44', '4', '23', '81', '31', '18', '27', '40', '77', '22', '20', '63', '24', '16', '2']\n",
      "core           INFO \tLoading data for Italian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[14/66] Processing: 2023 Round 14 - Monza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 1 completed the race distance 06:25.888000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 11 completed the race distance 06:19.824000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 55 completed the race distance 06:14.695000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 16 completed the race distance 06:14.511000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 63 completed the race distance 06:07.860000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 44 completed the race distance 05:48.209000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 23 completed the race distance 05:40.782000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 4 completed the race distance 05:40.439000 before the recorded end of the session.\n",
      "core        WARNING \tDriver 14 completed the race distance 05:39.594000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '55', '16', '63', '44', '23', '4', '14', '77', '40', '81', '2', '24', '10', '18', '27', '20', '31', '22']\n",
      "events      WARNING \tCorrecting user input 'Marina-bay' to 'Singapore Grand Prix'\n",
      "core           INFO \tLoading data for Singapore Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[15/66] Processing: 2023 Round 15 - Marina Bay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tNo lap data for driver 18\n",
      "core        WARNING \tFailed to perform lap accuracy check - all laps marked as inaccurate (driver 18)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['55', '4', '44', '16', '1', '10', '81', '11', '40', '20', '23', '24', '27', '2', '14', '63', '77', '31', '22', '18']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[16/66] Processing: 2023 Round 16 - Suzuka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 1 completed the race distance 00:00.076000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '16', '44', '55', '63', '14', '31', '10', '40', '22', '24', '27', '20', '23', '2', '18', '11', '77']\n",
      "core           INFO \tLoading data for Qatar Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[17/66] Processing: 2023 Round 17 - Lusail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tNo lap data for driver 55\n",
      "core        WARNING \tFailed to perform lap accuracy check - all laps marked as inaccurate (driver 55)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '81', '4', '63', '16', '14', '31', '77', '24', '11', '18', '10', '23', '20', '22', '27', '40', '2', '44', '55']\n",
      "core           INFO \tLoading data for United States Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[18/66] Processing: 2023 Round 18 - Americas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '55', '11', '63', '10', '18', '22', '23', '2', '27', '77', '24', '20', '3', '14', '81', '31', '44', '16']\n",
      "events      WARNING \tCorrecting user input 'Mexico-city' to 'Mexico City Grand Prix'\n",
      "core           INFO \tLoading data for Mexico City Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[19/66] Processing: 2023 Round 19 - Hermanos Rodríguez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '44', '16', '55', '4', '63', '3', '81', '23', '31', '10', '22', '27', '24', '77', '2', '18', '14', '20', '11']\n",
      "events      WARNING \tCorrecting user input 'Interlagos' to 'Dutch Grand Prix'\n",
      "core           INFO \tLoading data for Dutch Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[20/66] Processing: 2023 Round 20 - José Carlos Pace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 1 completed the race distance 00:02.059000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '14', '10', '11', '55', '44', '4', '23', '81', '31', '18', '27', '40', '77', '22', '20', '63', '24', '16', '2']\n",
      "events      WARNING \tCorrecting user input 'Las-vegas' to 'Las Vegas Grand Prix'\n",
      "core           INFO \tLoading data for Las Vegas Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[21/66] Processing: 2023 Round 21 - Las Vegas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 1 completed the race distance 00:00.001000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '16', '11', '31', '18', '55', '44', '63', '14', '81', '10', '23', '20', '3', '24', '2', '77', '22', '27', '4']\n",
      "events      WARNING \tCorrecting user input 'Yas-marina' to 'Singapore Grand Prix'\n",
      "core           INFO \tLoading data for Singapore Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tNo lap data for driver 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[22/66] Processing: 2023 Round 22 - Yas Marina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tFailed to perform lap accuracy check - all laps marked as inaccurate (driver 18)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['55', '4', '44', '16', '1', '10', '81', '11', '40', '20', '23', '24', '27', '2', '14', '63', '77', '31', '22', '18']\n",
      "core           INFO \tLoading data for Bahrain Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[23/66] Processing: 2024 Round  1 - Bahrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '55', '16', '63', '4', '44', '81', '14', '18', '24', '20', '3', '22', '23', '27', '31', '10', '77', '2']\n",
      "core           INFO \tLoading data for Saudi Arabian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[24/66] Processing: 2024 Round  2 - Jeddah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '16', '81', '14', '63', '38', '4', '44', '27', '23', '20', '31', '2', '22', '3', '77', '24', '18', '10']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[25/66] Processing: 2024 Round  3 - Melbourne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 19 drivers: ['55', '16', '4', '81', '11', '18', '22', '14', '27', '20', '23', '3', '10', '77', '24', '31', '63', '44', '1']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[26/66] Processing: 2024 Round  4 - Suzuka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '55', '16', '4', '14', '63', '81', '44', '22', '27', '18', '20', '77', '31', '10', '2', '24', '3', '23']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[27/66] Processing: 2024 Round  5 - Shanghai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 1 completed the race distance 00:08.313000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '11', '16', '55', '63', '14', '81', '44', '27', '31', '23', '10', '24', '18', '20', '2', '3', '22', '77']\n",
      "core           INFO \tLoading data for Miami Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[28/66] Processing: 2024 Round  6 - Miami\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '16', '11', '55', '44', '22', '63', '14', '31', '27', '10', '81', '24', '3', '77', '18', '23', '20', '2']\n",
      "core           INFO \tLoading data for Emilia Romagna Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[29/66] Processing: 2024 Round  7 - Enzo e Dino Ferrari\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '16', '81', '55', '44', '63', '11', '18', '22', '27', '20', '3', '31', '24', '10', '2', '77', '14', '23']\n",
      "core           INFO \tLoading data for Monaco Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[30/66] Processing: 2024 Round  8 - Monaco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '81', '55', '4', '63', '1', '44', '22', '23', '10', '14', '3', '77', '18', '2', '24', '31', '11', '27', '20']\n",
      "events      WARNING \tCorrecting user input 'Montreal' to 'Canadian Grand Prix'\n",
      "core           INFO \tLoading data for Canadian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[31/66] Processing: 2024 Round  9 - Gilles Villeneuve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '63', '44', '81', '14', '18', '3', '10', '31', '27', '20', '77', '22', '24', '55', '23', '11', '16', '2']\n",
      "events      WARNING \tCorrecting user input 'Catalunya' to 'Australian Grand Prix'\n",
      "core           INFO \tLoading data for Australian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[32/66] Processing: 2024 Round 10 - Catalunya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 19 drivers: ['55', '16', '4', '81', '11', '18', '22', '14', '27', '20', '23', '3', '10', '77', '24', '31', '63', '44', '1']\n",
      "core           INFO \tLoading data for Austrian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[33/66] Processing: 2024 Round 11 - Red Bull Ring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '81', '55', '44', '1', '27', '11', '20', '3', '10', '16', '31', '18', '22', '23', '77', '24', '14', '2', '4']\n",
      "core           INFO \tLoading data for British Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[34/66] Processing: 2024 Round 12 - Silverstone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '1', '4', '81', '55', '27', '18', '14', '23', '22', '2', '20', '3', '16', '77', '31', '11', '24', '63', '10']\n",
      "events      WARNING \tCorrecting user input 'Hungaroring' to 'Hungarian Grand Prix'\n",
      "core           INFO \tLoading data for Hungarian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[35/66] Processing: 2024 Round 13 - Hungaroring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '44', '16', '1', '55', '11', '63', '22', '18', '14', '3', '27', '23', '20', '77', '2', '31', '24', '10']\n",
      "core           INFO \tLoading data for Belgian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '14'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '3'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '18'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '22'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[36/66] Processing: 2024 Round 14 - Spa-Francorchamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '81', '16', '1', '4', '55', '11', '14', '31', '3', '18', '23', '10', '20', '77', '22', '2', '27', '24', '63']\n",
      "core           INFO \tLoading data for Dutch Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[37/66] Processing: 2024 Round 15 - Zandvoort\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '16', '81', '55', '11', '63', '44', '10', '14', '27', '3', '18', '23', '31', '2', '22', '20', '77', '24']\n",
      "core           INFO \tLoading data for Italian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[38/66] Processing: 2024 Round 16 - Monza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '81', '4', '55', '44', '1', '63', '11', '23', '20', '14', '43', '3', '31', '10', '77', '27', '24', '18', '22']\n",
      "core           INFO \tLoading data for Azerbaijan Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[39/66] Processing: 2024 Round 17 - Baku\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '16', '63', '4', '1', '14', '23', '43', '44', '50', '27', '10', '3', '24', '31', '77', '11', '55', '18', '22']\n",
      "events      WARNING \tCorrecting user input 'Marina-bay' to 'Singapore Grand Prix'\n",
      "core           INFO \tLoading data for Singapore Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[40/66] Processing: 2024 Round 18 - Marina Bay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '81', '63', '16', '44', '55', '14', '27', '11', '43', '22', '31', '18', '24', '77', '10', '3', '20', '23']\n",
      "core           INFO \tLoading data for United States Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[41/66] Processing: 2024 Round 19 - Americas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '55', '1', '4', '81', '63', '11', '27', '30', '43', '20', '10', '14', '22', '18', '23', '77', '31', '24', '44']\n",
      "events      WARNING \tCorrecting user input 'Mexico-city' to 'Mexico City Grand Prix'\n",
      "core           INFO \tLoading data for Mexico City Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[42/66] Processing: 2024 Round 20 - Hermanos Rodríguez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['55', '4', '16', '44', '63', '1', '20', '81', '27', '10', '18', '43', '31', '77', '24', '30', '11', '14', '23', '22']\n",
      "events      WARNING \tCorrecting user input 'Interlagos' to 'Dutch Grand Prix'\n",
      "core           INFO \tLoading data for Dutch Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[43/66] Processing: 2024 Round 21 - José Carlos Pace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '16', '81', '55', '11', '63', '44', '10', '14', '27', '3', '18', '23', '31', '2', '22', '20', '77', '24']\n",
      "events      WARNING \tCorrecting user input 'Las-vegas' to 'Las Vegas Grand Prix'\n",
      "core           INFO \tLoading data for Las Vegas Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[44/66] Processing: 2024 Round 22 - Las Vegas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tDriver 63: Lap timing integrity check failed for 2 lap(s)\n",
      "core        WARNING \tDriver 44: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver 55: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver 16: Lap timing integrity check failed for 2 lap(s)\n",
      "core        WARNING \tDriver  1: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver  4: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver 81: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver 30: Lap timing integrity check failed for 2 lap(s)\n",
      "core        WARNING \tDriver 77: Lap timing integrity check failed for 2 lap(s)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 63 completed the race distance 00:00.427000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '44', '55', '16', '1', '4', '81', '27', '22', '11', '14', '20', '24', '43', '18', '30', '31', '77', '23', '10']\n",
      "core           INFO \tLoading data for Qatar Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[45/66] Processing: 2024 Round 23 - Lusail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tFixed incorrect tyre stint information for driver '43'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '31'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '16', '81', '63', '10', '55', '14', '24', '20', '4', '77', '44', '22', '30', '23', '27', '11', '18', '43', '31']\n",
      "events      WARNING \tCorrecting user input 'Yas-marina' to 'Singapore Grand Prix'\n",
      "core           INFO \tLoading data for Singapore Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[46/66] Processing: 2024 Round 24 - Yas Marina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '81', '63', '16', '44', '55', '14', '27', '11', '43', '22', '31', '18', '24', '77', '10', '3', '20', '23']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[47/66] Processing: 2025 Round  1 - Melbourne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '87'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '30'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 4 completed the race distance 00:00.022000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '63', '12', '23', '18', '27', '16', '81', '44', '10', '22', '31', '87', '30', '5', '14', '55', '7', '6']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/2/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/2/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[48/66] Processing: 2025 Round  2 - Shanghai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/2/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/2/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '63', '1', '31', '12', '23', '87', '18', '55', '6', '30', '7', '5', '27', '22', '14', '16', '44', '10']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/3/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/3/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[49/66] Processing: 2025 Round  3 - Suzuka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '16', '63', '12', '44', '6', '23', '87', '14', '22', '10', '55', '7', '27', '30', '31', '5', '18']\n",
      "core           INFO \tLoading data for Bahrain Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/4/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/4/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[50/66] Processing: 2025 Round  4 - Bahrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/4/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/4/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '63', '4', '16', '44', '1', '10', '31', '22', '87', '12', '23', '6', '7', '14', '30', '18', '5', '55', '27']\n",
      "core           INFO \tLoading data for Saudi Arabian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/5/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/5/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[51/66] Processing: 2025 Round  5 - Jeddah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '1', '16', '4', '63', '12', '44', '55', '23', '6', '14', '30', '87', '31', '27', '18', '7', '5', '22', '10']\n",
      "core           INFO \tLoading data for Miami Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/6/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/6/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '6'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '31'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '18'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[52/66] Processing: 2025 Round  6 - Miami\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/6/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/6/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 81 completed the race distance 00:00.036000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '63', '1', '23', '12', '16', '44', '55', '22', '6', '31', '10', '27', '14', '18', '30', '5', '87', '7']\n",
      "core           INFO \tLoading data for Emilia Romagna Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/7/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/7/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[53/66] Processing: 2025 Round  7 - Enzo e Dino Ferrari\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/7/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/7/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '44', '23', '16', '63', '55', '6', '22', '14', '27', '10', '30', '18', '43', '87', '5', '12', '31']\n",
      "core           INFO \tLoading data for Monaco Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[54/66] Processing: 2025 Round  8 - Monaco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/8/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/8/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '16', '81', '1', '44', '6', '31', '30', '23', '55', '63', '87', '43', '5', '18', '27', '22', '12', '14', '10']\n",
      "events      WARNING \tCorrecting user input 'Catalunya' to 'Australian Grand Prix'\n",
      "core           INFO \tLoading data for Australian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '87'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '30'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[55/66] Processing: 2025 Round  9 - Catalunya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 4 completed the race distance 00:00.022000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '63', '12', '23', '18', '27', '16', '81', '44', '10', '22', '31', '87', '30', '5', '14', '55', '7', '6']\n",
      "events      WARNING \tCorrecting user input 'Montreal' to 'Canadian Grand Prix'\n",
      "core           INFO \tLoading data for Canadian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[56/66] Processing: 2025 Round 10 - Gilles Villeneuve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/10/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/10/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '1', '12', '81', '16', '44', '14', '27', '31', '55', '87', '22', '43', '5', '10', '6', '18', '4', '30', '23']\n",
      "core           INFO \tLoading data for Austrian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/11/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/11/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[57/66] Processing: 2025 Round 11 - Red Bull Ring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/11/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/11/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '16', '44', '63', '30', '14', '5', '27', '31', '87', '6', '10', '18', '43', '22', '23', '1', '12', '55']\n",
      "core           INFO \tLoading data for British Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[58/66] Processing: 2025 Round 12 - Silverstone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/12/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/12/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '27', '44', '1', '10', '18', '23', '14', '63', '87', '55', '31', '16', '22', '12', '6', '5', '30', '43']\n",
      "core           INFO \tLoading data for Belgian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/13/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/13/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '81'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '4'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '16'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '1'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '63'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '23'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '44'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '30'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '10'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '87'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '27'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '22'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '18'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '31'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '12'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[59/66] Processing: 2025 Round 13 - Spa-Francorchamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tFixed incorrect tyre stint information for driver '14'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '55'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '43'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '6'\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/13/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/13/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '16', '1', '63', '23', '44', '30', '5', '10', '87', '27', '22', '18', '31', '12', '14', '55', '43', '6']\n",
      "events      WARNING \tCorrecting user input 'Hungaroring' to 'Hungarian Grand Prix'\n",
      "core           INFO \tLoading data for Hungarian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[60/66] Processing: 2025 Round 14 - Hungaroring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/14/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/14/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '63', '16', '14', '5', '18', '30', '1', '12', '6', '44', '27', '55', '23', '31', '22', '43', '10', '87']\n",
      "core           INFO \tLoading data for Dutch Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/15/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/15/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[61/66] Processing: 2025 Round 15 - Zandvoort\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/15/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/15/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '1', '6', '63', '23', '87', '18', '14', '22', '31', '43', '30', '55', '27', '5', '12', '10', '4', '16', '44']\n",
      "core           INFO \tLoading data for Italian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[62/66] Processing: 2025 Round 16 - Monza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/16/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/16/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '16', '63', '44', '23', '5', '12', '6', '55', '87', '22', '30', '31', '10', '43', '18', '14', '27']\n",
      "core           INFO \tLoading data for Azerbaijan Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/17/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/17/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[63/66] Processing: 2025 Round 17 - Baku\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/17/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/17/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core        WARNING \tDriver 1 completed the race distance 00:00.015000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '63', '55', '12', '30', '22', '4', '44', '16', '6', '5', '87', '23', '31', '14', '27', '18', '10', '43', '81']\n",
      "events      WARNING \tCorrecting user input 'Marina-bay' to 'Singapore Grand Prix'\n",
      "core           INFO \tLoading data for Singapore Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/18/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/18/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[64/66] Processing: 2025 Round 18 - Marina Bay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '1', '4', '81', '12', '16', '14', '44', '87', '55', '6', '22', '18', '23', '30', '43', '5', '31', '10', '27']\n",
      "core           INFO \tLoading data for United States Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/19/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/19/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[65/66] Processing: 2025 Round 19 - Americas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/19/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/19/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '16', '44', '81', '63', '22', '27', '87', '14', '30', '18', '12', '23', '31', '6', '43', '5', '10', '55']\n",
      "events      WARNING \tCorrecting user input 'Mexico-city' to 'Mexico City Grand Prix'\n",
      "core           INFO \tLoading data for Mexico City Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/20/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/20/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "[66/66] Processing: 2025 Round 20 - Hermanos Rodríguez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/20/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/20/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '16', '1', '87', '81', '12', '63', '44', '31', '5', '22', '23', '6', '18', '10', '43', '55', '14', '27', '30']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Success\n",
      "\n",
      "======================================================================\n",
      "PROCESSING COMPLETE\n",
      "Successfully processed: 66/66 races\n",
      "Failed: 0/66 races\n",
      "======================================================================\n",
      "\n",
      "✓ Dataset saved to: csv_output/Circuit_geometry_2023_2025.csv\n",
      "  Total records: 66\n",
      "  Years covered: 2023 - 2025\n",
      "  Unique circuits: 24\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================\n",
    "# DATA COLLECTION FROM CACHE\n",
    "# =============================================================================\n",
    "# This section processes ONLY pre-cached FastF1 data from ./cache folder\n",
    "#\n",
    "# 💡 TIP: If you're getting many failures, process year-by-year:\n",
    "#    1. Look at your cache folder to see which years have data\n",
    "#    2. Update SCHEDULE_YEARS above (line 262) to process one year at a time\n",
    "#    3. Run the script multiple times for different year ranges\n",
    "#    4. Manually merge the output CSV files afterwards\n",
    "#\n",
    "# Example: Process only 2018:  SCHEDULE_YEARS = range(2018, 2019)\n",
    "# Example: Process 2018-2019:  SCHEDULE_YEARS = range(2018, 2020)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROCESSING CACHED DATA - No downloads will occur\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_data = []\n",
    "total_races = len(merged_all_years)\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "\n",
    "for idx, row in merged_all_years.iterrows():\n",
    "    circuit_name = row[\"circuitRef\"].capitalize()\n",
    "    year = int(row[\"year\"])\n",
    "    round_num = int(row[\"round\"])\n",
    "    \n",
    "    print(f\"\\n[{idx+1}/{total_races}] Processing: {year} Round {round_num:2d} - {row['name']}\")\n",
    "\n",
    "    try:\n",
    "        df_tel = summarize_circuit(\n",
    "            year,\n",
    "            circuit_name,\n",
    "            official_length_km=row[\"length_km\"]  # Use static length if provided\n",
    "        )\n",
    "\n",
    "        # Add metadata\n",
    "        df_tel[\"circuitRef\"] = row[\"circuitRef\"]\n",
    "        df_tel[\"year\"] = year\n",
    "        df_tel[\"round\"] = round_num\n",
    "        df_tel[\"type\"] = row[\"type\"]\n",
    "        df_tel[\"num_drs_zones\"] = row[\"num_drs_zones\"]\n",
    "        df_tel[\"name\"] = row[\"name\"]\n",
    "\n",
    "        all_data.append(df_tel)\n",
    "        success_count += 1\n",
    "        print(f\"  ✓ Success\")\n",
    "\n",
    "    except Exception as e:\n",
    "        fail_count += 1\n",
    "        print(f\"  ✗ Failed: {str(e)[:80]}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"PROCESSING COMPLETE\")\n",
    "print(f\"Successfully processed: {success_count}/{total_races} races\")\n",
    "print(f\"Failed: {fail_count}/{total_races} races\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if len(all_data) == 0:\n",
    "    print(\"\\n WARNING: No data was successfully processed!\")\n",
    "    print(\"Make sure the cache folder contains the required FastF1 data.\")\n",
    "else:\n",
    "    telemetry_all_years = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Column ordering section::\n",
    "    ordered_cols = [\n",
    "        \"circuitRef\", \"year\", \"round\", \"name\", \"type\", \"num_drs_zones\", \"length_km\", \"num_turns\",\n",
    "        \"slow_corners\", \"medium_corners\", \"fast_corners\", \"flat_corners\", \"slow_cluster_max\",\n",
    "        \"straight_distance_m\", \"straight_ratio\", \"straight_len_max_m\", \"n_major_straights\",\n",
    "        \"heavy_braking_zones\", \"heavy_braking_mean_dv_kmh\", \"hb_spacing_std_m\", \"hb_at_end_of_max\",\n",
    "        \"corner_density_tpkm\", \"avg_corner_angle\", \"total_corner_angle\", \"avg_corner_distance\"\n",
    "    ]\n",
    "    telemetry_all_years = telemetry_all_years[[c for c in ordered_cols if c in telemetry_all_years.columns]]\n",
    "\n",
    "    # Save the final dataset\n",
    "    outdir = \"csv_output\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    \n",
    "    # Create filename based on actual years in final dataset\n",
    "    min_year = int(telemetry_all_years['year'].min())\n",
    "    max_year = int(telemetry_all_years['year'].max())\n",
    "    output_path = os.path.join(outdir, f\"Circuit_geometry_{min_year}_{max_year}.csv\")\n",
    "    telemetry_all_years.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Dataset saved to: {output_path}\")\n",
    "    print(f\"  Total records: {len(telemetry_all_years)}\")\n",
    "    print(f\"  Years covered: {min_year} - {max_year}\")\n",
    "    print(f\"  Unique circuits: {telemetry_all_years['circuitRef'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c489bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset saved to: csv_output/Circuit_geometry_unique.csv (34 circuits)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a unique circuits dataset from Circuit_geometry_2018_2025.csv\n",
    "- Keeps the most recent version of each circuit (typically 2025)\n",
    "- ADDS old layout (one entry before geometry change) for circuits that changed:\n",
    "    - yas-marina (2021)\n",
    "    - melbourne (2022)\n",
    "    - catalunya (2023)\n",
    "    - marina-bay (2023)\n",
    "    - zandvoort (2021)\n",
    "\"\"\"\n",
    "\n",
    "# Load the full dataset\n",
    "input_file = \"csv_output/Circuit_geometry_2018_2025.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Define circuits with geometry changes and the year they changed\n",
    "GEOMETRY_CHANGES = {\n",
    "    'yas-marina': {\n",
    "        'change_year': 2021,\n",
    "        'description': 'Chicane removed, reprofiled hairpin; 21→19 turns'\n",
    "    },\n",
    "    'melbourne': {\n",
    "        'change_year': 2022,\n",
    "        'description': 'T9/10 chicane removed, corners widened, full resurface'\n",
    "    },\n",
    "    'catalunya': {\n",
    "        'change_year': 2023,\n",
    "        'description': 'Final chicane removed; lap 4.657 km'\n",
    "    },\n",
    "    'marina-bay': {\n",
    "        'change_year': 2023,\n",
    "        'description': 'Float section removed; 23→19 corners; lap 4.928 km'\n",
    "    },\n",
    "    'zandvoort': {\n",
    "        'change_year': 2021,\n",
    "        'description': 'Banked T3 & T14; new 4.259 km GP layout'\n",
    "    },\n",
    "}\n",
    "\n",
    "# Process the dataset\n",
    "unique_circuits = []\n",
    "\n",
    "for circuit_ref in df['circuitRef'].unique():\n",
    "    circuit_data = df[df['circuitRef'] == circuit_ref].copy()\n",
    "    \n",
    "    # Always get the most recent version (current layout)\n",
    "    most_recent = circuit_data.sort_values('year', ascending=False).iloc[0].copy()\n",
    "    unique_circuits.append(most_recent)\n",
    "    \n",
    "    # If this circuit had geometry changes, also add the old layout\n",
    "    if circuit_ref in GEOMETRY_CHANGES:\n",
    "        change_year = GEOMETRY_CHANGES[circuit_ref]['change_year']\n",
    "        \n",
    "        # Get data before the change (old layout)\n",
    "        old_layout_data = circuit_data[circuit_data['year'] < change_year]\n",
    "        \n",
    "        if not old_layout_data.empty:\n",
    "            # Get the most recent data from the old layout era\n",
    "            old_most_recent = old_layout_data.sort_values('year', ascending=False).iloc[0].copy()\n",
    "            \n",
    "            # Modify the circuit reference and name to indicate it's the old layout\n",
    "            old_most_recent['circuitRef'] = f\"{circuit_ref}_old\"\n",
    "            old_most_recent['name'] = f\"{old_most_recent['name']} (pre-{change_year})\"\n",
    "            \n",
    "            unique_circuits.append(old_most_recent)\n",
    "\n",
    "# Create the unique circuits dataframe\n",
    "df_unique = pd.DataFrame(unique_circuits)\n",
    "\n",
    "# Sort by year and round\n",
    "df_unique = df_unique.sort_values(['year', 'round']).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"csv_output/Circuit_geometry_unique.csv\"\n",
    "df_unique.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✓ Dataset saved to: {output_file} ({len(df_unique)} circuits)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31f58ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Las Vegas Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv_output/Circuit_geometry_unique.csv...\n",
      "\n",
      "Processing 34 circuits...\n",
      "\n",
      "[1/34] 2019 melbourne_old... ✗ No event name\n",
      "[2/34] 2019 hockenheimring... ✗ No event name\n",
      "[3/34] 2020 nurburgring... ✗ No event name\n",
      "[4/34] 2020 yas-marina_old... ✗ No event name\n",
      "[5/34] 2021 portimao... ✗ No event name\n",
      "[6/34] 2021 sochi... ✗ No event name\n",
      "[7/34] 2021 istanbul... ✗ No event name\n",
      "[8/34] 2022 catalunya_old... ✗ No event name\n",
      "[9/34] 2022 paul-ricard... ✗ No event name\n",
      "[10/34] 2022 marina-bay_old... ✗ No event name\n",
      "[11/34] 2024 las-vegas... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tDriver 63: Lap timing integrity check failed for 2 lap(s)\n",
      "core        WARNING \tDriver 44: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver 55: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver 16: Lap timing integrity check failed for 2 lap(s)\n",
      "core        WARNING \tDriver  1: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver  4: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver 81: Lap timing integrity check failed for 1 lap(s)\n",
      "core        WARNING \tDriver 30: Lap timing integrity check failed for 2 lap(s)\n",
      "core        WARNING \tDriver 77: Lap timing integrity check failed for 2 lap(s)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core        WARNING \tDriver 63 completed the race distance 00:00.427000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '44', '55', '16', '1', '4', '81', '27', '22', '11', '14', '20', '24', '43', '18', '30', '31', '77', '23', '10']\n",
      "events      WARNING \tCorrecting user input 'Qatar Grand Prix' to 'Qatar Grand Prix'\n",
      "core           INFO \tLoading data for Qatar Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2 zones, 1470m ✓longest\n",
      "[12/34] 2024 lusail... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tFixed incorrect tyre stint information for driver '43'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '31'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '16', '81', '63', '10', '55', '14', '24', '20', '4', '77', '44', '22', '30', '23', '27', '11', '18', '43', '31']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '87'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '30'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2 zones, 1006m ✓longest\n",
      "[13/34] 2025 melbourne... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core        WARNING \tDriver 4 completed the race distance 00:00.022000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '1', '63', '12', '23', '18', '27', '16', '81', '44', '10', '22', '31', '87', '30', '5', '14', '55', '7', '6']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 zones, 2687m \n",
      "[14/34] 2025 shanghai... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '63', '1', '31', '12', '23', '87', '18', '55', '6', '30', '7', '5', '27', '22', '14', '16', '44', '10']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 zones, 1760m ✓longest\n",
      "[15/34] 2025 suzuka... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '16', '63', '12', '44', '6', '23', '87', '14', '22', '10', '55', '7', '27', '30', '31', '5', '18']\n",
      "core           INFO \tLoading data for Bahrain Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2 zones, 1176m \n",
      "[16/34] 2025 bahrain... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/4/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/4/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '63', '4', '16', '44', '1', '10', '31', '22', '87', '12', '23', '6', '7', '14', '30', '18', '5', '55', '27']\n",
      "core           INFO \tLoading data for Saudi Arabian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/5/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/5/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 4 zones, 2025m ✓longest\n",
      "[17/34] 2025 jeddah... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '1', '16', '4', '63', '12', '44', '55', '23', '6', '14', '30', '87', '31', '27', '18', '7', '5', '22', '10']\n",
      "core           INFO \tLoading data for Miami Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '6'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '31'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '18'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 4 zones, 2102m \n",
      "[18/34] 2025 miami... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/6/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/6/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core        WARNING \tDriver 81 completed the race distance 00:00.036000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '63', '1', '23', '12', '16', '44', '55', '22', '6', '31', '10', '27', '14', '18', '30', '5', '87', '7']\n",
      "core           INFO \tLoading data for Emilia Romagna Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 4 zones, 2622m ✓longest\n",
      "[19/34] 2025 imola... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/7/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/7/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '44', '23', '16', '63', '55', '6', '22', '14', '27', '10', '30', '18', '43', '87', '5', '12', '31']\n",
      "core           INFO \tLoading data for Monaco Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2 zones, 1385m ✓longest\n",
      "[20/34] 2025 monaco... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/8/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/8/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '16', '81', '1', '44', '6', '31', '30', '23', '55', '63', '87', '43', '5', '18', '27', '22', '12', '14', '10']\n",
      "core           INFO \tLoading data for Spanish Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 zones, 1238m \n",
      "[21/34] 2025 catalunya... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/9/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/9/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 19 drivers: ['81', '4', '16', '63', '27', '44', '6', '10', '14', '1', '30', '5', '22', '55', '43', '31', '87', '12', '23']\n",
      "core           INFO \tLoading data for Canadian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 zones, 1276m ✓longest\n",
      "[22/34] 2025 montreal... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '1', '12', '81', '16', '44', '14', '27', '31', '55', '87', '22', '43', '5', '10', '6', '18', '4', '30', '23']\n",
      "core           INFO \tLoading data for Austrian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/11/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/11/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2 zones, 843m \n",
      "[23/34] 2025 spielberg... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/11/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/11/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '16', '44', '63', '30', '14', '5', '27', '31', '87', '6', '10', '18', '43', '22', '23', '1', '12', '55']\n",
      "core           INFO \tLoading data for British Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 4 zones, 1945m ✓longest\n",
      "[24/34] 2025 silverstone... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '27', '44', '1', '10', '18', '23', '14', '63', '87', '55', '31', '16', '22', '12', '6', '5', '30', '43']\n",
      "core           INFO \tLoading data for Belgian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/13/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/13/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '81'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '4'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '16'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '1'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '63'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '23'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '44'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '30'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '5'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '10'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '87'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '27'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '22'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 zones, 1647m ✓longest\n",
      "[25/34] 2025 spa-francorchamps... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core        WARNING \tFixed incorrect tyre stint information for driver '18'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '31'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '12'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '14'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '55'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '43'\n",
      "core        WARNING \tFixed incorrect tyre stint information for driver '6'\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['81', '4', '16', '1', '63', '23', '44', '30', '5', '10', '87', '27', '22', '18', '31', '12', '14', '55', '43', '6']\n",
      "core           INFO \tLoading data for Hungarian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 zones, 1639m \n",
      "[26/34] 2025 hungaroring... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/14/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/14/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '63', '16', '14', '5', '18', '30', '1', '12', '6', '44', '27', '55', '23', '31', '22', '43', '10', '87']\n",
      "core           INFO \tLoading data for Dutch Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2 zones, 1189m ✓longest\n",
      "[27/34] 2025 zandvoort... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/15/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/15/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tLoading data for Italian Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ No zones\n",
      "[28/34] 2025 monza... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/16/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/16/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '81', '16', '63', '44', '23', '5', '12', '6', '55', '87', '22', '30', '31', '10', '43', '18', '14', '27']\n",
      "core           INFO \tLoading data for Azerbaijan Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 zones, 1534m ✓longest\n",
      "[29/34] 2025 baku... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/17/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/17/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core        WARNING \tDriver 1 completed the race distance 00:00.015000 before the recorded end of the session.\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '63', '55', '12', '30', '22', '4', '44', '16', '6', '5', '87', '23', '31', '14', '27', '18', '10', '43', '81']\n",
      "core           INFO \tLoading data for Singapore Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/18/results.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/18/results.json\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 zones, 1471m ✓longest\n",
      "[30/34] 2025 marina-bay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['63', '1', '4', '81', '12', '16', '14', '44', '87', '55', '6', '22', '18', '23', '30', '43', '5', '31', '10', '27']\n",
      "events      WARNING \tCorrecting user input 'United States Grand Prix' to 'United States Grand Prix'\n",
      "core           INFO \tLoading data for United States Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 4 zones, 2405m ✓longest\n",
      "[31/34] 2025 austin... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request for URL https://api.jolpi.ca/ergast/f1/2025/19/laps/1.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests_cache/session.py\", line 291, in _resend\n",
      "    response.raise_for_status()\n",
      "  File \"/Applications/anaconda3/envs/Formula1/lib/python3.12/site-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://api.jolpi.ca/ergast/f1/2025/19/laps/1.json\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for weather_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '4', '16', '44', '81', '63', '22', '27', '87', '14', '30', '18', '12', '23', '31', '6', '43', '5', '10', '55']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 zones, 1545m ✓longest\n",
      "[32/34] 2025 mexico-city... ✗ No event name\n",
      "[33/34] 2025 interlagos... ✗ No event name\n",
      "[34/34] 2025 yas-marina... ✗ No event name\n",
      "\n",
      "========================================================================\n",
      "✓ Complete! Saved to csv_output/Circuit_geometry_unique.csv\n",
      "========================================================================\n",
      "\n",
      "Summary:\n",
      "  Total: 34\n",
      "  With DRS: 20\n",
      "  On longest straight: 14\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add DRS data to Circuit_geometry_unique.csv\n",
    "\n",
    "Adds/updates 3 columns:\n",
    "1. drs_zones_detected - number of DRS zones\n",
    "2. drs_total_len_m - total length of all DRS zones (meters)\n",
    "3. drs_on_max - True if any DRS zone is on the longest straight\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastf1\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Cache setup\n",
    "CACHE_DIR = \"./cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "fastf1.Cache.enable_cache(CACHE_DIR)\n",
    "\n",
    "# Parameters\n",
    "POS_JOIN_TOL = pd.Timedelta(\"200ms\")\n",
    "LAP_JOIN_DIR = \"backward\"\n",
    "MIN_SEG_LEN_M = 50.0\n",
    "EPS_CLUSTER_M = 200.0\n",
    "MIN_SUPPORT_FRAC = 0.12\n",
    "MIN_SUPPORT_ABS = 4\n",
    "MAX_ZONE_FRAC = 0.35\n",
    "MERGE_WRAP_GAP_M = 500.0\n",
    "DUP_OVERLAP_FRAC = 0.60\n",
    "\n",
    "\n",
    "# Circuit name to event name mapping\n",
    "CIRCUIT_TO_EVENT = {\n",
    "    \"austin\": \"United States\", \"bahrain\": \"Bahrain\", \"baku\": \"Azerbaijan\",\n",
    "    \"catalunya\": \"Spanish\", \"catalunya_old\": \"Spanish\", \"hockenheimring\": \"German\",\n",
    "    \"hungaroring\": \"Hungarian\", \"imola\": \"Emilia Romagna\", \"interlagos\": \"Brazilian\",\n",
    "    \"istanbul\": \"Turkish\", \"jeddah\": \"Saudi Arabian\", \"las-vegas\": \"Las Vegas\",\n",
    "    \"lusail\": \"Qatar\", \"marina-bay\": \"Singapore\", \"marina-bay_old\": \"Singapore\",\n",
    "    \"melbourne\": \"Australian\", \"melbourne_old\": \"Australian\", \"mexico-city\": \"Mexican\",\n",
    "    \"miami\": \"Miami\", \"monaco\": \"Monaco\", \"montreal\": \"Canadian\", \"monza\": \"Italian\",\n",
    "    \"nurburgring\": \"Eifel\", \"paul-ricard\": \"French\", \"portimao\": \"Portuguese\",\n",
    "    \"shanghai\": \"Chinese\", \"silverstone\": \"British\", \"sochi\": \"Russian\",\n",
    "    \"spa-francorchamps\": \"Belgian\", \"spielberg\": \"Austrian\", \"suzuka\": \"Japanese\",\n",
    "    \"yas-marina\": \"Abu Dhabi\", \"yas-marina_old\": \"Abu Dhabi\", \"zandvoort\": \"Dutch\",\n",
    "}\n",
    "\n",
    "\n",
    "def _drs_active_mask(series):\n",
    "    return series.fillna(0).astype(\"Int64\") > 0\n",
    "\n",
    "\n",
    "def _ensure_dtypes(df):\n",
    "    if \"Time\" in df.columns:\n",
    "        df[\"Time\"] = pd.to_timedelta(df[\"Time\"])\n",
    "    if \"Date\" in df.columns:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _clean_fastest_lap(session):\n",
    "    try:\n",
    "        laps = session.laps\n",
    "        if laps is None or laps.empty:\n",
    "            return None\n",
    "        laps = laps[(laps[\"PitOutTime\"].isna()) & (laps[\"PitInTime\"].isna())]\n",
    "        if \"TrackStatus\" in laps.columns:\n",
    "            green = laps[\"TrackStatus\"].fillna(\"\").astype(str).str.fullmatch(\"1\")\n",
    "            if green.any():\n",
    "                laps = laps[green]\n",
    "        return laps.pick_fastest()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _kd_map_distance(ref_tel, xy):\n",
    "    tree = cKDTree(ref_tel[[\"X\", \"Y\"]].to_numpy())\n",
    "    idx = tree.query(xy, k=1)[1]\n",
    "    return ref_tel[\"Distance\"].to_numpy()[idx]\n",
    "\n",
    "\n",
    "def _compute_curvature(tel):\n",
    "    \"\"\"Compute curvature from X,Y coordinates (unscaled).\"\"\"\n",
    "    x, y = tel[\"X\"].to_numpy(), tel[\"Y\"].to_numpy()\n",
    "    dx, dy = np.gradient(x), np.gradient(y)\n",
    "    ddx, ddy = np.gradient(dx), np.gradient(dy)\n",
    "    num = np.abs(dx * ddy - dy * ddx)\n",
    "    denom = (dx**2 + dy**2)**1.5\n",
    "    return np.where(denom > 1e-9, num / denom, 0.0)\n",
    "\n",
    "\n",
    "def _find_longest_straight(tel):\n",
    "    \"\"\"\n",
    "    Find the longest straight segment on the track.\n",
    "    Returns dict with start, end, length in meters.\n",
    "    This duplicates logic from formula1dataset.py but is kept for standalone use.\n",
    "    \"\"\"\n",
    "    curvature = _compute_curvature(tel)\n",
    "    is_straight = curvature < 0.001\n",
    "    s = tel[\"Distance\"].to_numpy()\n",
    "    \n",
    "    changes = np.where(np.diff(is_straight.astype(int)) != 0)[0] + 1\n",
    "    starts = np.concatenate([[0], changes])\n",
    "    ends = np.concatenate([changes, [len(is_straight)]])\n",
    "    \n",
    "    segments = []\n",
    "    for i in range(len(starts)):\n",
    "        if is_straight[starts[i]]:\n",
    "            length = float(s[ends[i] - 1] - s[starts[i]])\n",
    "            if length >= 70.0:\n",
    "                segments.append({\"start\": float(s[starts[i]]), \"end\": float(s[ends[i] - 1]), \"length\": length})\n",
    "    \n",
    "    return max(segments, key=lambda x: x[\"length\"]) if segments else None\n",
    "\n",
    "\n",
    "def _segments_from_mask(df):\n",
    "    segs = []\n",
    "    for lap, g in df.groupby(\"LapNumber\", sort=True):\n",
    "        m = g[\"drs_on\"].to_numpy(dtype=bool)\n",
    "        if not m.any():\n",
    "            continue\n",
    "        dm = np.diff(m.astype(int))\n",
    "        starts = np.where(dm == 1)[0] + 1\n",
    "        ends = np.where(dm == -1)[0] + 1\n",
    "        if m[0]:\n",
    "            starts = np.r_[0, starts]\n",
    "        if m[-1]:\n",
    "            ends = np.r_[ends, len(m)]\n",
    "        svals = g[\"Distance\"].to_numpy()\n",
    "        for a, b in zip(starts, ends):\n",
    "            seg_len = float(svals[b-1] - svals[a])\n",
    "            if seg_len >= MIN_SEG_LEN_M:\n",
    "                segs.append({\"lap\": int(lap), \"start\": float(svals[a]), \"end\": float(svals[b-1]), \"len\": seg_len})\n",
    "    return segs\n",
    "\n",
    "\n",
    "def _cluster_segments(segs, lap_len):\n",
    "    if not segs:\n",
    "        return []\n",
    "    \n",
    "    aug = []\n",
    "    for s in segs:\n",
    "        aug.append((s[\"start\"], s[\"end\"], s[\"lap\"]))\n",
    "        if lap_len - s[\"start\"] < EPS_CLUSTER_M:\n",
    "            aug.append((s[\"start\"] + lap_len, s[\"end\"] + lap_len, s[\"lap\"]))\n",
    "    \n",
    "    aug = np.array(aug)\n",
    "    aug = aug[np.argsort(aug[:, 0])]\n",
    "    \n",
    "    clusters = []\n",
    "    cur = [aug[0]]\n",
    "    for row in aug[1:]:\n",
    "        if abs(row[0] - cur[-1][0]) <= EPS_CLUSTER_M:\n",
    "            cur.append(row)\n",
    "        else:\n",
    "            clusters.append(np.array(cur))\n",
    "            cur = [row]\n",
    "    clusters.append(np.array(cur))\n",
    "    \n",
    "    zones = []\n",
    "    for C in clusters:\n",
    "        st = C[:, 0] % lap_len\n",
    "        en = C[:, 1] % lap_len\n",
    "        start_med = float(np.median(st))\n",
    "        end_med = float(np.median(en))\n",
    "        \n",
    "        if end_med < start_med:\n",
    "            zone_len = (end_med + lap_len) - start_med\n",
    "            wraps = True\n",
    "        else:\n",
    "            zone_len = end_med - start_med\n",
    "            wraps = False\n",
    "        \n",
    "        zones.append({\n",
    "            \"start\": start_med,\n",
    "            \"len\": max(float(zone_len), 0.0),\n",
    "            \"end\": (start_med + max(float(zone_len), 0.0)) % lap_len,\n",
    "            \"wraps\": wraps,\n",
    "            \"support\": int(len(np.unique(C[:, 2])))\n",
    "        })\n",
    "    return zones\n",
    "\n",
    "\n",
    "def _filter_zones(zones, laps_used, lap_len):\n",
    "    kept = []\n",
    "    for z in zones:\n",
    "        support_frac = z[\"support\"] / max(laps_used, 1)\n",
    "        frac_len = z[\"len\"] / max(lap_len, 1.0)\n",
    "        if support_frac < MIN_SUPPORT_FRAC and z[\"support\"] < MIN_SUPPORT_ABS:\n",
    "            continue\n",
    "        if z[\"len\"] <= 0 or frac_len > MAX_ZONE_FRAC:\n",
    "            continue\n",
    "        kept.append(z)\n",
    "    \n",
    "    if not kept:\n",
    "        return []\n",
    "    \n",
    "    kept.sort(key=lambda r: (-r[\"support\"], -r[\"len\"]))\n",
    "    final = []\n",
    "    used = np.zeros(len(kept), dtype=bool)\n",
    "    for i in range(len(kept)):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        final.append(kept[i])\n",
    "        for j in range(i+1, len(kept)):\n",
    "            if used[j]:\n",
    "                continue\n",
    "            same_start = min(abs(kept[i][\"start\"] - kept[j][\"start\"]),\n",
    "                           abs((kept[i][\"start\"] + lap_len) - kept[j][\"start\"]),\n",
    "                           abs(kept[i][\"start\"] - (kept[j][\"start\"] + lap_len))) <= EPS_CLUSTER_M\n",
    "            same_end = min(abs(kept[i][\"end\"] - kept[j][\"end\"]),\n",
    "                         abs((kept[i][\"end\"] + lap_len) - kept[j][\"end\"]),\n",
    "                         abs(kept[i][\"end\"] - (kept[j][\"end\"] + lap_len))) <= EPS_CLUSTER_M\n",
    "            if same_start and same_end:\n",
    "                used[j] = True\n",
    "    return final\n",
    "\n",
    "\n",
    "def _check_overlap(zones, longest_straight, lap_len):\n",
    "    if not longest_straight or not zones:\n",
    "        return False\n",
    "    \n",
    "    ss, se = longest_straight[\"start\"], longest_straight[\"end\"]\n",
    "    \n",
    "    for z in zones:\n",
    "        zs, ze = z[\"start\"], z[\"end\"]\n",
    "        \n",
    "        if z[\"wraps\"] or ze < zs:\n",
    "            zone_segs = [(zs, lap_len), (0.0, ze)]\n",
    "        else:\n",
    "            zone_segs = [(zs, ze)]\n",
    "        \n",
    "        overlap = 0.0\n",
    "        for zstart, zend in zone_segs:\n",
    "            overlap += max(0.0, min(zend, se) - max(zstart, ss))\n",
    "        \n",
    "        if overlap / z[\"len\"] >= 0.5:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_drs_for_circuit(circuit_ref, year, event_name):\n",
    "    \"\"\"Extract DRS data for one circuit. Returns (num_zones, total_len, on_longest_straight)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Load session once with all needed data\n",
    "        sess = fastf1.get_session(year, event_name, \"R\")\n",
    "        sess.load(telemetry=True, laps=True)\n",
    "        \n",
    "        if not hasattr(sess, 'laps') or sess.laps is None or sess.laps.empty:\n",
    "            return (np.nan, np.nan, False)\n",
    "        \n",
    "        all_drivers = sess.laps['DriverNumber'].dropna().unique().astype(str).tolist()\n",
    "        \n",
    "        # Get reference lap once (same for all drivers)\n",
    "        ref_lap = _clean_fastest_lap(sess)\n",
    "        if ref_lap is None:\n",
    "            return (np.nan, np.nan, False)\n",
    "        \n",
    "        ref_tel = ref_lap.get_telemetry().add_distance()\n",
    "        ref_tel = ref_tel.dropna(subset=[\"Distance\", \"X\", \"Y\"])\n",
    "        if ref_tel.empty:\n",
    "            return (np.nan, np.nan, False)\n",
    "        \n",
    "        longest_straight = _find_longest_straight(ref_tel)\n",
    "    except:\n",
    "        return (np.nan, np.nan, False)\n",
    "    \n",
    "    best_result = None\n",
    "    best_score = -1\n",
    "    \n",
    "    # Try all drivers\n",
    "    for driver in all_drivers:\n",
    "        try:\n",
    "            if driver not in sess.car_data or driver not in sess.pos_data:\n",
    "                continue\n",
    "            \n",
    "            car = sess.car_data[driver].copy().dropna(subset=[\"Time\", \"Date\", \"DRS\"]).reset_index(drop=True)\n",
    "            pos = sess.pos_data[driver].copy().dropna(subset=[\"Time\", \"Date\", \"X\", \"Y\"]).reset_index(drop=True)\n",
    "            car = _ensure_dtypes(car)\n",
    "            pos = _ensure_dtypes(pos)\n",
    "            \n",
    "            laps_drv = sess.laps[sess.laps[\"DriverNumber\"] == driver][[\"LapNumber\", \"LapStartTime\"]].dropna()\n",
    "            if laps_drv.empty:\n",
    "                continue\n",
    "            \n",
    "            laps_drv = laps_drv.sort_values(\"LapStartTime\").reset_index(drop=True)\n",
    "            car = car.sort_values(\"Time\")\n",
    "            car = pd.merge_asof(car, laps_drv, left_on=\"Time\", right_on=\"LapStartTime\",\n",
    "                              direction=LAP_JOIN_DIR, allow_exact_matches=True)\n",
    "            car = car.dropna(subset=[\"LapNumber\"]).copy()\n",
    "            car[\"LapNumber\"] = car[\"LapNumber\"].astype(int)\n",
    "            \n",
    "            car = car.sort_values(\"Date\")\n",
    "            pos = pos.sort_values(\"Date\")\n",
    "            car = pd.merge_asof(car, pos[[\"Date\", \"X\", \"Y\"]], on=\"Date\",\n",
    "                              direction=\"nearest\", tolerance=POS_JOIN_TOL)\n",
    "            car = car.dropna(subset=[\"X\", \"Y\"]).reset_index(drop=True)\n",
    "            \n",
    "            xy = car[[\"X\", \"Y\"]].to_numpy()\n",
    "            car[\"Distance\"] = _kd_map_distance(ref_tel, xy)\n",
    "            \n",
    "            lap_len = car.groupby(\"LapNumber\")[\"Distance\"].agg(lambda s: float(s.max() - s.min()))\n",
    "            lap_len = lap_len[lap_len > 1000.0]\n",
    "            if lap_len.empty:\n",
    "                continue\n",
    "            \n",
    "            lap_len_median = float(np.median(lap_len.values))\n",
    "            laps_used = int(car[\"LapNumber\"].nunique())\n",
    "            \n",
    "            car[\"drs_on\"] = _drs_active_mask(car[\"DRS\"])\n",
    "            \n",
    "            segs = _segments_from_mask(car)\n",
    "            if not segs:\n",
    "                continue\n",
    "            \n",
    "            zones = _cluster_segments(segs, lap_len_median)\n",
    "            zones = _filter_zones(zones, laps_used, lap_len_median)\n",
    "            \n",
    "            if not zones:\n",
    "                continue\n",
    "            \n",
    "            total_len = float(np.sum([z[\"len\"] for z in zones]))\n",
    "            num_zones = len(zones)\n",
    "            \n",
    "            # Check overlap with longest straight (already computed once)\n",
    "            on_longest = _check_overlap(zones, longest_straight, lap_len_median)\n",
    "            \n",
    "            # Score: more zones and more laps is better\n",
    "            score = num_zones * 1000 + laps_used\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_result = (num_zones, total_len, on_longest)\n",
    "        \n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    return best_result if best_result else (np.nan, np.nan, False)\n",
    "\n",
    "\n",
    "def find_event_name(circuit_ref, year):\n",
    "    \"\"\"Find FastF1 event name for circuit by looking in cache directory\"\"\"\n",
    "    pattern = CIRCUIT_TO_EVENT.get(circuit_ref)\n",
    "    if not pattern:\n",
    "        return None\n",
    "    \n",
    "    # Check cache directory for matching event\n",
    "    year_cache_dir = os.path.join(CACHE_DIR, str(year))\n",
    "    if not os.path.exists(year_cache_dir):\n",
    "        return None\n",
    "    \n",
    "    pattern_norm = pattern.lower()\n",
    "    \n",
    "    try:\n",
    "        # List all event folders in the year's cache directory\n",
    "        for folder_name in os.listdir(year_cache_dir):\n",
    "            folder_path = os.path.join(year_cache_dir, folder_name)\n",
    "            if os.path.isdir(folder_path):\n",
    "                # Extract event name from folder (e.g., \"2019-03-17_Australian_Grand_Prix\" -> \"Australian Grand Prix\")\n",
    "                parts = folder_name.split('_', 1)\n",
    "                if len(parts) == 2:\n",
    "                    event_name = parts[1].replace('_', ' ')\n",
    "                    if pattern_norm in event_name.lower():\n",
    "                        return event_name\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Add DRS columns to Circuit_geometry_unique.csv\"\"\"\n",
    "    \n",
    "    csv_path = \"csv_output/Circuit_geometry_unique.csv\"\n",
    "    output_path = \"csv_output/Circuit_geometry_unique.csv\"\n",
    "    #backup_path = \"csv_output/Circuit_geometry_unique_backup.csv\"\n",
    "\n",
    "    print(f\"Reading {csv_path}...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Backup\n",
    "    # df.to_csv(backup_path, index=False)\n",
    "    # print(f\"Backup saved to {backup_path}\")\n",
    "    \n",
    "    # Initialize columns if they don't exist\n",
    "    # Note: CSV uses \"drs_on_max\" as the column name\n",
    "    if \"drs_zones_detected\" not in df.columns:\n",
    "        df[\"drs_zones_detected\"] = np.nan\n",
    "    if \"drs_total_len_m\" not in df.columns:\n",
    "        df[\"drs_total_len_m\"] = np.nan\n",
    "    if \"drs_on_max\" not in df.columns:\n",
    "        df[\"drs_on_max\"] = False\n",
    "    \n",
    "    print(f\"\\nProcessing {len(df)} circuits...\\n\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        circuit_ref = row[\"circuitRef\"]\n",
    "        year = int(row[\"year\"])\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if pd.notna(row.get(\"drs_zones_detected\")):\n",
    "            print(f\"[{idx+1}/{len(df)}] {year} {circuit_ref} - SKIP (already done)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"[{idx+1}/{len(df)}] {year} {circuit_ref}...\", end=\" \")\n",
    "        \n",
    "        event_name = find_event_name(circuit_ref, year)\n",
    "        if not event_name:\n",
    "            print(f\"✗ No event name\")\n",
    "            df.at[idx, \"drs_zones_detected\"] = 0\n",
    "            df.at[idx, \"drs_total_len_m\"] = 0.0\n",
    "            df.at[idx, \"drs_on_max\"] = False\n",
    "            continue\n",
    "        \n",
    "        num_zones, total_len, on_longest = extract_drs_for_circuit(circuit_ref, year, event_name)\n",
    "        \n",
    "        df.at[idx, \"drs_zones_detected\"] = num_zones\n",
    "        df.at[idx, \"drs_total_len_m\"] = total_len\n",
    "        df.at[idx, \"drs_on_max\"] = on_longest\n",
    "        \n",
    "        if pd.notna(num_zones) and num_zones > 0:\n",
    "            on_str = \"✓longest\" if on_longest else \"\"\n",
    "            print(f\"✓ {int(num_zones)} zones, {total_len:.0f}m {on_str}\")\n",
    "        else:\n",
    "            print(f\"✗ No zones\")\n",
    "        \n",
    "        # Save after each\n",
    "        df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*72}\")\n",
    "    print(f\"✓ Complete! Saved to {output_path}\")\n",
    "    print(f\"{'='*72}\")\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"  Total: {len(df)}\")\n",
    "    print(f\"  With DRS: {(df['drs_zones_detected'] > 0).sum()}\")\n",
    "    print(f\"  On longest straight: {df['drs_on_max'].sum()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92526663",
   "metadata": {},
   "source": [
    "# Creating the other dataset from the cached data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778bc06f",
   "metadata": {},
   "source": [
    "We will start from the same base as before , hence we will use  circuit_specs_with_rounds csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b0663",
   "metadata": {},
   "source": [
    "Focusing just on one race for now ( as tyre regulation changed from 2021 to 2022 for now pick one race after the change in regulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316fa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Circuit_spec_with_round = pd.read_csv('csv_output/circuit_specs_with_rounds_2018_2025.csv')\n",
    "\n",
    "Circuit_spec_with_round.drop(columns=[\"length_km\", \"turns\" , \"type\" , \"num_drs_zones\" , \"turns\", \"length_km\", \"type\" , \"num_drs_zones\"], inplace=True)\n",
    "\n",
    "# save to csv\n",
    "\n",
    "Circuit_spec_with_round.to_csv('csv_output/Rounds_2018_2025.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drivers_for_race(base_path):\n",
    "    \"\"\"\n",
    "    Extract driver information for a single race from a given cache path.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_path : str\n",
    "        Path to race cache directory (e.g., \"cache/2023/2023-09-03_Italian_Grand_Prix/2023-09-03_Race\")\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with driver info including columns:\n",
    "        - RacingNumber, FullName, TeamName\n",
    "        - year, round, name, countryId (if circuit data found)\n",
    "    \"\"\"\n",
    "    # Load driver info\n",
    "    driver_path = os.path.join(base_path, \"driver_info.ff1pkl\")\n",
    "    with open(driver_path, 'rb') as f:\n",
    "        drivers = pickle.load(f)\n",
    "    \n",
    "    # Extract drivers info from the 'data' key (it's a defaultdict)\n",
    "    drivers_data = drivers['data']\n",
    "    \n",
    "    # Extract all drivers\n",
    "    drivers_info = []\n",
    "    for driver_num, driver_dict in drivers_data.items():\n",
    "        try:\n",
    "            drivers_info.append({\n",
    "                'RacingNumber': driver_dict['RacingNumber'],\n",
    "                'FullName': driver_dict['FullName'],\n",
    "                'TeamName': driver_dict['TeamName']\n",
    "            })\n",
    "        except (KeyError, TypeError):\n",
    "            continue\n",
    "    \n",
    "    drivers_df = pd.DataFrame(drivers_info)\n",
    "    \n",
    "    # Try to add circuit info  \n",
    "    try:\n",
    "        circuit_df = pd.read_csv('csv_output/Rounds_2018_2025.csv')\n",
    "        # Extract year from path\n",
    "        year = int(base_path.split('/')[-3])\n",
    "        \n",
    "        # Extract round number by counting chronologically\n",
    "        # Get year folder and find this race's position\n",
    "        year_folder = base_path.split('/')[-3]\n",
    "        race_folder = base_path.split('/')[-2]\n",
    "        races_in_year = sorted([d for d in os.listdir(f\"cache/{year_folder}\") if os.path.isdir(f\"cache/{year_folder}/{d}\")])\n",
    "        \n",
    "        try:\n",
    "            round_num = races_in_year.index(race_folder) + 1\n",
    "        except (ValueError, IndexError):\n",
    "            round_num = None\n",
    "        \n",
    "        # Get circuit info for this year and round\n",
    "        if round_num:\n",
    "            circuit_info = circuit_df[(circuit_df['year'] == year) & (circuit_df['round'] == round_num)]\n",
    "            if not circuit_info.empty:\n",
    "                circuit_info = circuit_info.iloc[0]\n",
    "                for col in ['year', 'round', 'name', 'countryId']:\n",
    "                    if col in circuit_info.index:\n",
    "                        drivers_df[col] = circuit_info[col]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    return drivers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07405047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract specific race with driver info\n",
    "base_path = \"cache/2024/2024-11-23_Las_Vegas_Grand_Prix/2024-11-23_Race\"\n",
    "\n",
    "drivers_info = extract_drivers_for_race(base_path)\n",
    "#print(drivers_info[['year', 'round', 'name', 'countryId', 'FullName', 'RacingNumber', 'TeamName']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lap_timing_data(base_path, drivers_info, output_path='csv_output/2024/Las_Vegas_GP_2024_lap_times.xlsx', tolerance_seconds=0.30):\n",
    "    \"\"\"\n",
    "    Process extended timing data and merge with driver information.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_path : str\n",
    "        Path to the directory containing the '_extended_timing_data.ff1pkl' file\n",
    "    drivers_info : pd.DataFrame\n",
    "        DataFrame containing driver information with columns:\n",
    "        ['RacingNumber', 'FullName', 'TeamName', 'year', 'round', 'name', 'countryId']\n",
    "    output_path : str, optional\n",
    "        Path to save the processed data as Excel file\n",
    "        (default: 'csv_output/Italian_GP_2023_lap_times.xlsx')\n",
    "    tolerance_seconds : float, optional\n",
    "        Tolerance in seconds for merging lap and position data (default: 0.05)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Processed dataframe with columns:\n",
    "        ['year', 'round', 'name', 'countryId', 'Name', 'Team', 'RacingNumber', \n",
    "         'Time', 'NumberOfLaps', 'LapTime', 'Position', 'IntervalToPositionAhead', 'NumberOfPitStops']\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load Data \n",
    "    fpath = os.path.join(base_path, \"_extended_timing_data.ff1pkl\")\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    \n",
    "    data = d[\"data\"]  # the real stuff\n",
    "    extended_timing_df = data[0].copy()\n",
    "    \n",
    "    # Extract Lap Data \n",
    "    lap_data = extended_timing_df[['Driver', 'Time', 'NumberOfLaps', 'LapTime', 'NumberOfPitStops']].copy()\n",
    "    lap_data_sorted = lap_data.sort_values(by=['Driver', 'NumberOfLaps']).reset_index(drop=True)\n",
    "    \n",
    "    # Extract Position Data \n",
    "    position_data = data[1][['Driver', 'Time', 'Position', 'GapToLeader', 'IntervalToPositionAhead']].copy()\n",
    "    \n",
    "    # Clean Data \n",
    "    lap_data_clean = lap_data_sorted[lap_data_sorted['Time'].notna()].copy()\n",
    "    position_data_clean = position_data[position_data['Time'].notna()].copy()\n",
    "    \n",
    "    # Convert Time to total seconds for more reliable merging\n",
    "    def timedelta_to_seconds(td):\n",
    "        \"\"\"Convert timedelta to total seconds\"\"\"\n",
    "        if pd.isna(td):\n",
    "            return None\n",
    "        return td.total_seconds()\n",
    "    \n",
    "    lap_data_clean['Time_seconds'] = lap_data_clean['Time'].apply(timedelta_to_seconds)\n",
    "    position_data_clean['Time_seconds'] = position_data_clean['Time'].apply(timedelta_to_seconds)\n",
    "    \n",
    "    # Normalize Driver to string and remove rows with NaN Time_seconds\n",
    "    lap_data_clean['Driver'] = lap_data_clean['Driver'].astype(str)\n",
    "    position_data_clean['Driver'] = position_data_clean['Driver'].astype(str)\n",
    "    lap_data_clean = lap_data_clean[lap_data_clean['Time_seconds'].notna()].copy()\n",
    "    position_data_clean = position_data_clean[position_data_clean['Time_seconds'].notna()].copy()\n",
    "    \n",
    "    # Merge Lap and Position Data \n",
    "    merged_parts = []\n",
    "    for driver in lap_data_clean['Driver'].unique():\n",
    "        lap_driver = lap_data_clean[lap_data_clean['Driver'] == driver].sort_values('Time_seconds').reset_index(drop=True)\n",
    "        pos_driver = position_data_clean[position_data_clean['Driver'] == driver].sort_values('Time_seconds').reset_index(drop=True)\n",
    "        \n",
    "        if len(pos_driver) == 0:\n",
    "            merged_parts.append(lap_driver)\n",
    "            continue\n",
    "        \n",
    "        merged_driver = pd.merge_asof(\n",
    "            lap_driver,\n",
    "            pos_driver[['Time_seconds', 'Position', 'GapToLeader', 'IntervalToPositionAhead']],\n",
    "            on='Time_seconds',\n",
    "            direction='nearest',\n",
    "            tolerance=tolerance_seconds\n",
    "        )\n",
    "        merged_parts.append(merged_driver)\n",
    "    \n",
    "    lap_data_merged = pd.concat(merged_parts, ignore_index=True)\n",
    "    lap_data_merged = lap_data_merged.drop(columns=['Time_seconds'])\n",
    "    lap_data_sorted = lap_data_merged.sort_values(by=['Driver', 'NumberOfLaps']).reset_index(drop=True)\n",
    "\n",
    "     # Shift only IntervalToPositionAhead column down by one row\n",
    "    lap_data_sorted['IntervalToPositionAhead'] = lap_data_sorted['IntervalToPositionAhead'].shift(1)\n",
    "    print(f\"✓ Merged {len(lap_data_sorted)} records with position and interval data\")\n",
    "    \n",
    "    # Merge with Driver Info \n",
    "    lap_data_detailed = lap_data_sorted.merge(\n",
    "        drivers_info[['RacingNumber', 'FullName', 'TeamName', 'year', 'round', 'name', 'countryId']], \n",
    "        left_on='Driver', \n",
    "        right_on='RacingNumber',\n",
    "        how='left'\n",
    "    )\n",
    "    lap_data_detailed = lap_data_detailed.drop(columns=['Driver'])\n",
    "    \n",
    "    # Convert LapTime to Seconds \n",
    "    lap_data_detailed['LapTime'] = lap_data_detailed['LapTime'].astype(str).str.split().str[-1]\n",
    "    \n",
    "    def time_to_seconds(time_str):\n",
    "        \"\"\"Convert time string (HH:MM:SS.microseconds) to total seconds\"\"\"\n",
    "        if pd.isna(time_str) or time_str == 'NaT':\n",
    "            return None\n",
    "        try:\n",
    "            parts = time_str.split(':')\n",
    "            hours = int(parts[0])\n",
    "            minutes = int(parts[1])\n",
    "            seconds = float(parts[2])\n",
    "            total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "            return round(total_seconds, 3)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    lap_data_detailed['LapTime'] = lap_data_detailed['LapTime'].apply(time_to_seconds)\n",
    "    \n",
    "    # Format and Export \n",
    "    lap_data_detailed = lap_data_detailed.rename(columns={\n",
    "        'FullName': 'Name',\n",
    "        'TeamName': 'Team'\n",
    "    })\n",
    "    \n",
    "    column_order = ['year', 'round', 'name', 'countryId', 'Name', 'Team', 'RacingNumber', \n",
    "                    'Time', 'NumberOfLaps', 'LapTime', 'Position', 'IntervalToPositionAhead', 'NumberOfPitStops']\n",
    "    lap_data_detailed = lap_data_detailed[column_order]\n",
    "    lap_data_detailed['Time'] = lap_data_detailed['Time'].astype(str)\n",
    "    \n",
    "    if output_path:\n",
    "        lap_data_detailed.to_excel(output_path, index=False, sheet_name='Lap Data')\n",
    "        print(f\"✓ Lap data saved to: {output_path}\")\n",
    "    \n",
    "    return lap_data_detailed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78cffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Merged 938 records with position and interval data\n",
      "✓ Lap data saved to: csv_output/2024/Las_Vegas_GP_2024_lap_times.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Usage \n",
    "lap_data_detailed = process_lap_timing_data(\n",
    "    base_path=base_path,\n",
    "    drivers_info=drivers_info,\n",
    "    output_path='csv_output/2024/Las_Vegas_GP_2024_lap_times.xlsx'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timing_app_data(\n",
    "    timing_app_path,\n",
    "    output_csv_path,\n",
    "    required_columns=None,\n",
    "    sort_columns=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract and process timing app data from a pickle file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    timing_app_path : str\n",
    "        Path to the timing_app_data.ff1pkl file\n",
    "    output_csv_path : str\n",
    "        Path where the processed CSV should be saved\n",
    "    required_columns : list, optional\n",
    "        List of columns to extract. Default: ['Driver', 'LapNumber', 'Stint', \n",
    "        'TotalLaps', 'Compound', 'New', 'TyresNotChanged']\n",
    "    sort_columns : list, optional\n",
    "        Columns to sort by. Default: ['Driver', 'LapNumber']\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The processed timing dataframe\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    ValueError\n",
    "        If the timing data structure is invalid or required columns not found\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set defaults\n",
    "    if required_columns is None:\n",
    "        required_columns = ['Driver', 'LapNumber', 'Stint', 'TotalLaps', 'Compound', 'New', 'TyresNotChanged']\n",
    "    \n",
    "    if sort_columns is None:\n",
    "        sort_columns = ['Driver', 'LapNumber']\n",
    "    \n",
    "    # Load timing app data\n",
    "    with open(timing_app_path, \"rb\") as f:\n",
    "        timing_data_raw = pickle.load(f)\n",
    "    \n",
    "    # Handle dictionary structure - extract the actual dataframe\n",
    "    if isinstance(timing_data_raw, dict):\n",
    "        if 'data' in timing_data_raw:\n",
    "            timing_data = timing_data_raw['data']\n",
    "        else:\n",
    "            # Get the first non-empty value that looks like a dataframe\n",
    "            timing_data = None\n",
    "            for key, value in timing_data_raw.items():\n",
    "                if hasattr(value, 'shape') and hasattr(value, 'columns'):\n",
    "                    timing_data = value\n",
    "                    break\n",
    "            if timing_data is None:\n",
    "                raise ValueError(f\"Could not find DataFrame in timing data. Available keys: {list(timing_data_raw.keys())}\")\n",
    "    else:\n",
    "        timing_data = timing_data_raw\n",
    "    \n",
    "    # Check which columns exist in the data\n",
    "    existing_columns = [col for col in required_columns if col in timing_data.columns]\n",
    "    \n",
    "    # Extract only existing columns\n",
    "    timing_df_filtered = timing_data[existing_columns].copy()\n",
    "    \n",
    "    # Fill TyresNotChanged: where not 0, fill with 1\n",
    "    # 0 = tires were changed, 1 = tires NOT changed\n",
    "    if 'TyresNotChanged' in timing_df_filtered.columns:\n",
    "        timing_df_filtered['TyresNotChanged'] = timing_df_filtered['TyresNotChanged'].fillna(1)\n",
    "    \n",
    "    # Sort by specified columns (only use columns that exist)\n",
    "    sort_cols_existing = [col for col in sort_columns if col in timing_df_filtered.columns]\n",
    "    if sort_cols_existing:\n",
    "        timing_df_filtered = timing_df_filtered.sort_values(by=sort_cols_existing).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    timing_df_filtered.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"✓ Timing data extracted and saved to: {output_csv_path}\")\n",
    "    print(f\"  Shape: {timing_df_filtered.shape}\")\n",
    "    print(f\"  Columns: {list(timing_df_filtered.columns)}\")\n",
    "    \n",
    "    return timing_df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167cc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Timing data extracted and saved to: csv_output/2023/Bahrain_GP_2023_timing_laps_data_raw.csv\n",
      "  Shape: (1307, 7)\n",
      "  Columns: ['Driver', 'LapNumber', 'Stint', 'TotalLaps', 'Compound', 'New', 'TyresNotChanged']\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "\n",
    "# Extract timing app data\n",
    "timing_app_path = os.path.join(base_path, \"timing_app_data.ff1pkl\")\n",
    "output_path_step1 = 'csv_output/2023/Bahrain_GP_2023_timing_laps_data_raw.csv'\n",
    "\n",
    "timing_df_filtered = extract_timing_app_data(\n",
    "    timing_app_path=timing_app_path,\n",
    "    output_csv_path=output_path_step1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align and clean timing data\n",
    "\n",
    "def align_and_clean_timing_data(\n",
    "    timing_df,\n",
    "    output_csv_path=None,\n",
    "    verbose=True,\n",
    "    drop_columns=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Align tire information and clean timing data by driver and stint.\n",
    "    \n",
    "    This function:\n",
    "    1. Forward fills Compound and TyresNotChanged within each Driver+Stint group\n",
    "    2. Creates LapInStint column from TotalLaps\n",
    "    3. Removes rows with missing critical data (Compound or TotalLaps)\n",
    "    4. Creates per-driver lap counters\n",
    "    5. Marks tire changes (New flag) at stint starts\n",
    "    6. Converts TyresNotChanged to numeric type\n",
    "    7. Optionally removes redundant columns\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    timing_df : pd.DataFrame\n",
    "        Input timing dataframe with columns: Driver, Stint, Compound, TotalLaps, TyresNotChanged, New\n",
    "    output_csv_path : str, optional\n",
    "        Path to save the cleaned CSV. If None, no file is saved.\n",
    "    verbose : bool, default=True\n",
    "        If True, prints alignment and completeness summaries\n",
    "    drop_columns : list, optional\n",
    "        Columns to drop before returning. Default: ['TotalLaps']\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Cleaned and aligned timing dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if drop_columns is None:\n",
    "        drop_columns = ['TotalLaps']\n",
    "    \n",
    "    # Create a working copy to avoid modifying the original\n",
    "    df = timing_df.copy()\n",
    "    \n",
    "    \n",
    "    # Step 1: Forward fill tire information within each Driver+Stint group\n",
    "    for (driver, stint), group_idx in df.groupby(['Driver', 'Stint']).groups.items():\n",
    "        # Forward fill Compound (identifies tire type - same throughout stint)\n",
    "        df.loc[group_idx, 'Compound'] = df.loc[group_idx, 'Compound'].ffill()\n",
    "        \n",
    "        # Forward fill TyresNotChanged (BEFORE filtering) to preserve tire state information\n",
    "        df.loc[group_idx, 'TyresNotChanged'] = df.loc[group_idx, 'TyresNotChanged'].ffill()\n",
    "    \n",
    "   \n",
    "    # Step 2: Create LapInStint column\n",
    "    df['LapInStint'] = df['TotalLaps']\n",
    "    \n",
    "   \n",
    "    # Step 3: Remove rows with missing critical data\n",
    "    rows_initial = len(df)\n",
    "    \n",
    "    # Drop rows with no useful data (no Compound AND no TotalLaps)\n",
    "    df_clean = df[\n",
    "        df['Compound'].notna() | df['TotalLaps'].notna()\n",
    "    ].copy()\n",
    "    \n",
    "    rows_after_first_filter = len(df_clean)\n",
    "    \n",
    "    # Remove rows where TotalLaps is missing (essential for lap sequencing)\n",
    "    rows_before = len(df_clean)\n",
    "    df_clean = df_clean[\n",
    "        df_clean['TotalLaps'].notna()\n",
    "    ].copy()\n",
    "    rows_after = len(df_clean)\n",
    "    \n",
    "\n",
    "    # Step 4: Create per-driver lap counter\n",
    "    df_clean['LapNumber'] = 0\n",
    "    for driver in df_clean['Driver'].unique():\n",
    "        driver_mask = df_clean['Driver'] == driver\n",
    "        driver_indices = df_clean[driver_mask].index\n",
    "        df_clean.loc[driver_indices, 'LapNumber'] = range(1, len(driver_indices) + 1)\n",
    "    \n",
    "   \n",
    "    # Step 5: Mark \"New\" tires only at stint start\n",
    "    df_clean['New'] = False  # Initialize all as FALSE\n",
    "    \n",
    "    for (driver, stint), group_idx in df_clean.groupby(['Driver', 'Stint']).groups.items():\n",
    "        group_indices = list(group_idx)\n",
    "        if len(group_indices) > 0:\n",
    "            # Set ONLY the first row of each stint to TRUE (new tires at start)\n",
    "            first_idx = group_indices[0]\n",
    "            df_clean.loc[first_idx, 'New'] = True\n",
    "    \n",
    "\n",
    "    # Step 6: Convert TyresNotChanged to numeric\n",
    "    df_clean['TyresNotChanged'] = pd.to_numeric(\n",
    "        df_clean['TyresNotChanged'], \n",
    "        errors='coerce'\n",
    "    ).fillna(1).astype(int)\n",
    "    \n",
    "\n",
    "    # Print summaries\n",
    "    if verbose:\n",
    "        print(f\"\\nRows removed:\")\n",
    "        print(f\"  Initial rows: {rows_initial}\")\n",
    "        print(f\"  After first filter (no Compound & no TotalLaps): {rows_initial - rows_after_first_filter}\")\n",
    "        print(f\"  After removing missing TotalLaps: {rows_before - rows_after}\")\n",
    "        print(f\"  Final rows: {rows_after}\")\n",
    "        \n",
    "        print(f\"\\nData Completeness:\")\n",
    "        for col in df_clean.columns:\n",
    "            non_null_count = df_clean[col].notna().sum()\n",
    "            empty_count = len(df_clean) - non_null_count\n",
    "            if empty_count > 0:\n",
    "                print(f\"  {col}: {empty_count} empty values\")\n",
    "            else:\n",
    "                print(f\"   {col}: complete (no empty values)\")\n",
    "        \n",
    "        print(f\"\\nTyresNotChanged unique values: {sorted(df_clean['TyresNotChanged'].unique())}\")\n",
    "    \n",
    "\n",
    "    # Step 7: Drop redundant columns\n",
    "    df_final = df_clean.drop(columns=drop_columns)\n",
    "    \n",
    "    \n",
    "    # Step 8: Save to CSV\n",
    "    if output_csv_path:\n",
    "        df_final.to_csv(output_csv_path, index=False)\n",
    "        if verbose:\n",
    "            print(f\"✓ Cleaned data saved to: {output_csv_path}\\n\")\n",
    "    \n",
    "    return df_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639130d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows removed:\n",
      "  Initial rows: 1307\n",
      "  After first filter (no Compound & no TotalLaps): 139\n",
      "  After removing missing TotalLaps: 58\n",
      "  Final rows: 1110\n",
      "\n",
      "Data Completeness:\n",
      "   Driver: complete (no empty values)\n",
      "   LapNumber: complete (no empty values)\n",
      "   Stint: complete (no empty values)\n",
      "   TotalLaps: complete (no empty values)\n",
      "   Compound: complete (no empty values)\n",
      "   New: complete (no empty values)\n",
      "   TyresNotChanged: complete (no empty values)\n",
      "   LapInStint: complete (no empty values)\n",
      "\n",
      "TyresNotChanged unique values: [0, 1]\n",
      "✓ Cleaned data saved to: csv_output/2023/Bahrain_GP_2023_timing_laps_data_cleaned.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# usage:\n",
    "\n",
    "# Align and clean the timing data\n",
    "output_path_step2 = 'csv_output/2023/Bahrain_GP_2023_timing_laps_data_cleaned.csv'\n",
    "\n",
    "timing_df_final = align_and_clean_timing_data(\n",
    "    timing_df=timing_df_filtered,\n",
    "    output_csv_path=output_path_step2,\n",
    "    verbose=True,\n",
    "    drop_columns=['TotalLaps']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c82091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Function to merge lap times and timing data\n",
    "# ============================================================================\n",
    "\n",
    "def merge_lap_timing_data(\n",
    "    lap_times_path,\n",
    "    timing_data_path,\n",
    "    output_path=None,\n",
    "    lap_times_file_type='xlsx',\n",
    "    lap_number_column_lap_times='NumberOfLaps',\n",
    "    lap_number_column_timing='LapNumber',\n",
    "    driver_race_number_column='RacingNumber',\n",
    "    timing_driver_column='Driver'\n",
    "):\n",
    "    \"\"\"\n",
    "    Merge lap times data with timing/tires data by driver (RacingNumber) and lap number.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lap_times_path : str\n",
    "        Path to the lap times file\n",
    "    timing_data_path : str\n",
    "        Path to the timing data CSV file\n",
    "    output_path : str, optional\n",
    "        Path to save the merged data as Excel or CSV\n",
    "    lap_times_file_type : str, default='xlsx'\n",
    "        File type of lap times data ('xlsx' or 'csv')\n",
    "    lap_number_column_lap_times : str, default='NumberOfLaps'\n",
    "        Name of the lap number column in lap times data\n",
    "    lap_number_column_timing : str, default='LapNumber'\n",
    "        Name of the lap number column in timing data\n",
    "    driver_race_number_column : str, default='RacingNumber'\n",
    "        Name of the racing number column in lap times data\n",
    "    timing_driver_column : str, default='Driver'\n",
    "        Name of the driver column in timing data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Merged dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    if lap_times_file_type.lower() == 'xlsx':\n",
    "        lap_times_df = pd.read_excel(lap_times_path)\n",
    "    else:\n",
    "        lap_times_df = pd.read_csv(lap_times_path)\n",
    "    \n",
    "    timing_df = pd.read_csv(timing_data_path)\n",
    "    \n",
    "    # Create merge keys\n",
    "    lap_times_df['_merge_driver'] = pd.to_numeric(lap_times_df[driver_race_number_column], errors='coerce')\n",
    "    lap_times_df['_merge_lap'] = pd.to_numeric(lap_times_df[lap_number_column_lap_times], errors='coerce')\n",
    "    \n",
    "    timing_df['_merge_driver'] = pd.to_numeric(timing_df[timing_driver_column], errors='coerce')\n",
    "    timing_df['_merge_lap'] = pd.to_numeric(timing_df[lap_number_column_timing], errors='coerce')\n",
    "    \n",
    "    # Remove invalid rows and merge\n",
    "    lap_times_df = lap_times_df.dropna(subset=['_merge_driver', '_merge_lap'])\n",
    "    timing_df = timing_df.dropna(subset=['_merge_driver', '_merge_lap'])\n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        lap_times_df,\n",
    "        timing_df,\n",
    "        left_on=['_merge_driver', '_merge_lap'],\n",
    "        right_on=['_merge_driver', '_merge_lap'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    merged_df = merged_df.drop(columns=['_merge_driver', '_merge_lap'])\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    cols_to_remove = []\n",
    "    if lap_number_column_lap_times in merged_df.columns and lap_number_column_timing in merged_df.columns:\n",
    "        cols_to_remove.append(lap_number_column_timing)\n",
    "    if driver_race_number_column in merged_df.columns and timing_driver_column in merged_df.columns:\n",
    "        cols_to_remove.append(timing_driver_column)\n",
    "    \n",
    "    if cols_to_remove:\n",
    "        merged_df = merged_df.drop(columns=[col for col in cols_to_remove if col in merged_df.columns])\n",
    "    \n",
    "    # Save if path provided\n",
    "    if output_path:\n",
    "        if output_path.endswith('.xlsx'):\n",
    "            merged_df.to_excel(output_path, index=False)\n",
    "        else:\n",
    "            merged_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage:\n",
    "\n",
    "merged_race_data = merge_lap_timing_data(\n",
    "    lap_times_path='csv_output/2023/Bahrain_GP_2023_lap_times.xlsx',\n",
    "    timing_data_path='csv_output/2023/Bahrain_GP_2023_timing_laps_data_cleaned.csv',\n",
    "    output_path='csv_output/2023/Bahrain_GP_2023_merged_lap_timing_data.xlsx'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ddb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_race_data_with_weather(merged_race_data, race_cache_path, tolerance_seconds=30):\n",
    "    \"\"\"\n",
    "    Merge race lap data with weather data using nearest time matching.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    merged_race_data : pd.DataFrame\n",
    "        DataFrame with lap timing data including 'Time' and 'RacingNumber' columns\n",
    "    race_cache_path : str\n",
    "        Path to race cache directory (e.g., \"cache/2023/2023-09-03_Italian_Grand_Prix/2023-09-03_Race\")\n",
    "    tolerance_seconds : int\n",
    "        Time tolerance in seconds for matching (default: 30)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Merged dataset with weather columns added, sorted by RacingNumber and lap progression\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load weather data from pickle file\n",
    "    weather_pkl_path = os.path.join(race_cache_path, 'weather_data.ff1pkl')\n",
    "    with open(weather_pkl_path, 'rb') as f:\n",
    "        weather_data_dict = pickle.load(f)\n",
    "    \n",
    "    df_weather = pd.DataFrame(weather_data_dict['data'])\n",
    "    df_weather['Time'] = df_weather['Time'].astype(str)\n",
    "    \n",
    "    # Create a copy for merging (preserve original)\n",
    "    df_for_merge = merged_race_data.copy()\n",
    "    original_columns = list(merged_race_data.columns)\n",
    "    \n",
    "    # Convert Time columns to timedelta for matching\n",
    "    df_for_merge['Time_td'] = pd.to_timedelta(df_for_merge['Time'])\n",
    "    df_weather['Time_td'] = pd.to_timedelta(df_weather['Time'])\n",
    "    \n",
    "    # Sort by time\n",
    "    df_for_merge_sorted = df_for_merge.sort_values('Time_td').reset_index(drop=True)\n",
    "    df_weather_sorted = df_weather.sort_values('Time_td').reset_index(drop=True)\n",
    "    \n",
    "    # Merge on nearest time\n",
    "    result = pd.merge_asof(\n",
    "        df_for_merge_sorted,\n",
    "        df_weather_sorted[['Time_td', 'AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed']],\n",
    "        left_on='Time_td',\n",
    "        right_on='Time_td',\n",
    "        direction='nearest',\n",
    "        tolerance=pd.Timedelta(f'{tolerance_seconds}s')\n",
    "    )\n",
    "    \n",
    "    # Restore original column order and add weather columns at end\n",
    "    weather_columns = ['AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed']\n",
    "    final_columns = original_columns + weather_columns\n",
    "    result = result[final_columns]\n",
    "    \n",
    "    # Sort by RacingNumber and lap progression\n",
    "    result = result.sort_values(\n",
    "        by=['RacingNumber', 'NumberOfLaps'],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_cache_path = 'cache/2023/2023-03-05_Bahrain_Grand_Prix/2023-03-05_Race'\n",
    "merged_race_data_with_weather = merge_race_data_with_weather(\n",
    "    merged_race_data=merged_race_data,\n",
    "    race_cache_path=race_cache_path,\n",
    "    tolerance_seconds=30\n",
    ")\n",
    "\n",
    "# Save to Excel file\n",
    "output_file = 'csv_output/2023/Bahrain_GP_2023_merged_lap_timing_with_weather.xlsx'\n",
    "merged_race_data_with_weather.to_excel(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d80a28",
   "metadata": {},
   "source": [
    "# So far the second dataset has been done just for one race. Now extend it to full season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Circuit_spec_with_round = pd.read_csv('csv_output/circuit_specs_with_rounds_2018_2025.csv')\n",
    "\n",
    "Circuit_spec_with_round.drop(columns=[\"length_km\", \"turns\" , \"type\" , \"num_drs_zones\" , \"turns\", \"length_km\", \"type\" , \"num_drs_zones\"], inplace=True)\n",
    "\n",
    "# save to csv\n",
    "\n",
    "Circuit_spec_with_round.to_csv('csv_output/Rounds_2018_2025.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b3a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning cache for Race sessions in years: ['2025']\n",
      "✓ Discovered 20 Race sessions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# HELPER FUNCTIONS: Race Discovery and Output Directory Management\n",
    "\n",
    "def discover_races_in_cache(cache_dir='cache', years=None, session_type='Race'):\n",
    "    \"\"\"\n",
    "    Discover all race sessions in the cache directory.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cache_dir : str, default='cache'\n",
    "        Base cache directory path\n",
    "    years : list, optional\n",
    "        Specific years to process (e.g., [2023, 2024]).\n",
    "        If None, all years in cache are processed.\n",
    "    session_type : str, default='Race'\n",
    "        Session type to find ('Race' or 'Qualifying'). Default is 'Race'.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of dict\n",
    "        Each dict contains:\n",
    "        - 'year': int (e.g., 2023)\n",
    "        - 'race_name': str (e.g., '2023-09-03_Italian_Grand_Prix')\n",
    "        - 'race_dir': str (e.g., 'cache/2023/2023-09-03_Italian_Grand_Prix')\n",
    "        - 'session_path': str (e.g., 'cache/2023/2023-09-03_Italian_Grand_Prix/2023-09-03_Race')\n",
    "        - 'session_date': str (e.g., '2023-09-03')\n",
    "        - 'session_type': str ('Race' or 'Qualifying')\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> races = discover_races_in_cache(years=[2023])\n",
    "    >>> print(f\"Found {len(races)} races in 2023\")\n",
    "    >>> for race in races:\n",
    "    ...     print(f\"  {race['race_name']} -> {race['session_path']}\")\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    discovered_races = []\n",
    "    cache_path = cache_dir\n",
    "    \n",
    "    # Get list of years to process\n",
    "    if not os.path.isdir(cache_path):\n",
    "        print(f\"ERROR: Cache directory not found: {cache_path}\")\n",
    "        return discovered_races\n",
    "    \n",
    "    all_years = sorted([d for d in os.listdir(cache_path) \n",
    "                       if os.path.isdir(os.path.join(cache_path, d)) and d.isdigit()])\n",
    "    \n",
    "    if years:\n",
    "        years_to_process = [str(y) for y in years if str(y) in all_years]\n",
    "    else:\n",
    "        years_to_process = all_years\n",
    "    \n",
    "    print(f\"Scanning cache for {session_type} sessions in years: {years_to_process}\")\n",
    "    \n",
    "    # Scan each year\n",
    "    for year_str in years_to_process:\n",
    "        year_path = os.path.join(cache_path, year_str)\n",
    "        year_int = int(year_str)\n",
    "        \n",
    "        # Get all race folders in this year (excluding season_schedule.ff1pkl)\n",
    "        race_folders = sorted([d for d in os.listdir(year_path) \n",
    "                              if os.path.isdir(os.path.join(year_path, d))])\n",
    "        \n",
    "        # For each race folder, find the session subfolder\n",
    "        for race_folder in race_folders:\n",
    "            race_dir = os.path.join(year_path, race_folder)\n",
    "            \n",
    "            # Find session subfolder (e.g., \"2023-09-03_Race\" or \"2023-09-02_Qualifying\")\n",
    "            session_folders = sorted([d for d in os.listdir(race_dir)\n",
    "                                     if os.path.isdir(os.path.join(race_dir, d)) and session_type in d])\n",
    "            \n",
    "            # Typically only 1 session of each type, but handle multiple\n",
    "            for session_folder in session_folders:\n",
    "                session_path = os.path.join(race_dir, session_folder)\n",
    "                \n",
    "                # Extract session date (e.g., \"2023-09-03\" from \"2023-09-03_Race\")\n",
    "                session_date = session_folder.replace(f\"_{session_type}\", \"\")\n",
    "                \n",
    "                discovered_races.append({\n",
    "                    'year': year_int,\n",
    "                    'race_name': race_folder,\n",
    "                    'race_dir': race_dir,\n",
    "                    'session_path': session_path,\n",
    "                    'session_date': session_date,\n",
    "                    'session_type': session_type\n",
    "                })\n",
    "    \n",
    "    print(f\"✓ Discovered {len(discovered_races)} {session_type} sessions\\n\")\n",
    "    return discovered_races\n",
    "\n",
    "\n",
    "def build_race_output_dir(race_info, base_output='csv_output', create_dir=True):\n",
    "    \"\"\"\n",
    "    Build organized output directory structure for a race.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    race_info : dict\n",
    "        Dictionary from discover_races_in_cache() containing race metadata\n",
    "    base_output : str, default='csv_output'\n",
    "        Base output directory\n",
    "    create_dir : bool, default=True\n",
    "        If True, creates the directory if it doesn't exist\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Contains:\n",
    "        - 'base_dir': str (e.g., 'csv_output/2023/Italian_Grand_Prix')\n",
    "        - 'year': int\n",
    "        - 'race_name_clean': str (race name without date prefix)\n",
    "        - 'full_path': str (absolute path to output directory)\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> output_info = build_race_output_dir(race_info)\n",
    "    >>> lap_times_file = os.path.join(output_info['base_dir'], 'lap_times.xlsx')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract race name (remove date prefix)\n",
    "    # e.g., \"2023-09-03_Italian_Grand_Prix\" -> \"Italian_Grand_Prix\"\n",
    "    race_name_parts = race_info['race_name'].split('_')\n",
    "    race_name_clean = '_'.join(race_name_parts[1:])  # Remove YYYY-MM-DD\n",
    "    \n",
    "    # Build output directory structure\n",
    "    year_str = str(race_info['year'])\n",
    "    output_dir = os.path.join(base_output, year_str, race_name_clean)\n",
    "    \n",
    "    # Create directory if needed\n",
    "    if create_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    return {\n",
    "        'base_dir': output_dir,\n",
    "        'year': race_info['year'],\n",
    "        'race_name_clean': race_name_clean,\n",
    "        'full_path': os.path.abspath(output_dir)\n",
    "    }\n",
    "\n",
    "\n",
    "races_2025 = discover_races_in_cache(years=[2025])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract Driver Info for the whole Season\n",
    "\n",
    "def extract_drivers_for_race(base_path):\n",
    "    \"\"\"\n",
    "    Extract driver information for a single race from a given cache path.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_path : str\n",
    "        Path to race cache directory (e.g., \"cache/2023/2023-09-03_Italian_Grand_Prix/2023-09-03_Race\")\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with driver info including columns:\n",
    "        - RacingNumber, FullName, TeamName\n",
    "        - year, round, name, countryId (if circuit data found)\n",
    "    \"\"\"\n",
    "    # Load driver info\n",
    "    driver_path = os.path.join(base_path, \"driver_info.ff1pkl\")\n",
    "    with open(driver_path, 'rb') as f:\n",
    "        drivers = pickle.load(f)\n",
    "    \n",
    "    # Extract drivers info from the 'data' key (it's a defaultdict)\n",
    "    drivers_data = drivers['data']\n",
    "    \n",
    "    # Extract all drivers\n",
    "    drivers_info = []\n",
    "    for driver_num, driver_dict in drivers_data.items():\n",
    "        try:\n",
    "            drivers_info.append({\n",
    "                'RacingNumber': driver_dict['RacingNumber'],\n",
    "                'FullName': driver_dict['FullName'],\n",
    "                'TeamName': driver_dict['TeamName']\n",
    "            })\n",
    "        except (KeyError, TypeError):\n",
    "            continue\n",
    "    \n",
    "    drivers_df = pd.DataFrame(drivers_info)\n",
    "    \n",
    "    # Try to add circuit info  \n",
    "    try:\n",
    "        circuit_df = pd.read_csv('csv_output/Rounds_2018_2025.csv')\n",
    "        # Extract year from path\n",
    "        year = int(base_path.split('/')[-3])\n",
    "        \n",
    "        # Extract round number by counting chronologically\n",
    "        # Get year folder and find this race's position\n",
    "        year_folder = base_path.split('/')[-3]\n",
    "        race_folder = base_path.split('/')[-2]\n",
    "        races_in_year = sorted([d for d in os.listdir(f\"cache/{year_folder}\") if os.path.isdir(f\"cache/{year_folder}/{d}\")])\n",
    "        \n",
    "        try:\n",
    "            round_num = races_in_year.index(race_folder) + 1\n",
    "        except (ValueError, IndexError):\n",
    "            round_num = None\n",
    "        \n",
    "        # Get circuit info for this year and round\n",
    "        if round_num:\n",
    "            circuit_info = circuit_df[(circuit_df['year'] == year) & (circuit_df['round'] == round_num)]\n",
    "            if not circuit_info.empty:\n",
    "                circuit_info = circuit_info.iloc[0]\n",
    "                for col in ['year', 'round', 'name', 'countryId']:\n",
    "                    if col in circuit_info.index:\n",
    "                        drivers_df[col] = circuit_info[col]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    return drivers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba340a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract drivers for EVERY RACE using helper functions\n",
    "\n",
    "all_drivers_by_race = {}\n",
    "for race in races_2025:\n",
    "    drivers_info = extract_drivers_for_race(race['session_path'])\n",
    "    all_drivers_by_race[race['race_name']] = drivers_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e662ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_lap_timing_data(base_path, drivers_info, output_path=None, tolerance_seconds=0.1):\n",
    "    \"\"\"\n",
    "    Process extended timing data and merge with driver information.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_path : str\n",
    "        Path to the directory containing the '_extended_timing_data.ff1pkl' file\n",
    "    drivers_info : pd.DataFrame\n",
    "        DataFrame containing driver information with columns:\n",
    "        ['RacingNumber', 'FullName', 'TeamName', 'year', 'round', 'name', 'countryId']\n",
    "    output_path : str, optional\n",
    "        Path to save the processed data as Excel file. If None, file is not saved.\n",
    "        (default: None)\n",
    "    tolerance_seconds : float, optional\n",
    "        Tolerance in seconds for merging lap and position data (default: 0.05)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Processed dataframe with columns:\n",
    "        ['year', 'round', 'name', 'countryId', 'Name', 'Team', 'RacingNumber', \n",
    "         'Time', 'NumberOfLaps', 'LapTime', 'Position', 'IntervalToPositionAhead', 'NumberOfPitStops']\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loading Data \n",
    "    fpath = os.path.join(base_path, \"_extended_timing_data.ff1pkl\")\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    \n",
    "    data = d[\"data\"]  # the real stuff\n",
    "    extended_timing_df = data[0].copy()\n",
    "    \n",
    "    # Extract Lap Data\n",
    "    lap_data = extended_timing_df[['Driver', 'Time', 'NumberOfLaps', 'LapTime', 'NumberOfPitStops']].copy()\n",
    "    lap_data_sorted = lap_data.sort_values(by=['Driver', 'NumberOfLaps']).reset_index(drop=True)\n",
    "    \n",
    "    # Extract Position Data\n",
    "    position_data = data[1][['Driver', 'Time', 'Position', 'GapToLeader', 'IntervalToPositionAhead']].copy()\n",
    "    \n",
    "    # Clean Data \n",
    "    lap_data_clean = lap_data_sorted[lap_data_sorted['Time'].notna()].copy()\n",
    "    position_data_clean = position_data[position_data['Time'].notna()].copy()\n",
    "    \n",
    "    # Convert Time to total seconds for more reliable merging\n",
    "    def timedelta_to_seconds(td):\n",
    "        \"\"\"Convert timedelta to total seconds\"\"\"\n",
    "        if pd.isna(td):\n",
    "            return None\n",
    "        return td.total_seconds()\n",
    "    \n",
    "    lap_data_clean['Time_seconds'] = lap_data_clean['Time'].apply(timedelta_to_seconds)\n",
    "    position_data_clean['Time_seconds'] = position_data_clean['Time'].apply(timedelta_to_seconds)\n",
    "    \n",
    "    # Normalize Driver to string and remove rows with NaN Time_seconds\n",
    "    lap_data_clean['Driver'] = lap_data_clean['Driver'].astype(str)\n",
    "    position_data_clean['Driver'] = position_data_clean['Driver'].astype(str)\n",
    "    lap_data_clean = lap_data_clean[lap_data_clean['Time_seconds'].notna()].copy()\n",
    "    position_data_clean = position_data_clean[position_data_clean['Time_seconds'].notna()].copy()\n",
    "    \n",
    "    # Merge Lap and Position Data\n",
    "    merged_parts = []\n",
    "    for driver in lap_data_clean['Driver'].unique():\n",
    "        lap_driver = lap_data_clean[lap_data_clean['Driver'] == driver].sort_values('Time_seconds').reset_index(drop=True)\n",
    "        pos_driver = position_data_clean[position_data_clean['Driver'] == driver].sort_values('Time_seconds').reset_index(drop=True)\n",
    "        \n",
    "        if len(pos_driver) == 0:\n",
    "            merged_parts.append(lap_driver)\n",
    "            continue\n",
    "        \n",
    "        merged_driver = pd.merge_asof(\n",
    "            lap_driver,\n",
    "            pos_driver[['Time_seconds', 'Position', 'GapToLeader', 'IntervalToPositionAhead']],\n",
    "            on='Time_seconds',\n",
    "            direction='nearest',\n",
    "            tolerance=tolerance_seconds\n",
    "        )\n",
    "        merged_parts.append(merged_driver)\n",
    "    \n",
    "    lap_data_merged = pd.concat(merged_parts, ignore_index=True)\n",
    "    lap_data_merged = lap_data_merged.drop(columns=['Time_seconds'])\n",
    "    lap_data_sorted = lap_data_merged.sort_values(by=['Driver', 'NumberOfLaps']).reset_index(drop=True)\n",
    "    \n",
    "    # Shift only IntervalToPositionAhead column down by one row\n",
    "    lap_data_sorted['IntervalToPositionAhead'] = lap_data_sorted['IntervalToPositionAhead'].shift(1)\n",
    "    \n",
    "    print(f\"✓ Merged {len(lap_data_sorted)} records with position and interval data\")\n",
    "    \n",
    "    # Merge with Driver Info\n",
    "    lap_data_detailed = lap_data_sorted.merge(\n",
    "        drivers_info[['RacingNumber', 'FullName', 'TeamName', 'year', 'round', 'name', 'countryId']], \n",
    "        left_on='Driver', \n",
    "        right_on='RacingNumber',\n",
    "        how='left'\n",
    "    )\n",
    "    lap_data_detailed = lap_data_detailed.drop(columns=['Driver'])\n",
    "    \n",
    "    # Convert LapTime to Seconds \n",
    "    lap_data_detailed['LapTime'] = lap_data_detailed['LapTime'].astype(str).str.split().str[-1]\n",
    "    \n",
    "    def time_to_seconds(time_str):\n",
    "        \"\"\"Convert time string (HH:MM:SS.microseconds) to total seconds\"\"\"\n",
    "        if pd.isna(time_str) or time_str == 'NaT':\n",
    "            return None\n",
    "        try:\n",
    "            parts = time_str.split(':')\n",
    "            hours = int(parts[0])\n",
    "            minutes = int(parts[1])\n",
    "            seconds = float(parts[2])\n",
    "            total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "            return round(total_seconds, 3)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    lap_data_detailed['LapTime'] = lap_data_detailed['LapTime'].apply(time_to_seconds)\n",
    "    \n",
    "    # Format and Export\n",
    "    lap_data_detailed = lap_data_detailed.rename(columns={\n",
    "        'FullName': 'Name',\n",
    "        'TeamName': 'Team'\n",
    "    })\n",
    "    \n",
    "    column_order = ['year', 'round', 'name', 'countryId', 'Name', 'Team', 'RacingNumber', \n",
    "                    'Time', 'NumberOfLaps', 'LapTime', 'Position', 'IntervalToPositionAhead', 'NumberOfPitStops']\n",
    "    lap_data_detailed = lap_data_detailed[column_order]\n",
    "    lap_data_detailed['Time'] = lap_data_detailed['Time'].astype(str)\n",
    "    \n",
    "    if output_path:\n",
    "        lap_data_detailed.to_excel(output_path, index=False, sheet_name='Lap Data')\n",
    "        \n",
    "    \n",
    "    return lap_data_detailed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561d196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Merged 921 records with position and interval data\n",
      "✓ 2025-03-16_Australian_Grand_Prix\n",
      "✓ Merged 1065 records with position and interval data\n",
      "✓ 2025-03-23_Chinese_Grand_Prix\n",
      "✓ Merged 1059 records with position and interval data\n",
      "✓ 2025-04-06_Japanese_Grand_Prix\n",
      "✓ Merged 1128 records with position and interval data\n",
      "✓ 2025-04-13_Bahrain_Grand_Prix\n",
      "✓ Merged 897 records with position and interval data\n",
      "✓ 2025-04-20_Saudi_Arabian_Grand_Prix\n",
      "✓ Merged 1002 records with position and interval data\n",
      "✓ 2025-05-04_Miami_Grand_Prix\n",
      "✓ Merged 1205 records with position and interval data\n",
      "✓ 2025-05-18_Emilia_Romagna_Grand_Prix\n",
      "✓ Merged 1424 records with position and interval data\n",
      "✓ 2025-05-25_Monaco_Grand_Prix\n",
      "✓ Merged 1202 records with position and interval data\n",
      "✓ 2025-06-01_Spanish_Grand_Prix\n",
      "✓ Merged 1347 records with position and interval data\n",
      "✓ 2025-06-15_Canadian_Grand_Prix\n",
      "✓ Merged 1124 records with position and interval data\n",
      "✓ 2025-06-29_Austrian_Grand_Prix\n",
      "✓ Merged 822 records with position and interval data\n",
      "✓ 2025-07-06_British_Grand_Prix\n",
      "✓ Merged 879 records with position and interval data\n",
      "✓ 2025-07-27_Belgian_Grand_Prix\n",
      "✓ Merged 1368 records with position and interval data\n",
      "✓ 2025-08-03_Hungarian_Grand_Prix\n",
      "✓ Merged 1362 records with position and interval data\n",
      "✓ 2025-08-31_Dutch_Grand_Prix\n",
      "✓ Merged 974 records with position and interval data\n",
      "✓ 2025-09-07_Italian_Grand_Prix\n",
      "✓ Merged 967 records with position and interval data\n",
      "✓ 2025-09-21_Azerbaijan_Grand_Prix\n",
      "✓ Merged 1229 records with position and interval data\n",
      "✓ 2025-10-05_Singapore_Grand_Prix\n",
      "✓ Merged 1066 records with position and interval data\n",
      "✓ 2025-10-19_United_States_Grand_Prix\n",
      "✓ Merged 1262 records with position and interval data\n",
      "✓ 2025-10-26_Mexico_City_Grand_Prix\n",
      "\n",
      "✓ Processed and saved 20 races to: csv_output/2025_All_Races_Lap_Times.xlsx\n"
     ]
    }
   ],
   "source": [
    "# The commented one do it for every race , in the uncommented one we skip the dutch grand prix as it has issues\n",
    "\n",
    "# Process lap timing data for EVERY RACE and save to SINGLE file\n",
    "all_lap_data_list = []\n",
    "for race in races_2025:\n",
    "    race_name = race['race_name']\n",
    "    drivers_info = all_drivers_by_race[race_name]\n",
    "    \n",
    "    # Process lap timing data (no output_path to avoid saving individual files)\n",
    "    lap_data = process_lap_timing_data(\n",
    "        base_path=race['session_path'],\n",
    "        drivers_info=drivers_info,\n",
    "        output_path=None\n",
    "    )\n",
    "    all_lap_data_list.append(lap_data)\n",
    "    print(f\"✓ {race_name}\")\n",
    "\n",
    "# Combine all races into ONE dataframe\n",
    "all_lap_data_combined = pd.concat(all_lap_data_list, ignore_index=True)\n",
    "\n",
    "# Save to single file\n",
    "all_lap_data_combined.to_excel('csv_output/2025_All_Races_Lap_Times.xlsx', index=False, sheet_name='Lap Data')\n",
    "print(f\"\\n✓ Processed and saved {len(all_lap_data_list)} races to: csv_output/2025_All_Races_Lap_Times.xlsx\")\n",
    "\n",
    "\n",
    "# # Process lap timing data for every race \n",
    "# all_lap_data_list = []\n",
    "# skipped_races = []\n",
    "\n",
    "# for race in races_2024:\n",
    "#     race_name = race['race_name']\n",
    "    \n",
    "#     # Skip races that don't work\n",
    "#     if 'Las_Vegas_Grand_Prix' in race_name:\n",
    "#         skipped_races.append(race_name)\n",
    "#         print(f\"⊘ SKIPPED {race_name}\")\n",
    "#         continue\n",
    "    \n",
    "#     drivers_info = all_drivers_by_race[race_name]\n",
    "    \n",
    "#     # Process lap timing data (no output_path to avoid saving individual files)\n",
    "#     lap_data = process_lap_timing_data(\n",
    "#         base_path=race['session_path'],\n",
    "#         drivers_info=drivers_info,\n",
    "#         output_path=None\n",
    "#     )\n",
    "#     all_lap_data_list.append(lap_data)\n",
    "#     print(f\"✓ {race_name}\")\n",
    "\n",
    "# # Combine all races into ONE dataframe\n",
    "# all_lap_data_combined = pd.concat(all_lap_data_list, ignore_index=True)\n",
    "\n",
    "# # Save to single file\n",
    "# all_lap_data_combined.to_excel('csv_output/2024_All_Races_Lap_Times.xlsx', index=False, sheet_name='Lap Data')\n",
    "# print(f\"\\n✓ Processed and saved {len(all_lap_data_list)} races to: csv_output/2024_All_Races_Lap_Times.xlsx\")\n",
    "# if skipped_races:\n",
    "#     print(f\"⊘ Skipped {len(skipped_races)} races: {', '.join([r.split('_')[0] for r in skipped_races])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract timing app data - Specific columns only\n",
    "\n",
    "def extract_timing_app_data(\n",
    "    timing_app_path,\n",
    "    output_csv_path=None,\n",
    "    required_columns=None,\n",
    "    sort_columns=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract and process timing app data from a pickle file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    timing_app_path : str\n",
    "        Path to the timing_app_data.ff1pkl file\n",
    "    output_csv_path : str, optional\n",
    "        Path where the processed CSV should be saved. If None, file is not saved.\n",
    "        (default: None)\n",
    "    required_columns : list, optional\n",
    "        List of columns to extract. Default: ['Driver', 'LapNumber', 'Stint', \n",
    "        'TotalLaps', 'Compound', 'New', 'TyresNotChanged']\n",
    "    sort_columns : list, optional\n",
    "        Columns to sort by. Default: ['Driver', 'LapNumber']\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The processed timing dataframe\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    ValueError\n",
    "        If the timing data structure is invalid or required columns not found\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set defaults\n",
    "    if required_columns is None:\n",
    "        required_columns = ['Driver', 'LapNumber', 'Stint', 'TotalLaps', 'Compound', 'New', 'TyresNotChanged']\n",
    "    \n",
    "    if sort_columns is None:\n",
    "        sort_columns = ['Driver', 'LapNumber']\n",
    "    \n",
    "    # Load timing app data\n",
    "    with open(timing_app_path, \"rb\") as f:\n",
    "        timing_data_raw = pickle.load(f)\n",
    "    \n",
    "    # Handle dictionary structure - extract the actual dataframe\n",
    "    if isinstance(timing_data_raw, dict):\n",
    "        if 'data' in timing_data_raw:\n",
    "            timing_data = timing_data_raw['data']\n",
    "        else:\n",
    "            # Get the first non-empty value that looks like a dataframe\n",
    "            timing_data = None\n",
    "            for key, value in timing_data_raw.items():\n",
    "                if hasattr(value, 'shape') and hasattr(value, 'columns'):\n",
    "                    timing_data = value\n",
    "                    break\n",
    "            if timing_data is None:\n",
    "                raise ValueError(f\"Could not find DataFrame in timing data. Available keys: {list(timing_data_raw.keys())}\")\n",
    "    else:\n",
    "        timing_data = timing_data_raw\n",
    "    \n",
    "    # Check which columns exist in the data\n",
    "    existing_columns = [col for col in required_columns if col in timing_data.columns]\n",
    "    \n",
    "    # Extract only existing columns\n",
    "    timing_df_filtered = timing_data[existing_columns].copy()\n",
    "    \n",
    "    # Fill TyresNotChanged: where not 0, fill with 1\n",
    "    # 0 = tires were changed, 1 = tires NOT changed\n",
    "    if 'TyresNotChanged' in timing_df_filtered.columns:\n",
    "        timing_df_filtered['TyresNotChanged'] = timing_df_filtered['TyresNotChanged'].fillna(1)\n",
    "    \n",
    "    # Sort by specified columns (only use columns that exist)\n",
    "    sort_cols_existing = [col for col in sort_columns if col in timing_df_filtered.columns]\n",
    "    if sort_cols_existing:\n",
    "        timing_df_filtered = timing_df_filtered.sort_values(by=sort_cols_existing).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV if path provided\n",
    "    if output_csv_path:\n",
    "        timing_df_filtered.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    return timing_df_filtered\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb08ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Extracted and saved timing app data for 20 races to: csv_output/2025_All_Races_Timing_App_Data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract timing app data for every race\n",
    "\n",
    "all_timing_app_data = {}\n",
    "for race in races_2025:\n",
    "    race_name = race['race_name']\n",
    "    \n",
    "    # Skip races that don't work\n",
    "    if 'Las_Vegas_Grand_Prix' in race_name:\n",
    "        continue\n",
    "    \n",
    "    timing_app_path = os.path.join(race['session_path'], \"timing_app_data.ff1pkl\")\n",
    "    \n",
    "    # Extract timing data (not saving to file, storing in memory)\n",
    "    timing_df = extract_timing_app_data(\n",
    "        timing_app_path=timing_app_path,\n",
    "        output_csv_path=None\n",
    "    )\n",
    "    all_timing_app_data[race_name] = timing_df\n",
    "\n",
    "# Combine all races into ONE dataframe WITH RACE IDENTIFICATION\n",
    "all_timing_app_list = []\n",
    "for race_name, timing_df in all_timing_app_data.items():\n",
    "    # Extract clean race name (remove date prefix: \"2023-09-03_Italian_Grand_Prix\" -> \"Italian_Grand_Prix\")\n",
    "    clean_race_name = '_'.join(race_name.split('_')[1:])\n",
    "    timing_df['race_name'] = clean_race_name\n",
    "    all_timing_app_list.append(timing_df)\n",
    "\n",
    "all_timing_app_combined = pd.concat(all_timing_app_list, ignore_index=True)\n",
    "\n",
    "# Reorder columns to put race_name first\n",
    "cols = all_timing_app_combined.columns.tolist()\n",
    "cols.remove('race_name')\n",
    "all_timing_app_combined = all_timing_app_combined[['race_name'] + cols]\n",
    "\n",
    "# Save to single CSV file\n",
    "all_timing_app_combined.to_csv('csv_output/2025_All_Races_Timing_App_Data.csv', index=False)\n",
    "print(f\"\\n✓ Extracted and saved timing app data for {len(all_timing_app_data)} races to: csv_output/2025_All_Races_Timing_App_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213aa160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_and_clean_timing_data(\n",
    "    timing_df,\n",
    "    output_csv_path=None,\n",
    "    verbose=True,\n",
    "    drop_columns=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Align tire information and clean timing data by driver and stint.\n",
    "    \n",
    "    This function:\n",
    "    1. Forward fills Compound and TyresNotChanged within each Driver+Stint group\n",
    "    2. Creates LapInStint column from TotalLaps\n",
    "    3. Removes rows with missing critical data (Compound or TotalLaps)\n",
    "    4. Creates per-driver lap counters\n",
    "    5. Marks tire changes (New flag) at stint starts\n",
    "    6. Converts TyresNotChanged to numeric type\n",
    "    7. Optionally removes redundant columns\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    timing_df : pd.DataFrame\n",
    "        Input timing dataframe with columns: Driver, Stint, Compound, TotalLaps, TyresNotChanged, New\n",
    "    output_csv_path : str, optional\n",
    "        Path to save the cleaned CSV. If None, no file is saved.\n",
    "    verbose : bool, default=True\n",
    "        If True, prints alignment and completeness summaries\n",
    "    drop_columns : list, optional\n",
    "        Columns to drop before returning. Default: ['TotalLaps']\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Cleaned and aligned timing dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if drop_columns is None:\n",
    "        drop_columns = ['TotalLaps']\n",
    "    \n",
    "    # Create a working copy to avoid modifying the original\n",
    "    df = timing_df.copy()\n",
    "    \n",
    "    # Step 1: Forward fill tire information within each Driver+Stint group\n",
    "\n",
    "    for (driver, stint), group_idx in df.groupby(['Driver', 'Stint']).groups.items():\n",
    "        # Forward fill Compound (identifies tire type - same throughout stint)\n",
    "        df.loc[group_idx, 'Compound'] = df.loc[group_idx, 'Compound'].ffill()\n",
    "        \n",
    "        # Forward fill TyresNotChanged (BEFORE filtering) to preserve tire state information\n",
    "        df.loc[group_idx, 'TyresNotChanged'] = df.loc[group_idx, 'TyresNotChanged'].ffill()\n",
    "    \n",
    "\n",
    "    # Step 2: Create LapInStint column\n",
    "    df['LapInStint'] = df['TotalLaps']\n",
    "    \n",
    "    # Step 3: Remove rows with missing critical data\n",
    "    rows_initial = len(df)\n",
    "    \n",
    "    # Drop rows with no useful data (no Compound AND no TotalLaps)\n",
    "    df_clean = df[\n",
    "        df['Compound'].notna() | df['TotalLaps'].notna()\n",
    "    ].copy()\n",
    "    \n",
    "    rows_after_first_filter = len(df_clean)\n",
    "    \n",
    "    # Remove rows where TotalLaps is missing (essential for lap sequencing)\n",
    "    rows_before = len(df_clean)\n",
    "    df_clean = df_clean[\n",
    "        df_clean['TotalLaps'].notna()\n",
    "    ].copy()\n",
    "    rows_after = len(df_clean)\n",
    "    \n",
    "    # Step 4: Create per-driver lap counters  \n",
    "    df_clean['LapNumber'] = 0\n",
    "    for driver in df_clean['Driver'].unique():\n",
    "        driver_mask = df_clean['Driver'] == driver\n",
    "        driver_indices = df_clean[driver_mask].index\n",
    "        df_clean.loc[driver_indices, 'LapNumber'] = range(1, len(driver_indices) + 1)\n",
    "    \n",
    "    \n",
    "    # Step 5: Mark \"New\" tires only at stint start\n",
    "    df_clean['New'] = False  # Initialize all as FALSE\n",
    "    \n",
    "    for (driver, stint), group_idx in df_clean.groupby(['Driver', 'Stint']).groups.items():\n",
    "        group_indices = list(group_idx)\n",
    "        if len(group_indices) > 0:\n",
    "            # Set ONLY the first row of each stint to TRUE (new tires at start)\n",
    "            first_idx = group_indices[0]\n",
    "            df_clean.loc[first_idx, 'New'] = True\n",
    "    \n",
    "\n",
    "    # Step 6: Convert TyresNotChanged to numeric\n",
    "    df_clean['TyresNotChanged'] = pd.to_numeric(\n",
    "        df_clean['TyresNotChanged'], \n",
    "        errors='coerce'\n",
    "    ).fillna(1).astype(int)\n",
    "    \n",
    "\n",
    "    # Step 7: Drop redundant columns\n",
    "    df_final = df_clean.drop(columns=drop_columns)\n",
    "    \n",
    "\n",
    "    # Step 8: Save to CSV (if path provided)\n",
    "    if output_csv_path:\n",
    "        df_final.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc596b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Aligned and cleaned timing data for 20 races to: csv_output/2025_All_Races_Timing_App_Data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage \n",
    "# Align and clean timing data for EVERY RACE\n",
    "all_timing_cleaned = {}\n",
    "for race_name, timing_df in all_timing_app_data.items():\n",
    "    timing_clean = align_and_clean_timing_data(\n",
    "        timing_df=timing_df,\n",
    "        output_csv_path=None,\n",
    "        verbose=False,\n",
    "        drop_columns=['TotalLaps']\n",
    "    )\n",
    "    all_timing_cleaned[race_name] = timing_clean\n",
    "\n",
    "# Combine all races into ONE dataframe WITH RACE IDENTIFICATION\n",
    "all_timing_cleaned_list = []\n",
    "for race_name, timing_df in all_timing_cleaned.items():\n",
    "    # Extract clean race name (remove date prefix: \"2023-09-03_Italian_Grand_Prix\" -> \"Italian_Grand_Prix\")\n",
    "    clean_race_name = '_'.join(race_name.split('_')[1:])\n",
    "    timing_df['race_name'] = clean_race_name\n",
    "    all_timing_cleaned_list.append(timing_df)\n",
    "\n",
    "all_timing_cleaned_combined = pd.concat(all_timing_cleaned_list, ignore_index=True)\n",
    "\n",
    "# Reorder columns to put race_name first\n",
    "cols = all_timing_cleaned_combined.columns.tolist()\n",
    "cols.remove('race_name')\n",
    "all_timing_cleaned_combined = all_timing_cleaned_combined[['race_name'] + cols]\n",
    "\n",
    "# Save to single CSV file\n",
    "all_timing_cleaned_combined.to_csv('csv_output/2025_All_Races_Timing_App_Data_cleaned.csv', index=False)\n",
    "print(f\"\\n✓ Aligned and cleaned timing data for {len(all_timing_cleaned)} races to: csv_output/2025_All_Races_Timing_App_Data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to merge lap times and timing data\n",
    "\n",
    "def merge_lap_timing_data(\n",
    "    lap_times_path,\n",
    "    timing_data_path,\n",
    "    output_path=None,\n",
    "    lap_times_file_type='xlsx',\n",
    "    lap_number_column_lap_times='NumberOfLaps',\n",
    "    lap_number_column_timing='LapNumber',\n",
    "    driver_race_number_column='RacingNumber',\n",
    "    timing_driver_column='Driver',\n",
    "    race_identifier_lap_times='name',\n",
    "    race_identifier_timing='race_name'\n",
    "):\n",
    "    \"\"\"\n",
    "    Merge lap times data with timing/tires data by RACE, driver (RacingNumber), and lap number.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lap_times_path : str\n",
    "        Path to the lap times file\n",
    "    timing_data_path : str\n",
    "        Path to the timing data CSV file\n",
    "    output_path : str, optional\n",
    "        Path to save the merged data as Excel or CSV\n",
    "    lap_times_file_type : str, default='xlsx'\n",
    "        File type of lap times data ('xlsx' or 'csv')\n",
    "    lap_number_column_lap_times : str, default='NumberOfLaps'\n",
    "        Name of the lap number column in lap times data\n",
    "    lap_number_column_timing : str, default='LapNumber'\n",
    "        Name of the lap number column in timing data\n",
    "    driver_race_number_column : str, default='RacingNumber'\n",
    "        Name of the racing number column in lap times data\n",
    "    timing_driver_column : str, default='Driver'\n",
    "        Name of the driver column in timing data\n",
    "    race_identifier_lap_times : str, default='name'\n",
    "        Name of the race identifier column in lap times data\n",
    "    race_identifier_timing : str, default='race_name'\n",
    "        Name of the race identifier column in timing data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Merged dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    if lap_times_file_type.lower() == 'xlsx':\n",
    "        lap_times_df = pd.read_excel(lap_times_path)\n",
    "    else:\n",
    "        lap_times_df = pd.read_csv(lap_times_path)\n",
    "    \n",
    "    timing_df = pd.read_csv(timing_data_path)\n",
    "    \n",
    "    # Create merge keys (include race identifier!)\n",
    "    lap_times_df['_merge_race'] = lap_times_df[race_identifier_lap_times].astype(str)\n",
    "    lap_times_df['_merge_driver'] = pd.to_numeric(lap_times_df[driver_race_number_column], errors='coerce')\n",
    "    lap_times_df['_merge_lap'] = pd.to_numeric(lap_times_df[lap_number_column_lap_times], errors='coerce')\n",
    "    \n",
    "    timing_df['_merge_race'] = timing_df[race_identifier_timing].astype(str)\n",
    "    timing_df['_merge_driver'] = pd.to_numeric(timing_df[timing_driver_column], errors='coerce')\n",
    "    timing_df['_merge_lap'] = pd.to_numeric(timing_df[lap_number_column_timing], errors='coerce')\n",
    "    \n",
    "    # Remove invalid rows and merge\n",
    "    lap_times_df = lap_times_df.dropna(subset=['_merge_driver', '_merge_lap'])\n",
    "    timing_df = timing_df.dropna(subset=['_merge_driver', '_merge_lap'])\n",
    "    \n",
    "    # Merge on RACE + DRIVER + LAP (not just driver + lap)\n",
    "    merged_df = pd.merge(\n",
    "        lap_times_df,\n",
    "        timing_df,\n",
    "        left_on=['_merge_race', '_merge_driver', '_merge_lap'],\n",
    "        right_on=['_merge_race', '_merge_driver', '_merge_lap'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    merged_df = merged_df.drop(columns=['_merge_race', '_merge_driver', '_merge_lap'])\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    cols_to_remove = []\n",
    "    if lap_number_column_lap_times in merged_df.columns and lap_number_column_timing in merged_df.columns:\n",
    "        cols_to_remove.append(lap_number_column_timing)\n",
    "    if driver_race_number_column in merged_df.columns and timing_driver_column in merged_df.columns:\n",
    "        cols_to_remove.append(timing_driver_column)\n",
    "    \n",
    "    if cols_to_remove:\n",
    "        merged_df = merged_df.drop(columns=[col for col in cols_to_remove if col in merged_df.columns])\n",
    "    \n",
    "    # Save if path provided\n",
    "    if output_path:\n",
    "        if output_path.endswith('.xlsx'):\n",
    "            merged_df.to_excel(output_path, index=False)\n",
    "        else:\n",
    "            merged_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4f8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Merged lap timing data: 21720 rows, 19 columns\n",
      "✓ Saved to: csv_output/2025_All_Races_Merged_Lap_Timing.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, build a dictionary of lap data from all_lap_data_list with race names as keys\n",
    "all_lap_data_dict = {}\n",
    "race_list = [race for race in races_2025 if 'Las_Vegas_Grand_Prix' not in race['race_name']]\n",
    "for idx, lap_data in enumerate(all_lap_data_list):\n",
    "    if idx < len(race_list):\n",
    "        race_full_name = race_list[idx]['race_name']\n",
    "        all_lap_data_dict[race_full_name] = lap_data\n",
    "\n",
    "# Merge lap times with cleaned timing data for ALL RACES (in memory to avoid race name mismatch)\n",
    "all_merged_races = []\n",
    "\n",
    "for race_full_name, lap_data in all_lap_data_dict.items():\n",
    "    timing_data = all_timing_cleaned.get(race_full_name)\n",
    "    \n",
    "    if timing_data is None:\n",
    "        continue\n",
    "    \n",
    "    # Merge by driver and lap number (same race, so no need for race identifier)\n",
    "    merged = pd.merge(\n",
    "        lap_data,\n",
    "        timing_data,\n",
    "        left_on=['RacingNumber', 'NumberOfLaps'],\n",
    "        right_on=['Driver', 'LapNumber'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Drop duplicate driver/lap columns\n",
    "    if 'Driver' in merged.columns:\n",
    "        merged = merged.drop(columns=['Driver'])\n",
    "    if 'LapNumber' in merged.columns:\n",
    "        merged = merged.drop(columns=['LapNumber'])\n",
    "    \n",
    "    all_merged_races.append(merged)\n",
    "\n",
    "# Combine all merged races\n",
    "merged_race_data = pd.concat(all_merged_races, ignore_index=True)\n",
    "\n",
    "# Save to file\n",
    "merged_race_data.to_excel('csv_output/2025_All_Races_Merged_Lap_Timing.xlsx', index=False, sheet_name='Merged Data')\n",
    "print(f\"\\n✓ Merged lap timing data: {merged_race_data.shape[0]} rows, {merged_race_data.shape[1]} columns\")\n",
    "print(f\"✓ Saved to: csv_output/2025_All_Races_Merged_Lap_Timing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73809e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge Lap Data with Weather Data\n",
    "\n",
    "def merge_race_data_with_weather(merged_race_data, race_cache_path, tolerance_seconds=30):\n",
    "    \"\"\"\n",
    "    Merge race lap data with weather data using nearest time matching.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    merged_race_data : pd.DataFrame\n",
    "        DataFrame with lap timing data including 'Time' and 'RacingNumber' columns\n",
    "    race_cache_path : str\n",
    "        Path to race cache directory (e.g., \"cache/2023/2023-09-03_Italian_Grand_Prix/2023-09-03_Race\")\n",
    "    tolerance_seconds : int\n",
    "        Time tolerance in seconds for matching (default: 30)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Merged dataset with weather columns added, sorted by RacingNumber and lap progression\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load weather data from pickle file\n",
    "    weather_pkl_path = os.path.join(race_cache_path, 'weather_data.ff1pkl')\n",
    "    with open(weather_pkl_path, 'rb') as f:\n",
    "        weather_data_dict = pickle.load(f)\n",
    "    \n",
    "    df_weather = pd.DataFrame(weather_data_dict['data'])\n",
    "    df_weather['Time'] = df_weather['Time'].astype(str)\n",
    "    \n",
    "    # Create a copy for merging (preserve original)\n",
    "    df_for_merge = merged_race_data.copy()\n",
    "    original_columns = list(merged_race_data.columns)\n",
    "    \n",
    "    # Convert Time columns to timedelta for matching\n",
    "    df_for_merge['Time_td'] = pd.to_timedelta(df_for_merge['Time'])\n",
    "    df_weather['Time_td'] = pd.to_timedelta(df_weather['Time'])\n",
    "    \n",
    "    # Sort by time\n",
    "    df_for_merge_sorted = df_for_merge.sort_values('Time_td').reset_index(drop=True)\n",
    "    df_weather_sorted = df_weather.sort_values('Time_td').reset_index(drop=True)\n",
    "    \n",
    "    # Merge on nearest time\n",
    "    result = pd.merge_asof(\n",
    "        df_for_merge_sorted,\n",
    "        df_weather_sorted[['Time_td', 'AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed']],\n",
    "        left_on='Time_td',\n",
    "        right_on='Time_td',\n",
    "        direction='nearest',\n",
    "        tolerance=pd.Timedelta(f'{tolerance_seconds}s')\n",
    "    )\n",
    "    \n",
    "    # Restore original column order and add weather columns at end\n",
    "    weather_columns = ['AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed']\n",
    "    final_columns = original_columns + weather_columns\n",
    "    result = result[final_columns]\n",
    "    \n",
    "    # Sort by RacingNumber and lap progression\n",
    "    result = result.sort_values(\n",
    "        by=['RacingNumber', 'NumberOfLaps'],\n",
    "        ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17131e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Merged all races with weather data: 20458 rows\n",
      "✓ Saved to: csv_output/2025_All_Races_Merged_Lap_Timing_With_Weather.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge weather data with lap timing data for races that have weather data\n",
    "\n",
    "all_merged_with_weather = []\n",
    "\n",
    "for race_full_name, lap_data in all_lap_data_dict.items():\n",
    "    # Get this race from races_2025 to get the session path\n",
    "    matching_race = None\n",
    "    for race in races_2025:\n",
    "        if race['race_name'] == race_full_name:\n",
    "            matching_race = race\n",
    "            break\n",
    "    \n",
    "    if matching_race is None:\n",
    "        continue\n",
    "    \n",
    "    # Get the actual circuit name from the lap data itself\n",
    "    race_short_name = lap_data['name'].iloc[0] if 'name' in lap_data.columns and len(lap_data) > 0 else None\n",
    "    \n",
    "    if race_short_name is None:\n",
    "        continue\n",
    "    \n",
    "    # Filter merged data for THIS RACE ONLY using the actual circuit name\n",
    "    race_merged_data = merged_race_data[merged_race_data['name'] == race_short_name]\n",
    "    \n",
    "    if len(race_merged_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Merge with weather data\n",
    "    try:\n",
    "        # Check if weather file exists\n",
    "        weather_file = os.path.join(matching_race['session_path'], 'weather_data.ff1pkl')\n",
    "        if not os.path.exists(weather_file):\n",
    "            continue\n",
    "        \n",
    "        race_with_weather = merge_race_data_with_weather(\n",
    "            merged_race_data=race_merged_data,\n",
    "            race_cache_path=matching_race['session_path'],\n",
    "            tolerance_seconds=30\n",
    "        )\n",
    "        all_merged_with_weather.append(race_with_weather)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "# Check if we have any data to combine\n",
    "if len(all_merged_with_weather) == 0:\n",
    "    merged_race_data_with_weather = merged_race_data.copy()\n",
    "else:\n",
    "    # Combine all races with weather data\n",
    "    merged_race_data_with_weather = pd.concat(all_merged_with_weather, ignore_index=True)\n",
    "\n",
    "# Save to Excel file\n",
    "output_file = 'csv_output/2025_All_Races_Merged_Lap_Timing_With_Weather.xlsx'\n",
    "merged_race_data_with_weather.to_excel(output_file, index=False)\n",
    "print(f\"\\n✓ Merged all races with weather data: {merged_race_data_with_weather.shape[0]} rows\")\n",
    "print(f\"✓ Saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d699e",
   "metadata": {},
   "source": [
    "# I want to see if it is possible to extract the Race Control datasfrom Openf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4211f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from urllib.request import urlopen\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00eff82",
   "metadata": {},
   "source": [
    "# aaaaaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf9d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_keys(year):\n",
    "    \"\"\"\n",
    "    Extract session keys from OpenF1 API for a given year.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    year : int\n",
    "        The year to fetch session keys for (e.g., 2023)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary mapping circuit short names to session keys\n",
    "    \"\"\"\n",
    "    sessions_url = f\"https://api.openf1.org/v1/sessions?year={year}&session_name=Race\"\n",
    "    with urlopen(sessions_url) as resp:\n",
    "        sessions = json.loads(resp.read().decode(\"utf-8\"))\n",
    "    \n",
    "    session_keys = {\n",
    "        s[\"circuit_short_name\"]: s[\"session_key\"]\n",
    "        for s in sessions\n",
    "    }\n",
    "    \n",
    "    return session_keys\n",
    "\n",
    "\n",
    "def fetch_race_control_data(session_keys_dict, max_retries=3, base_delay=2):\n",
    "    \"\"\"\n",
    "    Fetch race control data from OpenF1 API for all sessions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    session_keys_dict : dict\n",
    "        Dictionary mapping Grand Prix names to session keys\n",
    "    max_retries : int, optional\n",
    "        Maximum number of retry attempts for failed requests (default: 3)\n",
    "    base_delay : int, optional\n",
    "        Delay in seconds between requests (default: 2)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing all race control events with grand_prix and race_session_key columns\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://api.openf1.org/v1/stints\"\n",
    "    all_events = []\n",
    "    \n",
    "    for idx, (gp_name, session_key) in enumerate(session_keys_dict.items(), 1):\n",
    "        url = f\"{BASE_URL}?session_key={session_key}\"\n",
    "        \n",
    "        # Retry logic with exponential backoff\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                print(f\"[{idx}/{len(session_keys_dict)}] Fetching {gp_name} (session_key={session_key})...\", end=\" \")\n",
    "                with urlopen(url) as resp:\n",
    "                    data = json.loads(resp.read().decode(\"utf-8\"))\n",
    "                \n",
    "                # Tag each event with GP name and session_key\n",
    "                for ev in data:\n",
    "                    ev[\"grand_prix\"] = gp_name\n",
    "                    ev[\"race_session_key\"] = session_key\n",
    "                    all_events.append(ev)\n",
    "                \n",
    "                print(f\"✓ ({len(data)} events)\")\n",
    "                \n",
    "                # Add delay between successful requests to avoid rate limiting\n",
    "                if idx < len(session_keys_dict):\n",
    "                    time.sleep(base_delay)\n",
    "                break\n",
    "                \n",
    "            except HTTPError as e:\n",
    "                if e.code == 429:  # Too Many Requests\n",
    "                    wait_time = base_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"Rate limited! Retrying in {wait_time}s (attempt {attempt + 1}/{max_retries})...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"HTTP Error {e.code}: {e.reason}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                break\n",
    "    \n",
    "    df_rc = pd.DataFrame(all_events)\n",
    "    return df_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d3936b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing year: 2023\n",
      "============================================================\n",
      "✓ Found 22 sessions for 2023\n",
      "[1/22] Fetching Sakhir (session_key=7953)... ✓ (70 events)\n",
      "[2/22] Fetching Jeddah (session_key=7779)... ✓ (44 events)\n",
      "[3/22] Fetching Melbourne (session_key=7787)... ✓ (85 events)\n",
      "[4/22] Fetching Baku (session_key=9070)... ✓ (43 events)\n",
      "[5/22] Fetching Miami (session_key=9078)... ✓ (40 events)\n",
      "[6/22] Fetching Monte Carlo (session_key=9094)... ✓ (57 events)\n",
      "[7/22] Fetching Catalunya (session_key=9102)... ✓ (63 events)\n",
      "[8/22] Fetching Montreal (session_key=9110)... ✓ (53 events)\n",
      "[9/22] Fetching Spielberg (session_key=9118)... ✓ (83 events)\n",
      "[10/22] Fetching Silverstone (session_key=9126)... ✓ (44 events)\n",
      "[11/22] Fetching Hungaroring (session_key=9133)... ✓ (56 events)\n",
      "[12/22] Fetching Spa-Francorchamps (session_key=9141)... ✓ (57 events)\n",
      "[13/22] Fetching Zandvoort (session_key=9149)... ✓ (121 events)\n",
      "[14/22] Fetching Monza (session_key=9157)... ✓ (45 events)\n",
      "[15/22] Fetching Singapore (session_key=9165)... ✓ (44 events)\n",
      "[16/22] Fetching Suzuka (session_key=9173)... ✓ (63 events)\n",
      "[17/22] Fetching Lusail (session_key=9221)... ✓ (73 events)\n",
      "[18/22] Fetching Austin (session_key=9213)... ✓ (56 events)\n",
      "[19/22] Fetching Mexico City (session_key=9181)... ✓ (58 events)\n",
      "[20/22] Fetching Interlagos (session_key=9205)... ✓ (87 events)\n",
      "[21/22] Fetching Las Vegas (session_key=9189)... ✓ (51 events)\n",
      "[22/22] Fetching Yas Marina Circuit (session_key=9197)... ✓ (57 events)\n",
      "✓ Saved raw data: csv_output/stint_2023_races.csv\n",
      "\n",
      "============================================================\n",
      "Processing year: 2024\n",
      "============================================================\n",
      "✓ Found 24 sessions for 2024\n",
      "[1/24] Fetching Sakhir (session_key=9472)... ✓ (63 events)\n",
      "[2/24] Fetching Jeddah (session_key=9480)... ✓ (39 events)\n",
      "[3/24] Fetching Melbourne (session_key=9488)... ✓ (55 events)\n",
      "[4/24] Fetching Suzuka (session_key=9496)... ✓ (74 events)\n",
      "[5/24] Fetching Shanghai (session_key=9673)... ✓ (60 events)\n",
      "[6/24] Fetching Miami (session_key=9507)... ✓ (48 events)\n",
      "[7/24] Fetching Imola (session_key=9515)... ✓ (47 events)\n",
      "[8/24] Fetching Monte Carlo (session_key=9523)... ✓ (43 events)\n",
      "[9/24] Fetching Montreal (session_key=9531)... ✓ (62 events)\n",
      "[10/24] Fetching Catalunya (session_key=9539)... ✓ (62 events)\n",
      "[11/24] Fetching Spielberg (session_key=9550)... ✓ (65 events)\n",
      "[12/24] Fetching Silverstone (session_key=9558)... ✓ (65 events)\n",
      "[13/24] Fetching Hungaroring (session_key=9566)... ✓ (60 events)\n",
      "[14/24] Fetching Spa-Francorchamps (session_key=9574)... ✓ (58 events)\n",
      "[15/24] Fetching Zandvoort (session_key=9582)... ✓ (46 events)\n",
      "[16/24] Fetching Monza (session_key=9590)... ✓ (50 events)\n",
      "[17/24] Fetching Baku (session_key=9598)... ✓ (42 events)\n",
      "[18/24] Fetching Singapore (session_key=9606)... ✓ (43 events)\n",
      "[19/24] Fetching Austin (session_key=9617)... ✓ (43 events)\n",
      "[20/24] Fetching Mexico City (session_key=9625)... ✓ (41 events)\n",
      "[21/24] Fetching Interlagos (session_key=9636)... ✓ (54 events)\n",
      "[22/24] Fetching Las Vegas (session_key=9644)... ✓ (59 events)\n",
      "[23/24] Fetching Lusail (session_key=9655)... ✓ (82 events)\n",
      "[24/24] Fetching Yas Marina Circuit (session_key=9662)... ✓ (48 events)\n",
      "✓ Saved raw data: csv_output/stint_2024_races.csv\n",
      "\n",
      "============================================================\n",
      "Processing year: 2025\n",
      "============================================================\n",
      "✓ Found 23 sessions for 2025\n",
      "[1/23] Fetching Melbourne (session_key=9693)... ✓ (106 events)\n",
      "[2/23] Fetching Shanghai (session_key=9998)... ✓ (45 events)\n",
      "[3/23] Fetching Suzuka (session_key=10006)... ✓ (41 events)\n",
      "[4/23] Fetching Sakhir (session_key=10014)... ✓ (62 events)\n",
      "[5/23] Fetching Jeddah (session_key=10022)... ✓ (39 events)\n",
      "[6/23] Fetching Miami (session_key=10033)... ✓ (38 events)\n",
      "[7/23] Fetching Imola (session_key=9987)... ✓ (57 events)\n",
      "[8/23] Fetching Monte Carlo (session_key=9979)... ✓ (59 events)\n",
      "[9/23] Fetching Catalunya (session_key=9971)... ✓ (73 events)\n",
      "[10/23] Fetching Montreal (session_key=9963)... ✓ (102 events)\n",
      "[11/23] Fetching Spielberg (session_key=9955)... ✓ (52 events)\n",
      "[12/23] Fetching Silverstone (session_key=9947)... ✓ (55 events)\n",
      "[13/23] Fetching Spa-Francorchamps (session_key=9939)... ✓ (60 events)\n",
      "[14/23] Fetching Hungaroring (session_key=9928)... ✓ (49 events)\n",
      "[15/23] Fetching Zandvoort (session_key=9920)... ✓ (60 events)\n",
      "[16/23] Fetching Monza (session_key=9912)... ✓ (39 events)\n",
      "[17/23] Fetching Baku (session_key=9904)... ✓ (41 events)\n",
      "[18/23] Fetching Singapore (session_key=9896)... ✓ (43 events)\n",
      "[19/23] Fetching Austin (session_key=9888)... ✓ (41 events)\n",
      "[20/23] Fetching Mexico City (session_key=9877)... ✓ (47 events)\n",
      "[21/23] Fetching Interlagos (session_key=9869)... ✓ (57 events)\n",
      "[22/23] Fetching Las Vegas (session_key=9858)... ✓ (44 events)\n",
      "[23/23] Fetching Lusail (session_key=9850)... ✓ (61 events)\n",
      "✓ Saved raw data: csv_output/stint_2025_races.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define years to process\n",
    "years_to_process = [2023, 2024, 2025]\n",
    "\n",
    "# Dictionary to store data for all years\n",
    "all_rc_data = {}\n",
    "\n",
    "for year in years_to_process:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing year: {year}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Get session keys\n",
    "        session_keys = get_session_keys(year)\n",
    "        print(f\"✓ Found {len(session_keys)} sessions for {year}\")\n",
    "        \n",
    "        # Fetch race control data\n",
    "        df_rc = fetch_race_control_data(session_keys)\n",
    "        df_rc.to_csv(f\"csv_output/stint_{year}_races.csv\", index=False)\n",
    "        print(f\"✓ Saved raw data: csv_output/stint_{year}_races.csv\")\n",
    "        \n",
    "        # Store for later processing\n",
    "        all_rc_data[year] = df_rc\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing year {year}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327b6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_race_control_data(df_input):\n",
    "    \"\"\"\n",
    "    Process race control data: detect flags, classify clean laps, and format output.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_input : pd.DataFrame\n",
    "        Input race control data with columns: message, flag, scope, category, \n",
    "        driver_number, lap_number, grand_prix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Processed race control dataframe with normalized flags and clean lap classification\n",
    "    \"\"\"\n",
    "    rc = df_input.copy()\n",
    "    \n",
    "    # Normalize text columns\n",
    "    rc[\"msg_upper\"] = rc[\"message\"].str.upper().fillna(\"\")\n",
    "    rc[\"flag_upper\"] = rc[\"flag\"].astype(str).str.upper().fillna(\"\")\n",
    "\n",
    "    # Remove rows with specific flags (BLUE, CHEQUERED, BLACK AND WHITE, NONE, NAN, empty, Green, CLEAR)\n",
    "    rc = rc[~rc[\"flag_upper\"].isin([\"BLUE\", \"CHEQUERED\", \"BLACK AND WHITE\", \"NONE\", \"NAN\", \"\", \"CLEAR\", \"GREEN\"])].copy()\n",
    "    \n",
    "    # Safety car events\n",
    "    rc[\"sc_deploy\"] = rc[\"msg_upper\"].str.contains(\"SAFETY CAR DEPLOYED\", case=False, na=False)\n",
    "    rc[\"sc_end\"] = (\n",
    "        rc[\"msg_upper\"].str.contains(\"SAFETY CAR IN THIS LAP\", case=False, na=False) |\n",
    "        rc[\"msg_upper\"].str.contains(\"SAFETY CAR ENDING\", case=False, na=False) |\n",
    "        rc[\"msg_upper\"].str.contains(\"SAFETY CAR ENTERS PIT LANE\", case=False, na=False)\n",
    "    )\n",
    "    \n",
    "    # Virtual safety car events\n",
    "    rc[\"vsc_deploy\"] = rc[\"msg_upper\"].str.contains(\"VIRTUAL SAFETY CAR DEPLOYED\", case=False, na=False)\n",
    "    rc[\"vsc_end\"] = rc[\"msg_upper\"].str.contains(\"VIRTUAL SAFETY CAR END\", case=False, na=False)\n",
    "    \n",
    "    # Track flags (Yellow / Double Yellow / Red)\n",
    "    track_mask = rc[\"scope\"].isin([\"Track\", \"Sector\", \"SafetyCar\"]) if \"scope\" in rc.columns else pd.Series([False] * len(rc))\n",
    "    track_rc = rc[track_mask].copy()\n",
    "    \n",
    "    if len(track_rc) > 0:\n",
    "        track_rc[\"is_yellow\"] = (\n",
    "            track_rc[\"flag_upper\"].str.contains(\"YELLOW\", case=False, na=False) |\n",
    "            track_rc[\"msg_upper\"].str.contains(\"YELLOW\", case=False, na=False)\n",
    "        )\n",
    "        track_rc[\"is_double_yellow\"] = track_rc[\"msg_upper\"].str.contains(\"DOUBLE YELLOW\", case=False, na=False)\n",
    "        track_rc[\"is_red\"] = track_rc[\"msg_upper\"].str.contains(\"RED FLAG\", case=False, na=False)\n",
    "        \n",
    "        rc.loc[track_rc.index, \"is_yellow\"] = track_rc[\"is_yellow\"]\n",
    "        rc.loc[track_rc.index, \"is_double_yellow\"] = track_rc[\"is_double_yellow\"]\n",
    "        rc.loc[track_rc.index, \"is_red\"] = track_rc[\"is_red\"]\n",
    "    else:\n",
    "        rc[\"is_yellow\"] = False\n",
    "        rc[\"is_double_yellow\"] = False\n",
    "        rc[\"is_red\"] = False\n",
    "    \n",
    "    rc[\"is_yellow\"] = rc[\"is_yellow\"].fillna(False).astype(bool)\n",
    "    rc[\"is_double_yellow\"] = rc[\"is_double_yellow\"].fillna(False).astype(bool)\n",
    "    rc[\"is_red\"] = rc[\"is_red\"].fillna(False).astype(bool)\n",
    "    \n",
    "    # # Blue flags (Driver specific)\n",
    "    # drv_mask = rc[\"scope\"] == \"Driver\" if \"scope\" in rc.columns else pd.Series([False] * len(rc))\n",
    "    # drv_rc = rc[drv_mask].copy()\n",
    "    \n",
    "    # if len(drv_rc) > 0:\n",
    "    #     drv_rc[\"is_blue\"] = (\n",
    "    #         (drv_rc[\"flag_upper\"] == \"BLUE\") |\n",
    "    #         drv_rc[\"msg_upper\"].str.contains(\"BLUE FLAG\", case=False, na=False)\n",
    "    #     )\n",
    "    #     rc.loc[drv_rc.index, \"is_blue\"] = drv_rc[\"is_blue\"]\n",
    "    # else:\n",
    "    #     rc[\"is_blue\"] = False\n",
    "    \n",
    "    # rc[\"is_blue\"] = rc[\"is_blue\"].fillna(False).astype(bool)\n",
    "    \n",
    "    # Clean lap classification\n",
    "    #lap_clean = False when is_yellow OR vsc_deploy OR sc_deploy OR is_red is True, True otherwise\n",
    "    rc[\"lap_clean\"] = ~((rc[\"is_yellow\"]) | (rc[\"vsc_deploy\"]) | (rc[\"sc_deploy\"]) | (rc[\"is_red\"]))\n",
    "  \n",
    "    \n",
    "    laps_with_flags = rc[(rc[\"is_yellow\"]) | (rc[\"is_red\"])].groupby([\"driver_number\", \"lap_number\"])[\"lap_number\"].count().index   #(rc[\"is_blue\"]) removed , in case uncomment and add it \n",
    "    for driver, lap in laps_with_flags:\n",
    "        rc.loc[(rc[\"driver_number\"] == driver) & (rc[\"lap_number\"] == lap), \"lap_clean\"] = False\n",
    "    \n",
    "    # Select key columns for output\n",
    "    key_columns = [\n",
    "        'lap_number', 'driver_number', 'grand_prix',  # metadata\n",
    "        'flag_upper',  # normalized\n",
    "        'sc_deploy', 'sc_end', 'vsc_deploy', 'vsc_end',  # SC/VSC events\n",
    "        'is_yellow', 'is_double_yellow', 'is_red',  # track flags\n",
    "        #'is_blue',  # driver flags\n",
    "        'lap_clean'  # clean lap classification\n",
    "    ]\n",
    "    \n",
    "    # Keep only columns that exist\n",
    "    rc_processed = rc[[col for col in key_columns if col in rc.columns]].copy()\n",
    "    \n",
    "    # Create a sort key for driver_number that handles NaN values\n",
    "    rc_processed['_sort_driver'] = rc_processed['driver_number'].fillna(float('inf'))\n",
    "    \n",
    "    # Sort: For every Grand Prix, sort by driver first, then by lap number\n",
    "    rc_processed = rc_processed.sort_values(\n",
    "        by=['grand_prix', '_sort_driver', 'lap_number'], \n",
    "        na_position='last'\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    # Remove the helper column\n",
    "    rc_processed = rc_processed.drop(columns=['_sort_driver'])\n",
    "    \n",
    "    return rc_processed\n",
    "\n",
    "\n",
    "\n",
    "# CIRCUIT TO GRAND PRIX NAME MAPPING\n",
    "\n",
    "CIRCUIT_TO_RACE_NAME_MAP = {\n",
    "    \"Sakhir\": \"Bahrain_Grand_Prix\",\n",
    "    \"Saudi Arabia\": \"Saudi_Arabian_Grand_Prix\",\n",
    "    \"Melbourne\": \"Australian_Grand_Prix\",\n",
    "    \"Suzuka\": \"Japanese_Grand_Prix\",\n",
    "    \"Shanghai\": \"Chinese_Grand_Prix\",\n",
    "    \"Miami\": \"Miami_Grand_Prix\",\n",
    "    \"Imola\": \"Emilia_Romagna_Grand_Prix\",\n",
    "    \"Monaco\": \"Monaco_Grand_Prix\",\n",
    "    \"Barcelona\": \"Spanish_Grand_Prix\",\n",
    "    \"Montreal\": \"Canadian_Grand_Prix\",\n",
    "    \"Spielberg\": \"Austrian_Grand_Prix\",\n",
    "    \"Silverstone\": \"British_Grand_Prix\",\n",
    "    \"Budapest\": \"Hungarian_Grand_Prix\",\n",
    "    \"Spa\": \"Belgian_Grand_Prix\",\n",
    "    \"Zandvoort\": \"Dutch_Grand_Prix\",\n",
    "    \"Monza\": \"Italian_Grand_Prix\",\n",
    "    \"Azerbaijan\": \"Azerbaijan_Grand_Prix\",\n",
    "    \"Marina Bay\": \"Singapore_Grand_Prix\",\n",
    "    \"Austin\": \"United_States_Grand_Prix\",\n",
    "    \"Mexico City\": \"Mexico_City_Grand_Prix\",\n",
    "    \"Sao Paulo\": \"Sao_Paulo_Grand_Prix\",\n",
    "    \"Las Vegas\": \"Las_Vegas_Grand_Prix\",\n",
    "    \"Abu Dhabi\": \"Abu_Dhabi_Grand_Prix\",\n",
    "    \"Qatar\": \"Qatar_Grand_Prix\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# EXTRACT TRACK LIMIT VIOLATIONS AND OFF-TRACK INCIDENTS\n",
    "\n",
    "def extract_rc_violations(df: pd.DataFrame, gp_col: str = \"grand_prix\", use_race_names: bool = True):\n",
    "    \"\"\"\n",
    "    Extract track limit violations and off-track incidents from race control data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input race control data with columns: message, flag, driver_number, lap_number, grand_prix\n",
    "    gp_col : str, optional\n",
    "        Name of the Grand Prix column (default: \"grand_prix\")\n",
    "    use_race_names : bool, optional\n",
    "        If True, map circuit names to standardized race_name format (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Filtered dataframe containing only violations with columns:\n",
    "        race_name, car_number, lap_number, track_limit, off_track, any_violation, message\n",
    "    \"\"\"\n",
    "    rc = df.copy()\n",
    "\n",
    "    # Keep only messages involving violations (flag is None for these)\n",
    "    mask = (\n",
    "        rc[\"flag\"].isna() &\n",
    "        rc[\"message\"].str.contains(\"TRACK LIMIT|OFF TRACK\", case=False, na=False)\n",
    "    )\n",
    "    rc = rc[mask]\n",
    "\n",
    "    # Boolean flags\n",
    "    rc[\"track_limit\"] = rc[\"message\"].str.contains(\"TRACK LIMIT\", case=False)\n",
    "    rc[\"off_track\"]   = rc[\"message\"].str.contains(\"OFF TRACK\",   case=False)\n",
    "    rc[\"any_violation\"] = rc[\"track_limit\"] | rc[\"off_track\"]\n",
    "\n",
    "    # Extract car number from message (fallback)\n",
    "    car_fallback = (\n",
    "        rc[\"message\"]\n",
    "        .str.extract(r\"CAR\\s+(?P<car_number>\\d+)\", expand=True)\n",
    "        .astype(\"Int64\")\n",
    "    )\n",
    "\n",
    "    # Prefer driver_number when valid, else fallback\n",
    "    rc[\"driver_number\"] = rc[\"driver_number\"].astype(\"Int64\")\n",
    "    rc[\"car_number\"] = rc[\"driver_number\"].where(\n",
    "        rc[\"driver_number\"].notna() & (rc[\"driver_number\"] != 0),\n",
    "        car_fallback[\"car_number\"]\n",
    "    )\n",
    "    \n",
    "    # Map circuit names to standardized race_name format if requested\n",
    "    if use_race_names and gp_col in rc.columns:\n",
    "        rc[\"race_name\"] = rc[gp_col].map(CIRCUIT_TO_RACE_NAME_MAP).fillna(rc[gp_col])\n",
    "    else:\n",
    "        rc[\"race_name\"] = rc[gp_col]\n",
    "\n",
    "    # Select output columns\n",
    "    out = rc[[\n",
    "        \"race_name\",\n",
    "        \"car_number\",\n",
    "        \"lap_number\",\n",
    "        \"track_limit\",\n",
    "        \"off_track\",\n",
    "        \"any_violation\",\n",
    "        \"message\"\n",
    "    ]].reset_index(drop=True)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817233b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing and saving results for all years...\n",
      "============================================================\n",
      "✓ Saved violations: csv_output/race_control_2023_violations.csv (495 records)\n",
      "✓ Saved processed data: csv_output/race_control_2023_processed.csv (170 records)\n",
      "✓ Saved violations: csv_output/race_control_2024_violations.csv (350 records)\n",
      "✓ Saved processed data: csv_output/race_control_2024_processed.csv (168 records)\n",
      "✓ Saved violations: csv_output/race_control_2025_violations.csv (267 records)\n",
      "✓ Saved processed data: csv_output/race_control_2025_processed.csv (236 records)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/1436178061.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc[\"is_yellow\"] = rc[\"is_yellow\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/1436178061.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc[\"is_double_yellow\"] = rc[\"is_double_yellow\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/1436178061.py:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc[\"is_red\"] = rc[\"is_red\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/1436178061.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc[\"is_yellow\"] = rc[\"is_yellow\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/1436178061.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc[\"is_double_yellow\"] = rc[\"is_double_yellow\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/1436178061.py:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc[\"is_red\"] = rc[\"is_red\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/1436178061.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc[\"is_yellow\"] = rc[\"is_yellow\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/1436178061.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc[\"is_double_yellow\"] = rc[\"is_double_yellow\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/1436178061.py:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc[\"is_red\"] = rc[\"is_red\"].fillna(False).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  EXTRACT TRACK LIMIT VIOLATIONS AND OFF-TRACK INCIDENTS\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Processing and saving results for all years...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for year, df_rc in all_rc_data.items():\n",
    "    try:\n",
    "        # Extract violations FIRST on raw data (before processing)\n",
    "        violations = extract_rc_violations(df_rc)\n",
    "        violations.to_csv(f\"csv_output/race_control_{year}_violations.csv\", index=False)\n",
    "        print(f\"✓ Saved violations: csv_output/race_control_{year}_violations.csv ({len(violations)} records)\")\n",
    "        \n",
    "        # Then process main race control flags\n",
    "        rc_processed = process_race_control_data(df_rc)\n",
    "        rc_processed.to_csv(f\"csv_output/race_control_{year}_processed.csv\", index=False)\n",
    "        print(f\"✓ Saved processed data: csv_output/race_control_{year}_processed.csv ({len(rc_processed)} records)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing {year}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cd8e2",
   "metadata": {},
   "source": [
    "## Mergin the All_Races_Merged_Lap_Timing_With_Weather with the race control violations first and then with the race control processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "537f9374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Merging violations with lap timing data...\n",
      "============================================================\n",
      "\n",
      "Processing year 2023...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4135382895.py:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"track_limit\"] = df_merged[\"track_limit\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4135382895.py:55: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"off_track\"] = df_merged[\"off_track\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4135382895.py:56: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"any_violation\"] = df_merged[\"any_violation\"].fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved: csv_output/2023_Merged_Lap_Timing_With_Violations.xlsx\n",
      "\n",
      "Processing year 2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4135382895.py:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"track_limit\"] = df_merged[\"track_limit\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4135382895.py:55: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"off_track\"] = df_merged[\"off_track\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4135382895.py:56: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"any_violation\"] = df_merged[\"any_violation\"].fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved: csv_output/2024_Merged_Lap_Timing_With_Violations.xlsx\n",
      "\n",
      "Processing year 2025...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4135382895.py:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"track_limit\"] = df_merged[\"track_limit\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4135382895.py:55: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"off_track\"] = df_merged[\"off_track\"].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4135382895.py:56: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"any_violation\"] = df_merged[\"any_violation\"].fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved: csv_output/2025_Merged_Lap_Timing_With_Violations.xlsx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MERGING \n",
    "\n",
    "# Violation first \n",
    "\n",
    "def merge_violations_with_timing(\n",
    "    timing_dir: str = \"csv_output\",\n",
    "    violations_dir: str = \"csv_output\",\n",
    "    output_dir: str = \"csv_output\",\n",
    "    years: list = [2023, 2024, 2025]\n",
    "):\n",
    "    \"\"\"\n",
    "    Merge track limit violations with lap timing and weather data (year-by-year).\n",
    "    Saves year-specific Excel files for inspection.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    timing_dir : str, optional\n",
    "        Directory containing year-specific timing Excel files (default: \"csv_output\")\n",
    "    violations_dir : str, optional\n",
    "        Directory containing violation CSV files (default: \"csv_output\")\n",
    "    output_dir : str, optional\n",
    "        Output directory for merged Excel files (default: \"csv_output\")\n",
    "    years : list, optional\n",
    "        Years to process (default: [2023, 2024, 2025])\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Merging violations with lap timing data...\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for year in years:\n",
    "        print(f\"Processing year {year}...\")\n",
    "        \n",
    "        try:\n",
    "            # Load timing data\n",
    "            timing_file = f\"{timing_dir}/{year}_All_Races_Merged_Lap_Timing_With_Weather.xlsx\"\n",
    "            df_timing = pd.read_excel(timing_file)\n",
    "            \n",
    "            # Load violations\n",
    "            violations_file = f\"{violations_dir}/race_control_{year}_violations.csv\"\n",
    "            df_violations = pd.read_csv(violations_file)\n",
    "            \n",
    "            # Merge on race_name, RacingNumber, and lap number\n",
    "            df_merged = df_timing.merge(\n",
    "                df_violations,\n",
    "                left_on=[\"race_name\", \"RacingNumber\", \"NumberOfLaps\"],\n",
    "                right_on=[\"race_name\", \"car_number\", \"lap_number\"],\n",
    "                how=\"left\"\n",
    "            )\n",
    "            \n",
    "            # Drop redundant columns\n",
    "            df_merged = df_merged.drop(columns=[\"car_number\", \"lap_number\"])\n",
    "            \n",
    "            # Fill violation columns with False where NaN (no violation)\n",
    "            df_merged[\"track_limit\"] = df_merged[\"track_limit\"].fillna(False).astype(bool)\n",
    "            df_merged[\"off_track\"] = df_merged[\"off_track\"].fillna(False).astype(bool)\n",
    "            df_merged[\"any_violation\"] = df_merged[\"any_violation\"].fillna(False).astype(bool)\n",
    "            \n",
    "            # Save Excel file\n",
    "            excel_file = f\"{output_dir}/{year}_Merged_Lap_Timing_With_Violations.xlsx\"\n",
    "            df_merged.to_excel(excel_file, index=False)\n",
    "            \n",
    "            print(f\"  ✓ Saved: {excel_file}\\n\")\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"  ✗ Error for {year}: {e}\\n\")\n",
    "            continue\n",
    "    \n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTE MERGE\n",
    "# ============================================================================\n",
    "\n",
    "merge_violations_with_timing()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef673cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea411c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023 DEBUG:\n",
      "  df_timing rows: 21879\n",
      "  rc_race_level rows: 83\n",
      "  df_merged rows: 21879\n",
      "  lap_clean before fillna: 20486 NaN values\n",
      "  lap_clean before fillna value counts: lap_clean\n",
      "False    1393\n",
      "Name: count, dtype: int64\n",
      "  lap_clean after fillna value counts: lap_clean\n",
      "True     20486\n",
      "False     1393\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:141: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(True).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024 DEBUG:\n",
      "  df_timing rows: 25633\n",
      "  rc_race_level rows: 57\n",
      "  df_merged rows: 25633\n",
      "  lap_clean before fillna: 24868 NaN values\n",
      "  lap_clean before fillna value counts: lap_clean\n",
      "False    765\n",
      "Name: count, dtype: int64\n",
      "  lap_clean after fillna value counts: lap_clean\n",
      "True     24868\n",
      "False      765\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:141: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(True).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025 DEBUG:\n",
      "  df_timing rows: 20462\n",
      "  rc_race_level rows: 76\n",
      "  df_merged rows: 20462\n",
      "  lap_clean before fillna: 19205 NaN values\n",
      "  lap_clean before fillna value counts: lap_clean\n",
      "False    1257\n",
      "Name: count, dtype: int64\n",
      "  lap_clean after fillna value counts: lap_clean\n",
      "True     19205\n",
      "False     1257\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:144: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(False).astype(bool)\n",
      "/var/folders/6f/l2mhfvbx40b0r05n911lr0fc0000gn/T/ipykernel_91148/4003042090.py:141: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[col] = df_merged[col].fillna(True).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "def map_race_control_to_race_name(grand_prix):\n",
    "    \"\"\"\n",
    "    Map race control grand_prix names to race_name format.\n",
    "    Example: \"Austin\" -> \"United_States_Grand_Prix\"\n",
    "    \"\"\"\n",
    "    if pd.isna(grand_prix):\n",
    "        return None\n",
    "    \n",
    "    grand_prix = str(grand_prix).strip()\n",
    "    \n",
    "    # Map from race control grand_prix to race_name format\n",
    "    mapping = {\n",
    "        'Sakhir': 'Bahrain_Grand_Prix',\n",
    "        'Jeddah': 'Saudi_Arabian_Grand_Prix',\n",
    "        'Melbourne': 'Australian_Grand_Prix',\n",
    "        'Suzuka': 'Japanese_Grand_Prix',\n",
    "        'Shanghai': 'Chinese_Grand_Prix',\n",
    "        'Miami': 'Miami_Grand_Prix',\n",
    "        'Imola': 'Emilia_Romagna_Grand_Prix',\n",
    "        'Monte Carlo': 'Monaco_Grand_Prix',\n",
    "        'Barcelona': 'Spanish_Grand_Prix',\n",
    "        'Montreal': 'Canadian_Grand_Prix',\n",
    "        'Spielberg': 'Austrian_Grand_Prix',\n",
    "        'Silverstone': 'British_Grand_Prix',\n",
    "        'Hungaroring': 'Hungarian_Grand_Prix',\n",
    "        'Spa-Francorchamps': 'Belgian_Grand_Prix',\n",
    "        'Zandvoort': 'Dutch_Grand_Prix',\n",
    "        'Monza': 'Italian_Grand_Prix',\n",
    "        'Baku': 'Azerbaijan_Grand_Prix',\n",
    "        'Singapore': 'Singapore_Grand_Prix',\n",
    "        'SINGAPORE': 'Singapore_Grand_Prix',\n",
    "        'Austin': 'United_States_Grand_Prix',\n",
    "        'Mexico City': 'Mexico_City_Grand_Prix',\n",
    "        'Interlagos': 'Sao_Paulo_Grand_Prix',\n",
    "        'Las Vegas': 'Las_Vegas_Grand_Prix',\n",
    "        'Abu Dhabi': 'Abu_Dhabi_Grand_Prix',\n",
    "        'Qatar': 'Qatar_Grand_Prix',\n",
    "    }\n",
    "    \n",
    "    # Check for exact match first\n",
    "    if grand_prix in mapping:\n",
    "        return mapping[grand_prix]\n",
    "    \n",
    "    # Check for case-insensitive match\n",
    "    for key, value in mapping.items():\n",
    "        if key.lower() == grand_prix.lower():\n",
    "            return value\n",
    "    \n",
    "    # If no match found, return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def merge_race_flags_to_violations(\n",
    "    violations_dir: str = \"csv_output\",\n",
    "    race_control_dir: str = \"csv_output\",\n",
    "    output_dir: str = \"csv_output\",\n",
    "    years: list = [2023, 2024, 2025]\n",
    "):\n",
    "    \"\"\"\n",
    "    Add race control flags to violations-merged lap timing data.\n",
    "    \n",
    "    For each (grand_prix, lap_number), merges race control flags to all drivers at that lap.\n",
    "    Example: Yellow flag on lap 20 in Austin applies to all drivers on lap 20 in Austin.\n",
    "    \n",
    "    Input: {year}_Merged_Lap_Timing_With_Violations.xlsx (timing + violations data)\n",
    "           race_control_{year}_processed.csv (processed flags)\n",
    "    \n",
    "    Output: {year}_Merged_Lap_Timing_Violations_RaceControl.xlsx\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    violations_dir : str\n",
    "        Directory containing {year}_Merged_Lap_Timing_With_Violations.xlsx files\n",
    "    race_control_dir : str\n",
    "        Directory containing race_control_{year}_processed.csv files\n",
    "    output_dir : str\n",
    "        Output directory for merged CSV files\n",
    "    years : list\n",
    "        Years to process\n",
    "    \"\"\"\n",
    "    yearly_data = {}\n",
    "    \n",
    "    for year in years:\n",
    "        violations_file = f\"{violations_dir}/{year}_Merged_Lap_Timing_With_Violations.xlsx\"\n",
    "        rc_file = f\"{race_control_dir}/race_control_{year}_processed.csv\"\n",
    "        output_file = f\"{output_dir}/{year}_Merged_Lap_Timing_Violations_RaceControl.xlsx\"\n",
    "        \n",
    "        try:\n",
    "            # Load data\n",
    "            df_timing = pd.read_excel(violations_file)\n",
    "            df_rc = pd.read_csv(rc_file)\n",
    "            \n",
    "            # Rename lap number column in timing data if needed\n",
    "            if 'NumberOfLaps' in df_timing.columns:\n",
    "                df_timing = df_timing.rename(columns={'NumberOfLaps': 'lap_number'})\n",
    "            \n",
    "            # Map race_control grand_prix to race_name format\n",
    "            df_rc['race_name'] = df_rc['grand_prix'].apply(map_race_control_to_race_name)\n",
    "            \n",
    "            # Extract race-level flags (one row per race_name, lap_number)\n",
    "            rc_race_level = df_rc[[\n",
    "                'race_name', 'lap_number', 'flag_upper',\n",
    "                'sc_deploy', 'sc_end', 'vsc_deploy', 'vsc_end',\n",
    "                'is_yellow', 'is_double_yellow', 'is_red', 'lap_clean'\n",
    "            ]].copy()\n",
    "            \n",
    "            # Remove rows with None race_name (unmapped grand_prix)\n",
    "            rc_race_level = rc_race_level[rc_race_level['race_name'].notna()]\n",
    "            \n",
    "            rc_race_level = rc_race_level.groupby(['race_name', 'lap_number']).first().reset_index()\n",
    "            \n",
    "            # Merge: same flags apply to all drivers in same lap/race\n",
    "            df_merged = df_timing.merge(\n",
    "                rc_race_level,\n",
    "                on=['race_name', 'lap_number'],\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Fill missing flags with False (except lap_clean = True for clean laps)\n",
    "            flag_columns = [\n",
    "                'sc_deploy', 'sc_end', 'vsc_deploy', 'vsc_end',\n",
    "                'is_yellow', 'is_double_yellow', 'is_red', 'lap_clean'\n",
    "            ]\n",
    "            for col in flag_columns:\n",
    "                if col in df_merged.columns:\n",
    "                    if col == 'lap_clean':\n",
    "                        # If lap not in processed file (no flags), lap_clean = True\n",
    "                        df_merged[col] = df_merged[col].fillna(True)\n",
    "                    else:\n",
    "                        # Other flags default to False\n",
    "                        df_merged[col] = df_merged[col].fillna(False)\n",
    "                    # Convert to bool efficiently\n",
    "                    df_merged[col] = df_merged[col].astype('bool')\n",
    "            \n",
    "            # Save output\n",
    "            df_merged.to_excel(output_file, index=False)\n",
    "            yearly_data[year] = df_merged\n",
    "            \n",
    "            # Clean up\n",
    "            del df_timing, df_rc, rc_race_level, df_merged\n",
    "            gc.collect()\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Skipping {year}: File not found ({e})\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {year}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return yearly_data if yearly_data else None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Step 2: Merge with violations data\n",
    "    result = merge_race_flags_to_violations(years=[2023, 2024, 2025])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aced9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 3 years into csv_output/Combined_Lap_Timing_Violations_RaceControl.xlsx\n",
      "Total rows: 67,974\n",
      "\n",
      "Combined Data Columns (39):\n",
      "['year', 'round', 'name', 'countryId', 'Name', 'Team', 'RacingNumber', 'Time', 'lap_number', 'LapTime', 'Position', 'IntervalToPositionAhead', 'NumberOfPitStops', 'Stint', 'Compound', 'New', 'TyresNotChanged', 'race_name', 'LapInStint', 'AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed', 'track_limit', 'off_track', 'any_violation', 'message', 'flag_upper', 'sc_deploy', 'sc_end', 'vsc_deploy', 'vsc_end', 'is_yellow', 'is_double_yellow', 'is_red', 'lap_clean']\n"
     ]
    }
   ],
   "source": [
    "def combine_yearly_results(\n",
    "    output_dir: str = \"csv_output\",\n",
    "    years: list = [2023, 2024, 2025],\n",
    "    combined_output: str = \"csv_output/Combined_Lap_Timing_Violations_RaceControl.xlsx\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Combine the yearly merged files into one combined dataset.\n",
    "    \n",
    "    Input: {year}_Merged_Lap_Timing_Violations_RaceControl.xlsx\n",
    "    Output: Combined_Lap_Timing_Violations_RaceControl.xlsx\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for year in years:\n",
    "        file = f\"{output_dir}/{year}_Merged_Lap_Timing_Violations_RaceControl.xlsx\"\n",
    "        try:\n",
    "            df = pd.read_excel(file)\n",
    "            all_data.append(df)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Skipping {year}: File not found\")\n",
    "            continue\n",
    "    \n",
    "    if all_data:\n",
    "        df_combined = pd.concat(all_data, ignore_index=True)\n",
    "        df_combined.to_excel(combined_output, index=False)\n",
    "        print(f\"Combined {len(all_data)} years into {combined_output}\")\n",
    "        print(f\"Total rows: {len(df_combined):,}\")\n",
    "        return df_combined\n",
    "    else:\n",
    "        print(\"No files to combine!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    \n",
    "    # Step 3: Combine yearly results\n",
    "combined = combine_yearly_results(years=[2023, 2024, 2025])\n",
    "\n",
    "# print the columns of the combined dataframe\n",
    "if combined is not None:\n",
    "    print(f\"\\nCombined Data Columns ({combined.shape[1]}):\")\n",
    "    print(combined.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99134a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data saved to csv_output/Combined_Lap_Timing_Clean.xlsx\n",
      "Total rows: 67,974\n",
      "Final columns (22): ['year', 'round', 'Grand_Prix', 'Name', 'RacingNumber', 'Team', 'lap_number', 'LapTime', 'IntervalToPositionAhead', 'Position', 'Stint', 'Compound', 'New', 'AirTemp', 'Humidity', 'Pressure', 'TrackTemp', 'WindDirection', 'WindSpeed', 'Rainfall', 'any_violation', 'lap_clean']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_combined_data(\n",
    "    df_combined,\n",
    "    output_file: str = \"csv_output/Combined_Lap_Timing_Clean.xlsx\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Clean the combined dataset by removing unnecessary columns and reordering.\n",
    "    \n",
    "    Input: Combined dataset with all columns\n",
    "    Output: Cleaned dataset with only modeling-relevant columns\n",
    "    \"\"\"\n",
    "    df_clean = df_combined.copy()\n",
    "    \n",
    "    # Remove unnecessary columns\n",
    "    columns_to_drop = [\n",
    "        'name', 'countryId', 'Time', 'NumberOfPitStops', 'TyresNotChanged',\n",
    "        'LapInStint', 'track_limit', 'off_track', 'message', 'flag_upper',\n",
    "        'sc_deploy', 'sc_end', 'vsc_deploy', 'vsc_end', 'is_yellow', 'is_double_yellow', 'is_red'\n",
    "    ]\n",
    "    df_clean = df_clean.drop(columns=[col for col in columns_to_drop if col in df_clean.columns])\n",
    "    \n",
    "    # Rename race_name to Grand_Prix\n",
    "    if 'race_name' in df_clean.columns:\n",
    "        df_clean = df_clean.rename(columns={'race_name': 'Grand_Prix'})\n",
    "    \n",
    "    # Reorder columns for better readability\n",
    "    column_order = [\n",
    "        'year', 'round', 'Grand_Prix', 'Name', 'RacingNumber', 'Team',\n",
    "        'lap_number', 'LapTime', 'IntervalToPositionAhead', 'Position',\n",
    "        'Stint', 'Compound', 'New',\n",
    "        'AirTemp', 'Humidity', 'Pressure', 'TrackTemp', 'WindDirection', 'WindSpeed', 'Rainfall',\n",
    "        'any_violation', 'lap_clean'\n",
    "    ]\n",
    "    df_clean = df_clean[[col for col in column_order if col in df_clean.columns]]\n",
    "    \n",
    "    # Convert Rainfall to boolean (rain indicator: 0 or 1 → False or True)\n",
    "    if 'Rainfall' in df_clean.columns:\n",
    "        df_clean['Rainfall'] = df_clean['Rainfall'].astype('bool')\n",
    "    \n",
    "    df_clean.to_excel(output_file, index=False)\n",
    "    print(f\"\\nCleaned data saved to {output_file}\")\n",
    "    print(f\"Total rows: {len(df_clean):,}\")\n",
    "    print(f\"Final columns ({len(df_clean.columns)}): {list(df_clean.columns)}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "    # Step 4: Clean combined data\n",
    "\n",
    "if combined is not None:\n",
    "    cleaned = clean_combined_data(combined)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Formula1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
