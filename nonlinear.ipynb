{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adff704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DECISION TREE & RANDOM FOREST BASELINE\n",
    "Answers 3 questions:\n",
    "  1. Do they beat the true online baseline?\n",
    "  2. How do they compare to each other?\n",
    "  3. What patterns do they learn?\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid, GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[LOAD] Loading data...\")\n",
    "df_train = pd.read_excel('csv_output/Train_set.xlsx')\n",
    "df_val = pd.read_excel('csv_output/Validation_set.xlsx')\n",
    "df_test = pd.read_excel('csv_output/Test_set.xlsx')\n",
    "print(f\"  Train: {len(df_train):,} | Val: {len(df_val):,} | Test: {len(df_test):,}\")\n",
    "\n",
    "# Define features\n",
    "TARGET = 'LapTime_next'\n",
    "\n",
    "NUMERICAL_FEATURES = [\n",
    "    'LapInStint', 'LapInStint_squared', 'is_new_tyre', 'TyreAgeAtStart',\n",
    "    'laptime_rolling_std_3', 'laptime_cumulative_trend', 'laptime_change_prev', 'stint_mean_so_far',\n",
    "    'is_leader', 'in_drs_range', 'in_clean_air', 'in_dirty_air', 'pushing',\n",
    "    'AirTemp', 'Humidity', 'Pressure', 'TrackTemp', 'WindSpeed', 'wind_sin', 'wind_cos',\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = ['Compound']\n",
    "\n",
    "# Add PCA geometry\n",
    "geom_pca_cols = [c for c in df_train.columns if c.startswith('geom_PC')]\n",
    "NUMERICAL_FEATURES.extend(geom_pca_cols)\n",
    "NUMERICAL_FEATURES = [f for f in NUMERICAL_FEATURES if f in df_train.columns]\n",
    "CATEGORICAL_FEATURES = [f for f in CATEGORICAL_FEATURES if f in df_train.columns]\n",
    "\n",
    "print(f\"  Features: {len(NUMERICAL_FEATURES)} numerical + {len(CATEGORICAL_FEATURES)} categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[BASELINE] Computing true online baseline (past laps only)...\")\n",
    "\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df['race_id'] = df['year'].astype(str) + '_' + df['round'].astype(str) + '_' + df['name']\n",
    "\n",
    "df_test_sorted = df_test.sort_values(['year', 'round', 'name', 'LapNumber']).reset_index(drop=True)\n",
    "\n",
    "baseline_preds = np.full(len(df_test_sorted), np.nan, dtype=float)\n",
    "\n",
    "for (year, round_no, circuit), group_df in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    past_laps = []\n",
    "    for idx in group_df.index:\n",
    "        lap_idx_in_test = df_test_sorted.index.get_loc(idx)\n",
    "        if past_laps:\n",
    "            baseline_preds[lap_idx_in_test] = float(np.median(past_laps))\n",
    "        past_laps.append(df_test_sorted.at[idx, TARGET])\n",
    "\n",
    "mask = ~np.isnan(baseline_preds)\n",
    "baseline_preds_valid = baseline_preds[mask]\n",
    "y_test_valid = df_test_sorted[TARGET].values[mask]\n",
    "\n",
    "# Per-race baseline\n",
    "baseline_per_race = []\n",
    "for (year, round_no, circuit), group_df in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    group_indices = group_df.index\n",
    "    group_mask = np.zeros(len(df_test_sorted), dtype=bool)\n",
    "    group_mask[group_indices] = True\n",
    "    group_mask = group_mask & mask\n",
    "    if group_mask.sum() > 0:\n",
    "        baseline_per_race.append(mean_absolute_error(df_test_sorted[TARGET].values[group_mask], baseline_preds[group_mask]))\n",
    "\n",
    "baseline_median_mae_per_race = float(np.median(baseline_per_race))\n",
    "print(f\"  Baseline (median MAE/race): {baseline_median_mae_per_race:.4f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1aada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "\n",
    "X_train = df_train[NUMERICAL_FEATURES + CATEGORICAL_FEATURES].copy()\n",
    "y_train = df_train[TARGET].copy()\n",
    "race_train = df_train['race_id'].copy()\n",
    "\n",
    "X_val = df_val[NUMERICAL_FEATURES + CATEGORICAL_FEATURES].copy()\n",
    "y_val = df_val[TARGET].copy()\n",
    "race_val = df_val['race_id'].copy()\n",
    "\n",
    "X_test = df_test_sorted[NUMERICAL_FEATURES + CATEGORICAL_FEATURES].copy()\n",
    "y_test = df_test_sorted[TARGET].copy()\n",
    "race_test = df_test_sorted['race_id'].copy()\n",
    "\n",
    "X_trainval = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_trainval = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "race_trainval = pd.concat([race_train, race_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Race-balanced weights\n",
    "vc = race_trainval.value_counts()\n",
    "w_trainval = race_trainval.map(lambda r: 1.0 / vc.loc[r])\n",
    "\n",
    "# FIX 4: OneHotEncoder compatibility shim\n",
    "ohe_args = dict(handle_unknown=\"ignore\")\n",
    "try:\n",
    "    OHE = OneHotEncoder(sparse_output=False, **ohe_args)\n",
    "except TypeError:\n",
    "    OHE = OneHotEncoder(sparse=False, **ohe_args)\n",
    "\n",
    "# Single preprocessor (reused for both DT and RF)\n",
    "has_cat = len(CATEGORICAL_FEATURES) > 0\n",
    "if has_cat:\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', SimpleImputer(strategy='median'), NUMERICAL_FEATURES),\n",
    "        ('cat', OHE, CATEGORICAL_FEATURES)\n",
    "    ], remainder='drop')\n",
    "else:\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', SimpleImputer(strategy='median'), NUMERICAL_FEATURES),\n",
    "    ], remainder='drop')\n",
    "\n",
    "# FIX 1: Precompute valid-subset indices once (don't fit preprocessor externally)\n",
    "valid_idx = np.where(mask)[0]\n",
    "\n",
    "# Map each race to positions within the valid subset\n",
    "race_groups_valid = []\n",
    "for _, g in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    full_idx = g.index.values\n",
    "    in_valid = np.intersect1d(valid_idx, full_idx)\n",
    "    if in_valid.size > 0:\n",
    "        pos_in_valid = np.searchsorted(valid_idx, in_valid)\n",
    "        race_groups_valid.append(pos_in_valid)\n",
    "\n",
    "# FIX 3: Helper to get feature names per pipeline\n",
    "def get_feature_names(num_feats, cat_feats, pipeline=None):\n",
    "    names = list(num_feats)\n",
    "    if len(cat_feats) > 0:\n",
    "        enc = pipeline.named_steps['preprocess'].named_transformers_['cat']\n",
    "        names += list(enc.get_feature_names_out(cat_feats))\n",
    "    return names\n",
    "\n",
    "# FIX 2: Rewritten helper for valid-subset permutation importance (transforms inside using pipeline's preprocessor)\n",
    "def compute_permutation_importance_valid(pipeline, X_test_raw, y_test_raw, valid_idx, race_groups_valid, feature_names, n_repeats=10):\n",
    "    \"\"\"Compute race-aware permutation importance on valid subset using pipeline's preprocessor.\"\"\"\n",
    "    rng = np.random.RandomState(42)\n",
    "    preproc = pipeline.named_steps['preprocess']\n",
    "    mdl = pipeline.named_steps['model']\n",
    "\n",
    "    # Transform test data using pipeline's preprocessor (ensures consistency)\n",
    "    X_test_t = preproc.transform(X_test_raw)\n",
    "    X_valid = X_test_t[valid_idx]\n",
    "    y_valid = y_test_raw[valid_idx]\n",
    "\n",
    "    base_pred = mdl.predict(X_valid)\n",
    "    base_med = np.median([mean_absolute_error(y_valid[g], base_pred[g]) for g in race_groups_valid if g.size > 0])\n",
    "\n",
    "    imps = []\n",
    "    for j, fname in enumerate(feature_names):\n",
    "        drops = []\n",
    "        for _ in range(n_repeats):\n",
    "            Xs = X_valid.copy()\n",
    "            rng.shuffle(Xs[:, j])\n",
    "            yp = mdl.predict(Xs)\n",
    "            med = np.median([mean_absolute_error(y_valid[g], yp[g]) for g in race_groups_valid if g.size > 0])\n",
    "            drops.append(med - base_med)\n",
    "        imps.append((fname, float(np.median(drops))))\n",
    "    \n",
    "    imps.sort(key=lambda x: x[1], reverse=True)\n",
    "    return imps[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DECISION TREE\n",
    "\n",
    "print(\"\\n[DT] Tuning Decision Tree...\")\n",
    "\n",
    "pipe_dt = Pipeline([(\"preprocess\", preprocessor), (\"model\", DecisionTreeRegressor(random_state=42))])\n",
    "\n",
    "param_dt = {\n",
    "    \"model__max_depth\": [4, 6, 8, 12],\n",
    "    \"model__min_samples_leaf\": [5, 10, 20],\n",
    "    \"model__min_samples_split\": [2, 10],\n",
    "    \"model__max_features\": [None, \"sqrt\", 0.5],\n",
    "    \"model__max_leaf_nodes\": [None, 64, 128, 256],\n",
    "    \"model__ccp_alpha\": [0.0, 1e-4, 5e-4],\n",
    "}\n",
    "\n",
    "best_dt_score, best_dt_params = np.inf, None\n",
    "gkf = GroupKFold(n_splits=min(5, race_trainval.nunique()))\n",
    "\n",
    "for i, params in enumerate(list(ParameterGrid(param_dt)), 1):\n",
    "    fold_scores = []\n",
    "    for tr, va in gkf.split(X_trainval, y_trainval, groups=race_trainval):\n",
    "        pipe_dt.set_params(**params)\n",
    "        w_tr = race_trainval.iloc[tr].map(lambda r: 1.0 / race_trainval.iloc[tr].value_counts().loc[r])\n",
    "        pipe_dt.fit(X_trainval.iloc[tr], y_trainval.iloc[tr], model__sample_weight=w_tr.values)\n",
    "        yp = pipe_dt.predict(X_trainval.iloc[va])\n",
    "        per_race = [mean_absolute_error(y_trainval.iloc[va][race_trainval.iloc[va] == rid], yp[race_trainval.iloc[va] == rid]) \n",
    "                    for rid in race_trainval.iloc[va].unique()]\n",
    "        fold_scores.append(float(np.median(per_race)))\n",
    "    score = float(np.median(fold_scores))\n",
    "    if score < best_dt_score:\n",
    "        best_dt_score = score\n",
    "        best_dt_params = params\n",
    "        if i % 50 == 0: print(f\"  [{i}] Best: {score:.4f}s\")\n",
    "\n",
    "print(f\"  Best CV: {best_dt_score:.4f}s\")\n",
    "\n",
    "# Evaluate DT\n",
    "pipe_dt.set_params(**best_dt_params)\n",
    "pipe_dt.fit(X_trainval, y_trainval, model__sample_weight=w_trainval.values)\n",
    "\n",
    "dt_pred_all = pipe_dt.predict(X_test)\n",
    "dt_pred = dt_pred_all[mask]\n",
    "dt_mae = mean_absolute_error(y_test_valid, dt_pred)\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test_valid, dt_pred))\n",
    "dt_r2 = r2_score(y_test_valid, dt_pred)\n",
    "\n",
    "# FIX 3: Use race_groups_valid consistently for per-race errors\n",
    "dt_per_race = []\n",
    "dt_race_ids = []\n",
    "for (year, round_no, circuit), g in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    group_indices = g.index.values\n",
    "    group_mask = np.zeros(len(df_test_sorted), dtype=bool)\n",
    "    group_mask[group_indices] = True\n",
    "    group_mask = group_mask & mask\n",
    "    if group_mask.sum() > 0:\n",
    "        dt_per_race.append(mean_absolute_error(df_test_sorted[TARGET].values[group_mask], dt_pred_all[group_mask]))\n",
    "        dt_race_ids.append(f\"{year}_{round_no}_{circuit}\")\n",
    "\n",
    "dt_median_mae_per_race = float(np.median(dt_per_race))\n",
    "tree_depth = pipe_dt.named_steps['model'].get_depth()\n",
    "tree_leaves = pipe_dt.named_steps['model'].get_n_leaves()\n",
    "\n",
    "print(f\"\\n  DT Results:\")\n",
    "print(f\"    Median MAE/race: {dt_median_mae_per_race:.4f}s\")\n",
    "print(f\"    Overall MAE: {dt_mae:.4f}s, RMSE: {dt_rmse:.4f}s, R²: {dt_r2:.4f}\")\n",
    "print(f\"    Tree: depth={tree_depth}, leaves={tree_leaves}\")\n",
    "\n",
    "# DT permutation importance (FIX 2: transform inside helper)\n",
    "print(f\"  Computing permutation importance...\")\n",
    "dt_feats = get_feature_names(NUMERICAL_FEATURES, CATEGORICAL_FEATURES, pipe_dt)\n",
    "dt_importances = compute_permutation_importance_valid(pipe_dt, X_test, y_test.values, valid_idx, race_groups_valid, dt_feats)\n",
    "\n",
    "# Save DT\n",
    "pd.DataFrame({\n",
    "    \"Model\": [\"Decision Tree\"],\n",
    "    \"CV_median_race_MAE\": [best_dt_score],\n",
    "    \"Test_median_race_MAE\": [dt_median_mae_per_race],\n",
    "    \"Test_MAE\": [dt_mae],\n",
    "    \"Test_RMSE\": [dt_rmse],\n",
    "    \"Test_R2\": [dt_r2],\n",
    "    \"Tree_Depth\": [tree_depth],\n",
    "}).to_csv('csv_output/dt_results.csv', index=False)\n",
    "\n",
    "# FIX 3: Use consistent race identifiers\n",
    "pd.DataFrame({'Race': dt_race_ids, 'MAE': dt_per_race}).sort_values('MAE', ascending=False).to_csv('csv_output/dt_per_race_mae.csv', index=False)\n",
    "\n",
    "pd.DataFrame(dt_importances, columns=['Feature', 'Importance']).to_csv('csv_output/dt_feature_importances_perm.csv', index=False)\n",
    "\n",
    "with open('csv_output/dt_best_hyperparameters.json', 'w') as f:\n",
    "    json.dump({'DecisionTree': best_dt_params, 'CV_score': float(best_dt_score), 'Test_score': float(dt_median_mae_per_race)}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87008965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RANDOM FOREST\n",
    "\n",
    "print(\"\\n[RF] Tuning Random Forest...\")\n",
    "\n",
    "# FIX 5: Make RF OOB explicit + keep GroupKFold robust\n",
    "pipe_rf = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(random_state=42, n_jobs=-1, oob_score=True, bootstrap=True))\n",
    "])\n",
    "\n",
    "param_rf = {\n",
    "    \"model__n_estimators\": [600],\n",
    "    \"model__max_depth\": [12, 20, None],\n",
    "    \"model__min_samples_leaf\": [5, 10, 20],\n",
    "    \"model__min_samples_split\": [2, 10, 20],\n",
    "    \"model__max_features\": [\"sqrt\", 0.5],\n",
    "}\n",
    "\n",
    "best_rf_score, best_rf_params = np.inf, None\n",
    "gkf_rf = GroupKFold(n_splits=min(5, race_trainval.nunique()))\n",
    "\n",
    "for i, params in enumerate(list(ParameterGrid(param_rf)), 1):\n",
    "    fold_scores = []\n",
    "    for tr, va in gkf_rf.split(X_trainval, y_trainval, groups=race_trainval):\n",
    "        pipe_rf.set_params(**params)\n",
    "        w_tr = race_trainval.iloc[tr].map(lambda r: 1.0 / race_trainval.iloc[tr].value_counts().loc[r])\n",
    "        pipe_rf.fit(X_trainval.iloc[tr], y_trainval.iloc[tr], model__sample_weight=w_tr.values)\n",
    "        yp = pipe_rf.predict(X_trainval.iloc[va])\n",
    "        per_race = [mean_absolute_error(y_trainval.iloc[va][race_trainval.iloc[va] == rid], yp[race_trainval.iloc[va] == rid]) \n",
    "                    for rid in race_trainval.iloc[va].unique()]\n",
    "        fold_scores.append(float(np.median(per_race)))\n",
    "    score = float(np.median(fold_scores))\n",
    "    if score < best_rf_score:\n",
    "        best_rf_score = score\n",
    "        best_rf_params = params\n",
    "        if i % 10 == 0: print(f\"  [{i}] Best: {score:.4f}s\")\n",
    "\n",
    "print(f\"  Best CV: {best_rf_score:.4f}s\")\n",
    "\n",
    "# Evaluate RF\n",
    "pipe_rf.set_params(**best_rf_params)\n",
    "pipe_rf.fit(X_trainval, y_trainval, model__sample_weight=w_trainval.values)\n",
    "\n",
    "rf_pred_all = pipe_rf.predict(X_test)\n",
    "rf_pred = rf_pred_all[mask]\n",
    "rf_mae = mean_absolute_error(y_test_valid, rf_pred)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test_valid, rf_pred))\n",
    "rf_r2 = r2_score(y_test_valid, rf_pred)\n",
    "rf_oob = pipe_rf.named_steps['model'].oob_score_\n",
    "\n",
    "rf_per_race = []\n",
    "rf_race_ids = []\n",
    "for (year, round_no, circuit), g in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    group_indices = g.index.values\n",
    "    group_mask = np.zeros(len(df_test_sorted), dtype=bool)\n",
    "    group_mask[group_indices] = True\n",
    "    group_mask = group_mask & mask\n",
    "    if group_mask.sum() > 0:\n",
    "        rf_per_race.append(mean_absolute_error(df_test_sorted[TARGET].values[group_mask], rf_pred_all[group_mask]))\n",
    "        rf_race_ids.append(f\"{year}_{round_no}_{circuit}\")\n",
    "\n",
    "rf_median_mae_per_race = float(np.median(rf_per_race))\n",
    "\n",
    "print(f\"\\n  RF Results:\")\n",
    "print(f\"    Median MAE/race: {rf_median_mae_per_race:.4f}s\")\n",
    "print(f\"    Overall MAE: {rf_mae:.4f}s, RMSE: {rf_rmse:.4f}s, R²: {rf_r2:.4f}\")\n",
    "print(f\"    OOB R²: {rf_oob:.4f} (diagnostic)\")\n",
    "\n",
    "# RF permutation importance (FIX 2: transform inside helper)\n",
    "print(f\"  Computing permutation importance...\")\n",
    "rf_feats = get_feature_names(NUMERICAL_FEATURES, CATEGORICAL_FEATURES, pipe_rf)\n",
    "rf_importances = compute_permutation_importance_valid(pipe_rf, X_test, y_test.values, valid_idx, race_groups_valid, rf_feats)\n",
    "\n",
    "# Save RF\n",
    "pd.DataFrame({\n",
    "    \"Model\": [\"Random Forest\"],\n",
    "    \"CV_median_race_MAE\": [best_rf_score],\n",
    "    \"Test_median_race_MAE\": [rf_median_mae_per_race],\n",
    "    \"Test_MAE\": [rf_mae],\n",
    "    \"Test_RMSE\": [rf_rmse],\n",
    "    \"Test_R2\": [rf_r2],\n",
    "    \"OOB_R2\": [rf_oob],\n",
    "}).to_csv('csv_output/rf_results.csv', index=False)\n",
    "\n",
    "# FIX 3: Use consistent race identifiers\n",
    "pd.DataFrame({'Race': rf_race_ids, 'MAE': rf_per_race}).sort_values('MAE', ascending=False).to_csv('csv_output/rf_per_race_mae.csv', index=False)\n",
    "\n",
    "pd.DataFrame(rf_importances, columns=['Feature', 'Importance']).to_csv('csv_output/rf_feature_importances_perm.csv', index=False)\n",
    "\n",
    "with open('csv_output/rf_best_hyperparameters.json', 'w') as f:\n",
    "    json.dump({'RandomForest': best_rf_params, 'CV_score': float(best_rf_score), 'Test_score': float(rf_median_mae_per_race)}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01582c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════════\n",
    "# SUMMARY\n",
    "# ══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: NON-LINEAR BASELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBaseline (online, past laps):      {baseline_median_mae_per_race:.4f}s\")\n",
    "print(f\"Decision Tree:                     {dt_median_mae_per_race:.4f}s\")\n",
    "print(f\"Random Forest:                     {rf_median_mae_per_race:.4f}s\")\n",
    "print(f\"\\nWinner: {'Random Forest' if rf_median_mae_per_race < dt_median_mae_per_race else 'Decision Tree'}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"  - dt_results.csv, dt_per_race_mae.csv, dt_feature_importances_perm.csv, dt_best_hyperparameters.json\")\n",
    "print(\"  - rf_results.csv, rf_per_race_mae.csv, rf_feature_importances_perm.csv, rf_best_hyperparameters.json\")\n",
    "print(\"\\n✓ Non-linear baseline complete!\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Formula1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
