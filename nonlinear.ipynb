{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adff704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DECISION TREE & RANDOM FOREST BASELINE\n",
    "Answers 3 questions:\n",
    "  1. Do they beat the true online baseline?\n",
    "  2. How do they compare to each other?\n",
    "  3. What patterns do they learn?\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create output folder for non-linear models\n",
    "os.makedirs('csv_output/nonlinear', exist_ok=True)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid, GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95dd82f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "  Train: 28,244 | Val: 5,035 | Test: 7,147\n",
      "  Features: 18 numerical + 1 categorical\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Loading data\")\n",
    "df_train = pd.read_excel('csv_output/Train_set.xlsx')\n",
    "df_val = pd.read_excel('csv_output/Validation_set.xlsx')\n",
    "df_test = pd.read_excel('csv_output/Test_set.xlsx')\n",
    "print(f\"  Train: {len(df_train):,} | Val: {len(df_val):,} | Test: {len(df_test):,}\")\n",
    "\n",
    "# Define features\n",
    "TARGET = 'LapTime_next'\n",
    "\n",
    "NUMERICAL_FEATURES = [\n",
    "    'LapInStint', 'LapInStint_squared', 'is_new_tyre', 'TyreAgeAtStart',\n",
    "    'laptime_rolling_std_3', 'laptime_cumulative_trend', 'laptime_change_prev', #'stint_mean_so_far',\n",
    "    'AirTemp', 'Humidity', 'Pressure', 'TrackTemp', 'WindSpeed', 'wind_sin', 'wind_cos',\n",
    "]\n",
    "\n",
    "# Add binary flags if they exist\n",
    "for flag in ['is_leader', 'in_drs_range', 'in_clean_air', 'in_dirty_air', 'pushing']:\n",
    "    if flag in df_train.columns:\n",
    "        NUMERICAL_FEATURES.append(flag)\n",
    "\n",
    "CATEGORICAL_FEATURES = ['Compound']\n",
    "\n",
    "# Add PCA geometry\n",
    "geom_pca_cols = [c for c in df_train.columns if c.startswith('geom_PC')]\n",
    "NUMERICAL_FEATURES.extend(geom_pca_cols)\n",
    "NUMERICAL_FEATURES = [f for f in NUMERICAL_FEATURES if f in df_train.columns]\n",
    "CATEGORICAL_FEATURES = [f for f in CATEGORICAL_FEATURES if f in df_train.columns]\n",
    "\n",
    "print(f\"  Features: {len(NUMERICAL_FEATURES)} numerical + {len(CATEGORICAL_FEATURES)} categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7a5bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing true online baseline (past laps only)\n",
      "  Baseline (median MAE/race): 0.7637s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing true online baseline (past laps only)\")\n",
    "\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df['race_id'] = df['year'].astype(str) + '_' + df['round'].astype(str) + '_' + df['name']\n",
    "\n",
    "# Sort test data by race and lap number (to reconstruct chronological order for online baseline)\n",
    "sort_cols = ['year', 'round', 'name']\n",
    "if 'lap_number' in df_test.columns:\n",
    "    sort_cols.append('lap_number')\n",
    "elif 'LapNumber' in df_test.columns:\n",
    "    sort_cols.append('LapNumber')\n",
    "df_test_sorted = df_test.sort_values(sort_cols).reset_index(drop=True)\n",
    "\n",
    "baseline_preds = np.full(len(df_test_sorted), np.nan, dtype=float)\n",
    "\n",
    "for (year, round_no, circuit), group_df in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    past_laps = []\n",
    "    for idx in group_df.index:\n",
    "        lap_idx_in_test = df_test_sorted.index.get_loc(idx)\n",
    "        if past_laps:\n",
    "            baseline_preds[lap_idx_in_test] = float(np.median(past_laps))\n",
    "        past_laps.append(df_test_sorted.at[idx, TARGET])\n",
    "\n",
    "mask = ~np.isnan(baseline_preds)\n",
    "baseline_preds_valid = baseline_preds[mask]\n",
    "y_test_valid = df_test_sorted[TARGET].values[mask]\n",
    "\n",
    "# Per-race baseline\n",
    "baseline_per_race = []\n",
    "for (year, round_no, circuit), group_df in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    group_indices = group_df.index\n",
    "    group_mask = np.zeros(len(df_test_sorted), dtype=bool)\n",
    "    group_mask[group_indices] = True\n",
    "    group_mask = group_mask & mask\n",
    "    if group_mask.sum() > 0:\n",
    "        baseline_per_race.append(mean_absolute_error(df_test_sorted[TARGET].values[group_mask], baseline_preds[group_mask]))\n",
    "\n",
    "baseline_median_mae_per_race = float(np.median(baseline_per_race))\n",
    "print(f\"  Baseline (median MAE/race): {baseline_median_mae_per_race:.4f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd1aada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "\n",
    "X_train = df_train[NUMERICAL_FEATURES + CATEGORICAL_FEATURES].copy()\n",
    "y_train = df_train[TARGET].copy()\n",
    "race_train = df_train['race_id'].copy()\n",
    "\n",
    "X_val = df_val[NUMERICAL_FEATURES + CATEGORICAL_FEATURES].copy()\n",
    "y_val = df_val[TARGET].copy()\n",
    "race_val = df_val['race_id'].copy()\n",
    "\n",
    "X_test = df_test_sorted[NUMERICAL_FEATURES + CATEGORICAL_FEATURES].copy()\n",
    "y_test = df_test_sorted[TARGET].copy()\n",
    "race_test = df_test_sorted['race_id'].copy()\n",
    "\n",
    "X_trainval = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_trainval = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "race_trainval = pd.concat([race_train, race_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Race-balanced weights\n",
    "vc = race_trainval.value_counts()\n",
    "w_trainval = race_trainval.map(lambda r: 1.0 / vc.loc[r])\n",
    "\n",
    "# FIX 4: OneHotEncoder compatibility shim\n",
    "ohe_args = dict(handle_unknown=\"ignore\")\n",
    "try:\n",
    "    OHE = OneHotEncoder(sparse_output=False, **ohe_args)\n",
    "except TypeError:\n",
    "    OHE = OneHotEncoder(sparse=False, **ohe_args)\n",
    "\n",
    "# Single preprocessor (reused for both DT and RF)\n",
    "has_cat = len(CATEGORICAL_FEATURES) > 0\n",
    "if has_cat:\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', SimpleImputer(strategy='median'), NUMERICAL_FEATURES),\n",
    "        ('cat', OHE, CATEGORICAL_FEATURES)\n",
    "    ], remainder='drop')\n",
    "else:\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', SimpleImputer(strategy='median'), NUMERICAL_FEATURES),\n",
    "    ], remainder='drop')\n",
    "\n",
    "# FIX 1: Precompute valid-subset indices once (don't fit preprocessor externally)\n",
    "valid_idx = np.where(mask)[0]\n",
    "\n",
    "# Map each race to positions within the valid subset\n",
    "race_groups_valid = []\n",
    "for _, g in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    full_idx = g.index.values\n",
    "    in_valid = np.intersect1d(valid_idx, full_idx)\n",
    "    if in_valid.size > 0:\n",
    "        pos_in_valid = np.searchsorted(valid_idx, in_valid)\n",
    "        race_groups_valid.append(pos_in_valid)\n",
    "\n",
    "# FIX 3: Helper to get feature names per pipeline\n",
    "def get_feature_names(num_feats, cat_feats, pipeline=None):\n",
    "    names = list(num_feats)\n",
    "    if len(cat_feats) > 0:\n",
    "        enc = pipeline.named_steps['preprocess'].named_transformers_['cat']\n",
    "        names += list(enc.get_feature_names_out(cat_feats))\n",
    "    return names\n",
    "\n",
    "# FIX 2: Rewritten helper for valid-subset permutation importance (transforms inside using pipeline's preprocessor)\n",
    "def compute_permutation_importance_valid(pipeline, X_test_raw, y_test_raw, valid_idx, race_groups_valid, feature_names, n_repeats=10):\n",
    "    \"\"\"Compute race-aware permutation importance on valid subset using pipeline's preprocessor.\"\"\"\n",
    "    rng = np.random.RandomState(42)\n",
    "    preproc = pipeline.named_steps['preprocess']\n",
    "    mdl = pipeline.named_steps['model']\n",
    "\n",
    "    # Transform test data using pipeline's preprocessor (ensures consistency)\n",
    "    X_test_t = preproc.transform(X_test_raw)\n",
    "    X_valid = X_test_t[valid_idx]\n",
    "    y_valid = y_test_raw[valid_idx]\n",
    "\n",
    "    base_pred = mdl.predict(X_valid)\n",
    "    base_med = np.median([mean_absolute_error(y_valid[g], base_pred[g]) for g in race_groups_valid if g.size > 0])\n",
    "\n",
    "    imps = []\n",
    "    for j, fname in enumerate(feature_names):\n",
    "        drops = []\n",
    "        for _ in range(n_repeats):\n",
    "            Xs = X_valid.copy()\n",
    "            rng.shuffle(Xs[:, j])\n",
    "            yp = mdl.predict(Xs)\n",
    "            med = np.median([mean_absolute_error(y_valid[g], yp[g]) for g in race_groups_valid if g.size > 0])\n",
    "            drops.append(med - base_med)\n",
    "        imps.append((fname, float(np.median(drops))))\n",
    "    \n",
    "    imps.sort(key=lambda x: x[1], reverse=True)\n",
    "    return imps[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc95700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DT] Tuning Decision Tree...\n",
      "  Best CV: 7.7178s\n",
      "\n",
      "  DT Results:\n",
      "    Median MAE/race: 5.2309s\n",
      "    Overall MAE: 6.4656s, RMSE: 8.4255s, R²: 0.0102\n",
      "    Tree: depth=6, leaves=60\n",
      "  Computing permutation importance...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DECISION TREE\n",
    "\n",
    "print(\"\\n[DT] Tuning Decision Tree...\")\n",
    "\n",
    "pipe_dt = Pipeline([(\"preprocess\", preprocessor), (\"model\", DecisionTreeRegressor(random_state=42))])\n",
    "\n",
    "# param_dt = {\n",
    "#     \"model__max_depth\": [4, 6, 8, 12],\n",
    "#     \"model__min_samples_leaf\": [5, 10, 20],\n",
    "#     \"model__min_samples_split\": [2, 10],\n",
    "#     \"model__max_features\": [None, \"sqrt\", 0.5],\n",
    "#     \"model__max_leaf_nodes\": [None, 64, 128, 256],\n",
    "#     \"model__ccp_alpha\": [0.0, 1e-4, 5e-4],\n",
    "# }\n",
    "\n",
    "param_dt = {\n",
    "    \"model__max_depth\": [6, 10],\n",
    "    \"model__min_samples_leaf\": [5, 10],\n",
    "    \"model__max_features\": [\"sqrt\", 0.5],\n",
    "    \"model__ccp_alpha\": [0.0, 1e-4],\n",
    "}\n",
    "\n",
    "best_dt_score, best_dt_params = np.inf, None\n",
    "gkf = GroupKFold(n_splits=min(5, race_trainval.nunique()))\n",
    "\n",
    "for i, params in enumerate(list(ParameterGrid(param_dt)), 1):\n",
    "    fold_scores = []\n",
    "    for tr, va in gkf.split(X_trainval, y_trainval, groups=race_trainval):\n",
    "        pipe_dt.set_params(**params)\n",
    "        w_tr = race_trainval.iloc[tr].map(lambda r: 1.0 / race_trainval.iloc[tr].value_counts().loc[r])\n",
    "        pipe_dt.fit(X_trainval.iloc[tr], y_trainval.iloc[tr], model__sample_weight=w_tr.values)\n",
    "        yp = pipe_dt.predict(X_trainval.iloc[va])\n",
    "        per_race = [mean_absolute_error(y_trainval.iloc[va][race_trainval.iloc[va] == rid], yp[race_trainval.iloc[va] == rid]) \n",
    "                    for rid in race_trainval.iloc[va].unique()]\n",
    "        fold_scores.append(float(np.median(per_race)))\n",
    "    score = float(np.median(fold_scores))\n",
    "    if score < best_dt_score:\n",
    "        best_dt_score = score\n",
    "        best_dt_params = params\n",
    "        if i % 50 == 0: print(f\"  [{i}] Best: {score:.4f}s\")\n",
    "\n",
    "print(f\"  Best CV: {best_dt_score:.4f}s\")\n",
    "\n",
    "# Evaluate DT\n",
    "pipe_dt.set_params(**best_dt_params)\n",
    "pipe_dt.fit(X_trainval, y_trainval, model__sample_weight=w_trainval.values)\n",
    "\n",
    "dt_pred_all = pipe_dt.predict(X_test)\n",
    "dt_pred = dt_pred_all[mask]\n",
    "dt_mae = mean_absolute_error(y_test_valid, dt_pred)\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test_valid, dt_pred))\n",
    "dt_r2 = r2_score(y_test_valid, dt_pred)\n",
    "\n",
    "# FIX 3: Use race_groups_valid consistently for per-race errors\n",
    "dt_per_race = []\n",
    "dt_race_ids = []\n",
    "for (year, round_no, circuit), g in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    group_indices = g.index.values\n",
    "    group_mask = np.zeros(len(df_test_sorted), dtype=bool)\n",
    "    group_mask[group_indices] = True\n",
    "    group_mask = group_mask & mask\n",
    "    if group_mask.sum() > 0:\n",
    "        dt_per_race.append(mean_absolute_error(df_test_sorted[TARGET].values[group_mask], dt_pred_all[group_mask]))\n",
    "        dt_race_ids.append(f\"{year}_{round_no}_{circuit}\")\n",
    "\n",
    "dt_median_mae_per_race = float(np.median(dt_per_race))\n",
    "tree_depth = pipe_dt.named_steps['model'].get_depth()\n",
    "tree_leaves = pipe_dt.named_steps['model'].get_n_leaves()\n",
    "\n",
    "print(f\"\\n  DT Results:\")\n",
    "print(f\"    Median MAE/race: {dt_median_mae_per_race:.4f}s\")\n",
    "print(f\"    Overall MAE: {dt_mae:.4f}s, RMSE: {dt_rmse:.4f}s, R²: {dt_r2:.4f}\")\n",
    "print(f\"    Tree: depth={tree_depth}, leaves={tree_leaves}\")\n",
    "\n",
    "# DT permutation importance (FIX 2: transform inside helper)\n",
    "print(f\"  Computing permutation importance...\")\n",
    "dt_feats = get_feature_names(NUMERICAL_FEATURES, CATEGORICAL_FEATURES, pipe_dt)\n",
    "dt_importances = compute_permutation_importance_valid(pipe_dt, X_test, y_test.values, valid_idx, race_groups_valid, dt_feats)\n",
    "\n",
    "# Save DT\n",
    "pd.DataFrame({\n",
    "    \"Model\": [\"Decision Tree\"],\n",
    "    \"CV_median_race_MAE\": [best_dt_score],\n",
    "    \"Test_median_race_MAE\": [dt_median_mae_per_race],\n",
    "    \"Test_MAE\": [dt_mae],\n",
    "    \"Test_RMSE\": [dt_rmse],\n",
    "    \"Test_R2\": [dt_r2],\n",
    "    \"Tree_Depth\": [tree_depth],\n",
    "}).to_csv('csv_output/nonlinear/dt_results.csv', index=False)\n",
    "\n",
    "# FIX 3: Use consistent race identifiers\n",
    "pd.DataFrame({'Race': dt_race_ids, 'MAE': dt_per_race}).sort_values('MAE', ascending=False).to_csv('csv_output/nonlinear/dt_per_race_mae.csv', index=False)\n",
    "\n",
    "pd.DataFrame(dt_importances, columns=['Feature', 'Importance']).to_csv('csv_output/nonlinear/dt_feature_importances_perm.csv', index=False)\n",
    "\n",
    "with open('csv_output/nonlinear/dt_best_hyperparameters.json', 'w') as f:\n",
    "    json.dump({'DecisionTree': best_dt_params, 'CV_score': float(best_dt_score), 'Test_score': float(dt_median_mae_per_race)}, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87008965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RF] Tuning Random Forest...\n",
      "  Best CV: 6.4333s\n",
      "\n",
      "  RF Results:\n",
      "    Median MAE/race: 2.6484s\n",
      "    Overall MAE: 4.4563s, RMSE: 5.8316s, R²: 0.5258\n",
      "    OOB R²: 0.9875 (diagnostic)\n",
      "  Computing permutation importance...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RANDOM FOREST\n",
    "\n",
    "print(\"\\n[RF] Tuning Random Forest...\")\n",
    "\n",
    "# FIX 5: Make RF OOB explicit + keep GroupKFold robust\n",
    "pipe_rf = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(random_state=42, n_jobs=-1, oob_score=True, bootstrap=True))\n",
    "])\n",
    "\n",
    "param_rf = {\n",
    "    \"model__n_estimators\": [600],\n",
    "    \"model__max_depth\": [12, 20, None],\n",
    "    \"model__min_samples_leaf\": [5, 10, 20],\n",
    "    \"model__min_samples_split\": [2, 10, 20],\n",
    "    \"model__max_features\": [\"sqrt\", 0.5],\n",
    "}\n",
    "\n",
    "best_rf_score, best_rf_params = np.inf, None\n",
    "gkf_rf = GroupKFold(n_splits=min(5, race_trainval.nunique()))\n",
    "\n",
    "for i, params in enumerate(list(ParameterGrid(param_rf)), 1):\n",
    "    fold_scores = []\n",
    "    for tr, va in gkf_rf.split(X_trainval, y_trainval, groups=race_trainval):\n",
    "        pipe_rf.set_params(**params)\n",
    "        w_tr = race_trainval.iloc[tr].map(lambda r: 1.0 / race_trainval.iloc[tr].value_counts().loc[r])\n",
    "        pipe_rf.fit(X_trainval.iloc[tr], y_trainval.iloc[tr], model__sample_weight=w_tr.values)\n",
    "        yp = pipe_rf.predict(X_trainval.iloc[va])\n",
    "        per_race = [mean_absolute_error(y_trainval.iloc[va][race_trainval.iloc[va] == rid], yp[race_trainval.iloc[va] == rid]) \n",
    "                    for rid in race_trainval.iloc[va].unique()]\n",
    "        fold_scores.append(float(np.median(per_race)))\n",
    "    score = float(np.median(fold_scores))\n",
    "    if score < best_rf_score:\n",
    "        best_rf_score = score\n",
    "        best_rf_params = params\n",
    "        if i % 10 == 0: print(f\"  [{i}] Best: {score:.4f}s\")\n",
    "\n",
    "print(f\"  Best CV: {best_rf_score:.4f}s\")\n",
    "\n",
    "# Evaluate RF\n",
    "pipe_rf.set_params(**best_rf_params)\n",
    "pipe_rf.fit(X_trainval, y_trainval, model__sample_weight=w_trainval.values)\n",
    "\n",
    "rf_pred_all = pipe_rf.predict(X_test)\n",
    "rf_pred = rf_pred_all[mask]\n",
    "rf_mae = mean_absolute_error(y_test_valid, rf_pred)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test_valid, rf_pred))\n",
    "rf_r2 = r2_score(y_test_valid, rf_pred)\n",
    "rf_oob = pipe_rf.named_steps['model'].oob_score_\n",
    "\n",
    "rf_per_race = []\n",
    "rf_race_ids = []\n",
    "for (year, round_no, circuit), g in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    group_indices = g.index.values\n",
    "    group_mask = np.zeros(len(df_test_sorted), dtype=bool)\n",
    "    group_mask[group_indices] = True\n",
    "    group_mask = group_mask & mask\n",
    "    if group_mask.sum() > 0:\n",
    "        rf_per_race.append(mean_absolute_error(df_test_sorted[TARGET].values[group_mask], rf_pred_all[group_mask]))\n",
    "        rf_race_ids.append(f\"{year}_{round_no}_{circuit}\")\n",
    "\n",
    "rf_median_mae_per_race = float(np.median(rf_per_race))\n",
    "\n",
    "print(f\"\\n  RF Results:\")\n",
    "print(f\"    Median MAE/race: {rf_median_mae_per_race:.4f}s\")\n",
    "print(f\"    Overall MAE: {rf_mae:.4f}s, RMSE: {rf_rmse:.4f}s, R²: {rf_r2:.4f}\")\n",
    "print(f\"    OOB R²: {rf_oob:.4f} (diagnostic)\")\n",
    "\n",
    "# RF permutation importance (FIX 2: transform inside helper)\n",
    "print(f\"  Computing permutation importance...\")\n",
    "rf_feats = get_feature_names(NUMERICAL_FEATURES, CATEGORICAL_FEATURES, pipe_rf)\n",
    "rf_importances = compute_permutation_importance_valid(pipe_rf, X_test, y_test.values, valid_idx, race_groups_valid, rf_feats)\n",
    "\n",
    "\n",
    "# Save RF\n",
    "pd.DataFrame({\n",
    "    \"Model\": [\"Random Forest\"],\n",
    "    \"CV_median_race_MAE\": [best_rf_score],\n",
    "    \"Test_median_race_MAE\": [rf_median_mae_per_race],\n",
    "    \"Test_MAE\": [rf_mae],\n",
    "    \"Test_RMSE\": [rf_rmse],\n",
    "    \"Test_R2\": [rf_r2],\n",
    "    \"OOB_R2\": [rf_oob],\n",
    "}).to_csv('csv_output/nonlinear/rf_results.csv', index=False)\n",
    "\n",
    "# FIX 3: Use consistent race identifiers\n",
    "pd.DataFrame({'Race': rf_race_ids, 'MAE': rf_per_race}).sort_values('MAE', ascending=False).to_csv('csv_output/nonlinear/rf_per_race_mae.csv', index=False)\n",
    "\n",
    "pd.DataFrame(rf_importances, columns=['Feature', 'Importance']).to_csv('csv_output/nonlinear/rf_feature_importances_perm.csv', index=False)\n",
    "\n",
    "with open('csv_output/nonlinear/rf_best_hyperparameters.json', 'w') as f:\n",
    "    json.dump({'RandomForest': best_rf_params, 'CV_score': float(best_rf_score), 'Test_score': float(rf_median_mae_per_race)}, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40b0411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[kNN] Tuning k-Nearest Neighbors...\n",
      "  Best params: {'model__n_neighbors': 25, 'model__p': 2, 'model__weights': 'distance'}\n",
      "  CV median MAE (fold-level): 8.9625s\n",
      "\n",
      "  kNN Results:\n",
      "    Median MAE/race: 6.7547s\n",
      "    Overall MAE: 8.2754s, RMSE: 11.6704s, R²: -0.8987\n",
      "  Computing permutation importance...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# k-NEAREST NEIGHBORS (kNN)\n",
    "\n",
    "print(\"\\n[kNN] Tuning k-Nearest Neighbors...\")\n",
    "\n",
    "# kNN-specific preprocessing: StandardScaler is critical for distance-based models\n",
    "#              numeric features scaled to N(0,1), categorical one-hot in {0,1}\n",
    "#              This asymmetry is acceptable for initial implementation.\n",
    "#              If kNN performs poorly, consider full-matrix scaling with StandardScaler(with_mean=False)\n",
    "\n",
    "\n",
    "preprocessor_knn = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),  # Essential for kNN: normalize feature magnitudes\n",
    "        ]), NUMERICAL_FEATURES),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),  # FIXED: use sparse to save RAM\n",
    "        ]), CATEGORICAL_FEATURES),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "pipe_knn = Pipeline([(\"preprocess\", preprocessor_knn), (\"model\", KNeighborsRegressor())])\n",
    "\n",
    "param_knn = {\n",
    "    \"model__n_neighbors\": [3, 5, 7, 11, 15, 25],      # Odd numbers preferred (symmetry/stability)\n",
    "    \"model__weights\": [\"uniform\", \"distance\"],        # uniform vs. distance-weighted\n",
    "    \"model__p\": [1, 2],                               # 1=Manhattan, 2=Euclidean (Minkowski)\n",
    "}\n",
    "\n",
    "best_knn_score = np.inf\n",
    "best_knn_params = None\n",
    "knn_fold_scores = []\n",
    "\n",
    "gkf = GroupKFold(n_splits=min(5, df_train['race_id'].nunique()))\n",
    "\n",
    "for params in ParameterGrid(param_knn):\n",
    "    fold_mae = []\n",
    "    for tr_idx, val_idx in gkf.split(X_train, y_train.values, groups=df_train['race_id']):\n",
    "        X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_va = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        pipe_knn.set_params(**params)\n",
    "        pipe_knn.fit(X_tr, y_tr)\n",
    "        pred = pipe_knn.predict(X_va)\n",
    "        fold_mae.append(mean_absolute_error(y_va, pred))\n",
    "    \n",
    "    score = np.median(fold_mae)  # Consistent with per-race grouping philosophy\n",
    "    knn_fold_scores.append(score)\n",
    "    \n",
    "    if score < best_knn_score:\n",
    "        best_knn_score = score\n",
    "        best_knn_params = params\n",
    "\n",
    "print(f\"  Best params: {best_knn_params}\")\n",
    "print(f\"  CV median MAE (fold-level): {best_knn_score:.4f}s\")\n",
    "\n",
    "# Train final kNN on full train set\n",
    "pipe_knn.set_params(**best_knn_params)\n",
    "pipe_knn.fit(X_train, y_train.values)\n",
    "\n",
    "# Test predictions\n",
    "knn_pred_all = pipe_knn.predict(X_test)\n",
    "knn_mae = mean_absolute_error(y_test, knn_pred_all)\n",
    "knn_rmse = np.sqrt(mean_squared_error(y_test, knn_pred_all))\n",
    "knn_r2 = r2_score(y_test, knn_pred_all)\n",
    "\n",
    "# Per-race evaluation (FIXED: use positions, not index labels)\n",
    "knn_per_race = []\n",
    "knn_race_ids = []\n",
    "for (year, round_no, circuit), group_df in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    # Convert index labels to positions (handles non-contiguous indices)\n",
    "    pos = df_test_sorted.index.get_indexer(group_df.index.to_numpy())\n",
    "    # Guard: filter out -1 (invalid) positions\n",
    "    pos = pos[pos >= 0]\n",
    "    # Filter to valid (non-NaN) positions\n",
    "    valid_pos = pos[mask[pos]]\n",
    "    if len(valid_pos) > 0:\n",
    "        knn_per_race.append(mean_absolute_error(df_test_sorted[TARGET].values[valid_pos], knn_pred_all[valid_pos]))\n",
    "        knn_race_ids.append(f\"{year}_{round_no}_{circuit}\")\n",
    "\n",
    "knn_median_mae_per_race = float(np.median(knn_per_race))\n",
    "\n",
    "print(f\"\\n  kNN Results:\")\n",
    "print(f\"    Median MAE/race: {knn_median_mae_per_race:.4f}s\")\n",
    "print(f\"    Overall MAE: {knn_mae:.4f}s, RMSE: {knn_rmse:.4f}s, R²: {knn_r2:.4f}\")\n",
    "\n",
    "# kNN permutation importance (same approach as DT/RF)\n",
    "print(f\"  Computing permutation importance...\")\n",
    "knn_feats = get_feature_names(NUMERICAL_FEATURES, CATEGORICAL_FEATURES, pipe_knn)\n",
    "knn_importances = compute_permutation_importance_valid(pipe_knn, X_test, y_test.values, valid_idx, race_groups_valid, knn_feats)\n",
    "\n",
    "# Save kNN\n",
    "pd.DataFrame({\n",
    "    \"Model\": [\"k-Nearest Neighbors\"],\n",
    "    \"CV_median_race_MAE\": [best_knn_score],\n",
    "    \"Test_median_race_MAE\": [knn_median_mae_per_race],\n",
    "    \"Test_MAE\": [knn_mae],\n",
    "    \"Test_RMSE\": [knn_rmse],\n",
    "    \"Test_R2\": [knn_r2],\n",
    "}).to_csv('csv_output/nonlinear/knn_results.csv', index=False)\n",
    "\n",
    "pd.DataFrame({'Race': knn_race_ids, 'MAE': knn_per_race}).sort_values('MAE', ascending=False).to_csv('csv_output/nonlinear/knn_per_race_mae.csv', index=False)\n",
    "\n",
    "pd.DataFrame(knn_importances, columns=['Feature', 'Importance']).to_csv('csv_output/nonlinear/knn_feature_importances_perm.csv', index=False)\n",
    "\n",
    "with open('csv_output/nonlinear/knn_best_hyperparameters.json', 'w') as f:\n",
    "    json.dump({'kNN': best_knn_params, 'CV_score': float(best_knn_score), 'Test_score': float(knn_median_mae_per_race)}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c9197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MLP] Training diagnostic MLP (small, shallow network)...\n",
      "  Fitting MLP on full training set...\n",
      "\n",
      "  MLP Results (diagnostic, non-optimized):\n",
      "    Median MAE/race: 4.7458s\n",
      "    Overall MAE: 7.1505s, RMSE: 10.3437s, R²: -0.4915\n",
      "    Network: input → [32 ReLU] → [16 ReLU] → output\n",
      "    Early stopping: converged after 478 iterations\n",
      "  Computing permutation importance...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SMALL DIAGNOSTIC MLP (Shallow Neural Network)\n",
    "# Purpose: Detect smooth non-linear interactions\n",
    "\n",
    "print(\"\\n[MLP] Training diagnostic MLP (small, shallow network)...\")\n",
    "\n",
    "# MLP-specific preprocessing: StandardScaler is REQUIRED for neural networks\n",
    "preprocessor_mlp = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),  # CRITICAL: neural nets need normalization\n",
    "        ]), NUMERICAL_FEATURES),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),  # FIXED: dense for MLP compatibility\n",
    "        ]), CATEGORICAL_FEATURES),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Simple MLPRegressor: [(32, 16)] architecture\n",
    "# - Shallow: only 2 hidden layers\n",
    "# - Low capacity: 32→16 neurons (approximates smooth interactions)\n",
    "# - Early stopping + L2 regularization: prevents overfitting\n",
    "mlp_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(32, 16),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    learning_rate_init=1e-3,       # Learning rate (stable default)\n",
    "    batch_size=256,                # Batch size (stable)\n",
    "    alpha=1e-3,                    # L2 regularization (mild)\n",
    "    max_iter=500,\n",
    "    early_stopping=True,           # Stop if validation doesn't improve\n",
    "    validation_fraction=0.1,       # Use 10% of train for early stopping validation\n",
    "    n_iter_no_change=20,           # Stop after 20 no-improvement epochs\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "pipe_mlp = Pipeline([\n",
    "    (\"preprocess\", preprocessor_mlp),\n",
    "    (\"model\", mlp_model)\n",
    "])\n",
    "\n",
    "# Train on full training set (no hyperparameter tuning for MLP — keep it diagnostic)\n",
    "print(\"  Fitting MLP on full training set...\")\n",
    "pipe_mlp.fit(X_train, y_train.values)\n",
    "\n",
    "# Test predictions\n",
    "mlp_pred_all = pipe_mlp.predict(X_test)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_pred_all)\n",
    "mlp_rmse = np.sqrt(mean_squared_error(y_test, mlp_pred_all))\n",
    "mlp_r2 = r2_score(y_test, mlp_pred_all)\n",
    "\n",
    "# Per-race evaluation (using corrected indexing from kNN)\n",
    "mlp_per_race = []\n",
    "mlp_race_ids = []\n",
    "for (year, round_no, circuit), group_df in df_test_sorted.groupby(['year', 'round', 'name'], sort=False):\n",
    "    # Convert index labels to positions (handles non-contiguous indices)\n",
    "    pos = df_test_sorted.index.get_indexer(group_df.index.to_numpy())\n",
    "    # Guard: filter out -1 (invalid) positions\n",
    "    pos = pos[pos >= 0]\n",
    "    # Filter to valid (non-NaN) positions\n",
    "    valid_pos = pos[mask[pos]]\n",
    "    if len(valid_pos) > 0:\n",
    "        mlp_per_race.append(mean_absolute_error(df_test_sorted[TARGET].values[valid_pos], mlp_pred_all[valid_pos]))\n",
    "        mlp_race_ids.append(f\"{year}_{round_no}_{circuit}\")\n",
    "\n",
    "mlp_median_mae_per_race = float(np.median(mlp_per_race))\n",
    "\n",
    "# Get n_iter from fitted model inside pipeline\n",
    "mlp_fitted_model = pipe_mlp.named_steps[\"model\"]\n",
    "mlp_n_iter = mlp_fitted_model.n_iter_\n",
    "\n",
    "print(f\"\\n  MLP Results (diagnostic, non-optimized):\")\n",
    "print(f\"    Median MAE/race: {mlp_median_mae_per_race:.4f}s\")\n",
    "print(f\"    Overall MAE: {mlp_mae:.4f}s, RMSE: {mlp_rmse:.4f}s, R²: {mlp_r2:.4f}\")\n",
    "print(f\"    Network: input → [32 ReLU] → [16 ReLU] → output\")\n",
    "print(f\"    Early stopping: converged after {mlp_n_iter} iterations\")\n",
    "\n",
    "# MLP permutation importance (same approach as others)\n",
    "print(f\"  Computing permutation importance...\")\n",
    "mlp_feats = get_feature_names(NUMERICAL_FEATURES, CATEGORICAL_FEATURES, pipe_mlp)\n",
    "mlp_importances = compute_permutation_importance_valid(pipe_mlp, X_test, y_test.values, valid_idx, race_groups_valid, mlp_feats)\n",
    "\n",
    "# Save MLP\n",
    "pd.DataFrame({\n",
    "    \"Model\": [\"Small MLP\"],\n",
    "    \"Architecture\": [\"(32, 16)\"],\n",
    "    \"Test_median_race_MAE\": [mlp_median_mae_per_race],\n",
    "    \"Test_MAE\": [mlp_mae],\n",
    "    \"Test_RMSE\": [mlp_rmse],\n",
    "    \"Test_R2\": [mlp_r2],\n",
    "    \"Iterations\": [mlp_n_iter],\n",
    "}).to_csv('csv_output/nonlinear/mlp_results.csv', index=False)\n",
    "\n",
    "pd.DataFrame({'Race': mlp_race_ids, 'MAE': mlp_per_race}).sort_values('MAE', ascending=False).to_csv('csv_output/nonlinear/mlp_per_race_mae.csv', index=False)\n",
    "\n",
    "pd.DataFrame(mlp_importances, columns=['Feature', 'Importance']).to_csv('csv_output/nonlinear/mlp_feature_importances_perm.csv', index=False)\n",
    "\n",
    "with open('csv_output/nonlinear/mlp_best_hyperparameters.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'MLP': {\n",
    "            'hidden_layer_sizes': (32, 16),\n",
    "            'activation': 'relu',\n",
    "            'alpha': 1e-3,\n",
    "            'early_stopping': True,\n",
    "            'n_iter_no_change': 20\n",
    "        },\n",
    "        'Test_score': float(mlp_median_mae_per_race),\n",
    "        'Iterations': int(mlp_n_iter),\n",
    "        'Purpose': 'Diagnostic - detect smooth non-linear interactions'\n",
    "    }, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01582c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY: NON-LINEAR BASELINE\n",
      "================================================================================\n",
      "\n",
      "Baseline (online, past laps):      0.7905s\n",
      "Decision Tree:                     0.7417s\n",
      "Random Forest:                     0.5688s\n",
      "\n",
      "Winner: Random Forest\n",
      "\n",
      "Files saved to csv_output/nonlinear/:\n",
      "  - dt_results.csv, dt_per_race_mae.csv, dt_feature_importances_perm.csv, dt_best_hyperparameters.json\n",
      "  - rf_results.csv, rf_per_race_mae.csv, rf_feature_importances_perm.csv, rf_best_hyperparameters.json\n",
      "\n",
      "✓ Non-linear baseline complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════════\n",
    "# SUMMARY\n",
    "# ══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: NON-LINEAR BASELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBaseline (online, past laps):      {baseline_median_mae_per_race:.4f}s\")\n",
    "print(f\"Decision Tree:                     {dt_median_mae_per_race:.4f}s\")\n",
    "print(f\"Random Forest:                     {rf_median_mae_per_race:.4f}s\")\n",
    "print(f\"\\nWinner: {'Random Forest' if rf_median_mae_per_race < dt_median_mae_per_race else 'Decision Tree'}\")\n",
    "print(\"\\nFiles saved to csv_output/nonlinear/:\")\n",
    "print(\"  - dt_results.csv, dt_per_race_mae.csv, dt_feature_importances_perm.csv, dt_best_hyperparameters.json\")\n",
    "print(\"  - rf_results.csv, rf_per_race_mae.csv, rf_feature_importances_perm.csv, rf_best_hyperparameters.json\")\n",
    "print(\"\\n✓ Non-linear baseline complete!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41475c8c",
   "metadata": {},
   "source": [
    "Why Random Forest and Decision Tree underperdform ? \n",
    "- Are they underfitting ? \n",
    "- Feature interactions \n",
    "- GB \n",
    "\n",
    "why it might be happening ?  relationship is fairly linear , df/rf may be overfitting, Stint mean so far does most of the job \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Formula1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
