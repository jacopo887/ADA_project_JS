{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "import pickle\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798398f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_excel(\"csv_output/Filtered_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall split (laps):\n",
      "  Train: 28425 (70.4%)\n",
      "  Val:   5388 (13.3%)\n",
      "  Test:  6583 (16.3%)\n",
      "\n",
      "Driver-stint groups total: 2869\n",
      "Groups with n < 10 put fully in train: 1019\n",
      "\n",
      "Any non-contiguous split blocks within a driver-stint group?: False\n",
      "Any non-monotonic time ordering inside a driver-stint group?: False\n",
      "Any boundary violations (train after val/test)?: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df_merged.copy()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 1 Stable identifiers\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "df['race_id'] = (\n",
    "    df['year'].astype(str) + '_' +\n",
    "    df['round'].astype(str) + '_' +\n",
    "    df['Grand_Prix'].astype(str)\n",
    ")\n",
    "\n",
    "group_cols = ['race_id', 'RacingNumber', 'Stint']\n",
    "\n",
    "# Choose the best time column available inside a stint\n",
    "time_col = 'LapInStint' if 'LapInStint' in df.columns else 'lap_number'\n",
    "\n",
    "# Sort so splits are strictly chronological inside each driver-stint\n",
    "df = df.sort_values(group_cols + [time_col]).reset_index(drop=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 2) Time-ordered 70/15/15 split inside each (race, driver, stint)\n",
    "#    - For very short stints, we don't create a test slice\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "MIN_TEST = 3   # minimum laps we want in test if we create a test segment\n",
    "MIN_VAL  = 2   # minimum laps we want in val if we create a val segment\n",
    "MIN_SPLIT_N = 10  # below this, keep in train (or train+val), avoid tiny test\n",
    "\n",
    "def assign_time_split(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    n = len(g)\n",
    "\n",
    "    # Too short -> keep it in train (avoids unstable tiny val/test)\n",
    "    if n < MIN_SPLIT_N:\n",
    "        g['split'] = 'train'\n",
    "        return g\n",
    "\n",
    "    # nominal cut points\n",
    "    i1 = int(np.floor(0.70 * n))\n",
    "    i2 = int(np.floor(0.85 * n))\n",
    "\n",
    "    # enforce minimum sizes\n",
    "    # ensure test has at least MIN_TEST\n",
    "    i2 = min(i2, n - MIN_TEST)\n",
    "    # ensure val has at least MIN_VAL\n",
    "    i1 = min(i1, i2 - MIN_VAL)\n",
    "\n",
    "    # ensure train has at least 1\n",
    "    i1 = max(1, i1)\n",
    "    # ensure val non-empty\n",
    "    i2 = max(i1 + 1, i2)\n",
    "\n",
    "    split = np.array(['train'] * n, dtype=object)\n",
    "    split[i1:i2] = 'val'\n",
    "    split[i2:] = 'test'\n",
    "    g['split'] = split\n",
    "    return g\n",
    "\n",
    "df_with_split = df.groupby(group_cols, group_keys=False).apply(assign_time_split)\n",
    "\n",
    "df_train = df_with_split[df_with_split['split'] == 'train'].drop(columns=['split']).copy()\n",
    "df_val   = df_with_split[df_with_split['split'] == 'val'].drop(columns=['split']).copy()\n",
    "df_test  = df_with_split[df_with_split['split'] == 'test'].drop(columns=['split']).copy()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 3 Reporting\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "total = len(df_with_split)\n",
    "print(\"Overall split (laps):\")\n",
    "print(f\"  Train: {len(df_train)} ({len(df_train)/total*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(df_val)} ({len(df_val)/total*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(df_test)} ({len(df_test)/total*100:.1f}%)\")\n",
    "\n",
    "# How many groups were too short and went fully to train?\n",
    "group_sizes = df_with_split.groupby(group_cols).size()\n",
    "print(f\"\\nDriver-stint groups total: {len(group_sizes)}\")\n",
    "print(f\"Groups with n < {MIN_SPLIT_N} put fully in train: {(group_sizes < MIN_SPLIT_N).sum()}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 4 HARD sanity checks (these catch subtle bugs)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "\n",
    "# A Contiguity check: splits must be contiguous blocks (train -> val -> test)\n",
    "def is_noncontiguous(s):\n",
    "    # if labels change more times than the number of unique labels, it's non-contiguous\n",
    "    changes = (s != s.shift()).sum()\n",
    "    return changes > s.nunique()\n",
    "\n",
    "bad_contig = (df_with_split.groupby(group_cols)['split'].apply(is_noncontiguous))\n",
    "print(\"\\nAny non-contiguous split blocks within a driver-stint group?:\", bad_contig.any())\n",
    "\n",
    "# B Time monotonicity check inside each group\n",
    "bad_time = (df_with_split.groupby(group_cols)[time_col].apply(lambda s: not s.is_monotonic_increasing))\n",
    "print(\"Any non-monotonic time ordering inside a driver-stint group?:\", bad_time.any())\n",
    "\n",
    "# C “Future in train” check: max train time should be <= min val time, etc.\n",
    "def boundary_ok(g):\n",
    "    t = g.loc[g['split']=='train', time_col]\n",
    "    v = g.loc[g['split']=='val', time_col]\n",
    "    te = g.loc[g['split']=='test', time_col]\n",
    "    ok = True\n",
    "    if len(v) > 0 and len(t) > 0:\n",
    "        ok &= (t.max() <= v.min())\n",
    "    if len(te) > 0 and len(v) > 0:\n",
    "        ok &= (v.max() <= te.min())\n",
    "    if len(te) > 0 and len(t) > 0 and len(v) == 0:\n",
    "        ok &= (t.max() <= te.min())\n",
    "    return ok\n",
    "\n",
    "bad_boundary = ~(df_with_split.groupby(group_cols).apply(boundary_ok))\n",
    "print(\"Any boundary violations (train after val/test)?:\", bad_boundary.any())\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 5 Save\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "df_train.to_excel('csv_output/Train_set.xlsx', index=False)\n",
    "df_val.to_excel('csv_output/Validation_set.xlsx', index=False)\n",
    "df_test.to_excel('csv_output/Test_set.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2036909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating synthetic features...\n",
      "   is_new_tyre created (1=fresh, 0=used)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nCreating synthetic features...\")\n",
    "for df_split in [df_train, df_val, df_test]:\n",
    "    df_split['is_new_tyre'] = (df_split['TyreAgeAtStart'] == 0).astype(int)\n",
    "print(f\"   is_new_tyre created (1=fresh, 0=used)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0ed2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# CONFIG & FEATURE SETS\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "TARGET = \"LapTime_next\"\n",
    "\n",
    "NUM_FEATS_FULL = [\n",
    "    \"is_new_tyre\",\n",
    "    \"TyreLife\",\n",
    "    \"TyreAgeAtStart\",\n",
    "    \"is_leader\",\n",
    "    \"in_drs_range\",\n",
    "    \"in_clean_air\",\n",
    "    \"in_dirty_air\",\n",
    "    \"pushing\",\n",
    "    \"AirTemp\",\n",
    "    \"Humidity\",\n",
    "    \"Pressure\",\n",
    "    \"TrackTemp\",\n",
    "    \"WindSpeed\",\n",
    "    \"wind_sin\",\n",
    "    \"wind_cos\",\n",
    "]\n",
    "\n",
    "CAT_FEATS_FULL = [\"RacingNumber\", \"Team\", \"Compound\"]\n",
    "\n",
    "# Define feature sets for comparison\n",
    "FEATURE_SETS = {\n",
    "    \"Tyre+Stint\": {\n",
    "        \"num\": [\n",
    "            \"is_new_tyre\",\n",
    "            \"TyreLife\",\n",
    "            \"TyreAgeAtStart\"\n",
    "        ],\n",
    "        \"cat\": [\"Compound\"]\n",
    "    },\n",
    "    \n",
    "    \"Tyre+Stint+Weather\": {\n",
    "        \"num\": [\n",
    "            \"is_new_tyre\",\n",
    "            \"TyreLife\",\n",
    "            \"TyreAgeAtStart\",\n",
    "            \"AirTemp\",\n",
    "            \"Humidity\",\n",
    "            \"Pressure\",\n",
    "            \"TrackTemp\",\n",
    "            \"WindSpeed\",\n",
    "            \"wind_sin\",\n",
    "            \"wind_cos\"\n",
    "        ],\n",
    "        \"cat\": [\"Compound\"]\n",
    "    },\n",
    "    \n",
    "\n",
    "\n",
    "    # \"Full (No Driver/Team)\": {\n",
    "    #     \"num\": NUM_FEATS_FULL,\n",
    "    #     \"cat\": [\"Compound\"]  # Only tyre compound, NO driver/team\n",
    "    # },\n",
    "    \n",
    "    \"Full (Driver+Team+Compound)\": {\n",
    "        \"num\": NUM_FEATS_FULL,\n",
    "        \"cat\": CAT_FEATS_FULL  # Includes RacingNumber, Team, Compound\n",
    "    }\n",
    "}\n",
    "\n",
    "# Validation - only require WindDirection if needed\n",
    "for name, cfg in FEATURE_SETS.items():\n",
    "    all_cols = cfg[\"num\"] + cfg[\"cat\"] + [\"year\", \"round\", TARGET]\n",
    "    # Only require WindDirection if wind features are used\n",
    "    if (\"wind_sin\" in cfg[\"num\"]) or (\"wind_cos\" in cfg[\"num\"]):\n",
    "        all_cols += [\"WindDirection\"]\n",
    "    for c in all_cols:\n",
    "        if c not in df_train.columns:\n",
    "            raise ValueError(f\"Missing column in df_train: {c} (needed for {name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0afc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE PREP\n",
    "\n",
    "def add_wind_trig(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    theta = np.deg2rad(d[\"WindDirection\"].astype(float))\n",
    "    d[\"wind_sin\"] = np.sin(theta)\n",
    "    d[\"wind_cos\"] = np.cos(theta)\n",
    "    return d\n",
    "\n",
    "def make_Xy(df: pd.DataFrame, num_feats, cat_feats, fit_cols=None, medians=None):\n",
    "    \"\"\"Make X, y matrices with dynamic feature selection.\"\"\"\n",
    "    # Only compute wind trig if wind features are used\n",
    "    need_wind = (\"wind_sin\" in num_feats) or (\"wind_cos\" in num_feats)\n",
    "    d = add_wind_trig(df) if need_wind else df.copy()\n",
    "\n",
    "    # keep only needed columns\n",
    "    X_raw = d[num_feats + cat_feats].copy()\n",
    "    y = d[TARGET].astype(float).copy()\n",
    "\n",
    "    # one-hot categorical\n",
    "    X = pd.get_dummies(X_raw, columns=cat_feats, drop_first=True)\n",
    "\n",
    "    # align columns to training set if provided\n",
    "    if fit_cols is not None:\n",
    "        X = X.reindex(columns=fit_cols, fill_value=0)\n",
    "\n",
    "    # impute using provided medians if available, otherwise compute from X (train only)\n",
    "    if medians is None:\n",
    "        medians = X.median(numeric_only=True)\n",
    "    X = X.fillna(medians)\n",
    "\n",
    "    # drop NaN target rows\n",
    "    m = y.notna()\n",
    "    return X.loc[m], y.loc[m], medians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8232c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# TRAIN ONE MODEL PER RACE FOR A GIVEN FEATURE SET\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "def train_race_models(df_train, num_feats, cat_feats, model_type=\"linear\", alpha=1.0, min_samples=None):\n",
    "    \"\"\"\n",
    "    Train race-specific models for given features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_train : pd.DataFrame\n",
    "        Training data\n",
    "    num_feats : list\n",
    "        Numerical features\n",
    "    cat_feats : list\n",
    "        Categorical features\n",
    "    model_type : str\n",
    "        \"linear\" for LinearRegression or \"ridge\" for Ridge\n",
    "    alpha : float\n",
    "        Regularization strength (only for Ridge)\n",
    "    min_samples : int\n",
    "        Minimum samples to train a race model. If None, use 100 or 5x num features.\n",
    "    \"\"\"\n",
    "    # Auto-calculate min_samples if not provided\n",
    "    if min_samples is None:\n",
    "        n_features = len(num_feats) + len(cat_feats)\n",
    "        min_samples = max(100, 5 * n_features)\n",
    "    \n",
    "    models = {}\n",
    "\n",
    "    for (y_, r_), d_race in df_train.groupby([\"year\", \"round\"]):\n",
    "        if len(d_race) < min_samples:\n",
    "            continue\n",
    "\n",
    "        Xtr, ytr, med = make_Xy(d_race, num_feats, cat_feats)\n",
    "        if len(Xtr) < min_samples:\n",
    "            continue\n",
    "\n",
    "        # Choose model type\n",
    "        if model_type == \"ridge\":\n",
    "            model = Ridge(alpha=alpha)\n",
    "        else:\n",
    "            model = LinearRegression()\n",
    "        \n",
    "        model.fit(Xtr, ytr)\n",
    "\n",
    "        models[(int(y_), int(r_))] = {\n",
    "            \"model\": model,\n",
    "            \"cols\": Xtr.columns,\n",
    "            \"med\": med,\n",
    "        }\n",
    "\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f6738b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# PREDICT & EVALUATE\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "def eval_feature_set(df_test, models, num_feats, cat_feats, name=\"model\"):\n",
    "    \"\"\"Evaluate a feature set on test data, with coverage reporting.\"\"\"\n",
    "    preds, trues = [], []\n",
    "    covered_races = 0\n",
    "    total_races = df_test.groupby([\"year\", \"round\"]).ngroups\n",
    "\n",
    "    for (y_, r_), d_race in df_test.groupby([\"year\", \"round\"]):\n",
    "        key = (int(y_), int(r_))\n",
    "        if key not in models:\n",
    "            continue\n",
    "\n",
    "        covered_races += 1\n",
    "        fit = models[key]\n",
    "        X, y, _ = make_Xy(d_race, num_feats, cat_feats,\n",
    "                          fit_cols=fit[\"cols\"], medians=fit[\"med\"])\n",
    "        yhat = fit[\"model\"].predict(X)\n",
    "\n",
    "        preds.append(yhat)\n",
    "        trues.append(y.values)\n",
    "\n",
    "    if not preds:\n",
    "        return None\n",
    "\n",
    "    yhat = np.concatenate(preds)\n",
    "    ytrue = np.concatenate(trues)\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"MAE\": mean_absolute_error(ytrue, yhat),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(ytrue, yhat)),\n",
    "        \"R2\": r2_score(ytrue, yhat),\n",
    "        \"n_samples\": len(yhat),\n",
    "        \"n_races_trained\": len(models),\n",
    "        \"n_races_covered\": covered_races,\n",
    "        \"test_race_coverage\": f\"{covered_races}/{total_races}\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eff3ce2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "RACE-SPECIFIC MODELS: LINEAR BASELINES + OPTIMIZED RIDGE (Full Model Only)\n",
      "Step 1: Train LINEAR models on ALL feature sets\n",
      "Step 2: Optimize RIDGE alphas on FULL model only using VAL\n",
      "Step 3: Report best result\n",
      "====================================================================================================\n",
      "\n",
      "Phase 1: Training LINEAR baselines...\n",
      "\n",
      "[Tyre+Stint] ✓ 64 races | Test MAE: 0.8825s\n",
      "[Tyre+Stint+Weather] ✓ 64 races | Test MAE: 0.7795s\n",
      "[Full (Driver+Team+Compound)] ✓ 64 races | Test MAE: 0.5508s\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Phase 2: Optimizing RIDGE alphas on Full (No Driver/Team) model only...\n",
      "\n",
      "[Ridge α=0.01] ✓ 64 races | Val MAE: 0.4198s\n",
      "[Ridge α=0.1] ✓ 64 races | Val MAE: 0.4183s\n",
      "[Ridge α=0.5] ✓ 64 races | Val MAE: 0.4150s\n",
      "[Ridge α=1.0] ✓ 64 races | Val MAE: 0.4137s\n",
      "[Ridge α=2.0] ✓ 64 races | Val MAE: 0.4141s\n",
      "[Ridge α=5.0] ✓ 64 races | Val MAE: 0.4201s\n",
      "[Ridge α=10.0] ✓ 64 races | Val MAE: 0.4323s\n",
      "\n",
      "✓ Best α on VAL: 1.0 (MAE: 0.4137s)\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Phase 3: Testing best Ridge model...\n",
      "\n",
      "\n",
      "Full (Driver+Team+Compound) + Ridge (α=1.0)\n",
      "  [Val]  MAE: 0.4137s\n",
      "  [Test] MAE: 0.5409s, RMSE: 0.7130s, R²: 0.9949\n",
      "\n",
      "====================================================================================================\n",
      "FINAL RESULTS (TEST SET)\n",
      "====================================================================================================\n",
      "\n",
      "                                      model      MAE     RMSE       R2  n_samples test_race_coverage\n",
      "Full (Driver+Team+Compound) + Ridge (α=1.0) 0.540860 0.712973 0.994866       6583              63/63\n",
      "       Full (Driver+Team+Compound) + Linear 0.550773 0.727473 0.994655       6583              63/63\n",
      "                Tyre+Stint+Weather + Linear 0.779522 1.009109 0.989715       6583              63/63\n",
      "                        Tyre+Stint + Linear 0.882530 1.095979 0.987868       6583              63/63\n",
      "\n",
      "✓ BEST MODEL: Full (Driver+Team+Compound) + Ridge (α=1.0)\n",
      "  Test MAE: 0.5409s\n",
      "  Test RMSE: 0.7130s\n",
      "  Test R²: 0.9949\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# RUN COMPARISON: LINEAR BASELINES + RIDGE ON FULL MODEL ONLY\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "print(\"=\"*100)\n",
    "print(\"RACE-SPECIFIC MODELS: LINEAR BASELINES + OPTIMIZED RIDGE (Full Model Only)\")\n",
    "print(\"Step 1: Train LINEAR models on ALL feature sets\")\n",
    "print(\"Step 2: Optimize RIDGE alphas on FULL model only using VAL\")\n",
    "print(\"Step 3: Report best result\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "all_models_all = {}  # Store all trained models\n",
    "test_results = []\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# PHASE 1: Train LINEAR models on all feature sets\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "print(\"\\nPhase 1: Training LINEAR baselines...\\n\")\n",
    "\n",
    "for feature_name, cfg in FEATURE_SETS.items():\n",
    "    print(f\"[{feature_name}]\", end=\" \")\n",
    "    \n",
    "    # Train linear\n",
    "    models = train_race_models(df_train, cfg[\"num\"], cfg[\"cat\"], \n",
    "                               model_type=\"linear\", alpha=None)\n",
    "    \n",
    "    model_key = f\"{feature_name} + Linear\"\n",
    "    all_models_all[model_key] = models\n",
    "    \n",
    "    print(f\"✓ {len(models)} races\", end=\"\")\n",
    "    \n",
    "    # Eval on test\n",
    "    test_res = eval_feature_set(df_test, models, cfg[\"num\"], cfg[\"cat\"], model_key)\n",
    "    if test_res:\n",
    "        print(f\" | Test MAE: {test_res['MAE']:.4f}s\")\n",
    "        test_results.append(test_res)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# PHASE 2: Optimize Ridge ONLY on Full (No Driver/Team) model\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "print(f\"\\n{'─'*100}\")\n",
    "print(\"Phase 2: Optimizing RIDGE alphas on Full (No Driver/Team) model only...\\n\")\n",
    "\n",
    "full_cfg = FEATURE_SETS[ \"Full (Driver+Team+Compound)\"]\n",
    "ridge_alphas = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "val_results_ridge = {}\n",
    "\n",
    "for alpha in ridge_alphas:\n",
    "    print(f\"[Ridge α={alpha}]\", end=\" \")\n",
    "    \n",
    "    # Train ridge\n",
    "    models = train_race_models(df_train, full_cfg[\"num\"], full_cfg[\"cat\"], \n",
    "                               model_type=\"ridge\", alpha=alpha)\n",
    "    \n",
    "    model_key = f\"Full (No Driver/Team) + Ridge (α={alpha})\"\n",
    "    all_models_all[model_key] = models\n",
    "    \n",
    "    print(f\"✓ {len(models)} races\", end=\"\")\n",
    "    \n",
    "    # Eval on val\n",
    "    val_res = eval_feature_set(df_val, models, full_cfg[\"num\"], full_cfg[\"cat\"], model_key)\n",
    "    if val_res:\n",
    "        val_mae = val_res['MAE']\n",
    "        val_results_ridge[alpha] = val_mae\n",
    "        print(f\" | Val MAE: {val_mae:.4f}s\")\n",
    "\n",
    "# Select best alpha\n",
    "best_alpha = min(val_results_ridge, key=val_results_ridge.get)\n",
    "best_val_mae = val_results_ridge[best_alpha]\n",
    "\n",
    "print(f\"\\n✓ Best α on VAL: {best_alpha} (MAE: {best_val_mae:.4f}s)\")\n",
    "\n",
    "# Train best ridge model and evaluate on test\n",
    "print(f\"\\n{'─'*100}\")\n",
    "print(f\"Phase 3: Testing best Ridge model...\\n\")\n",
    "\n",
    "best_models = train_race_models(df_train, full_cfg[\"num\"], full_cfg[\"cat\"], \n",
    "                                model_type=\"ridge\", alpha=best_alpha)\n",
    "\n",
    "best_model_key = f\"Full (Driver+Team+Compound) + Ridge (α={best_alpha})\"\n",
    "test_res_best = eval_feature_set(df_test, best_models, full_cfg[\"num\"], full_cfg[\"cat\"], best_model_key)\n",
    "\n",
    "if test_res_best:\n",
    "    print(f\"\\n{best_model_key}\")\n",
    "    print(f\"  [Val]  MAE: {best_val_mae:.4f}s\")\n",
    "    print(f\"  [Test] MAE: {test_res_best['MAE']:.4f}s, RMSE: {test_res_best['RMSE']:.4f}s, R²: {test_res_best['R2']:.4f}\")\n",
    "    test_results.append(test_res_best)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# SUMMARY\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL RESULTS (TEST SET)\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "if test_results:\n",
    "    results_df = pd.DataFrame(test_results).sort_values(\"MAE\")\n",
    "    print(results_df[[\"model\", \"MAE\", \"RMSE\", \"R2\", \"n_samples\", \"test_race_coverage\"]].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n✓ BEST MODEL: {results_df.iloc[0]['model']}\")\n",
    "    print(f\"  Test MAE: {results_df.iloc[0]['MAE']:.4f}s\")\n",
    "    print(f\"  Test RMSE: {results_df.iloc[0]['RMSE']:.4f}s\")\n",
    "    print(f\"  Test R²: {results_df.iloc[0]['R2']:.4f}\")\n",
    "\n",
    "# Store best model info for feature importance analysis\n",
    "best_model_key_final = best_model_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06e1e2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Driver effects: (2024, R16) - Full (Driver+Team+Compound) + Linear\n",
      "→ negative = faster than reference driver\n",
      "\n",
      "Fastest (most negative):\n",
      "RacingNumber_16   -0.458380\n",
      "RacingNumber_4    -0.402971\n",
      "RacingNumber_44   -0.288267\n",
      "RacingNumber_81   -0.233022\n",
      "RacingNumber_55   -0.177226\n",
      "RacingNumber_27   -0.035346\n",
      "RacingNumber_63   -0.026490\n",
      "RacingNumber_14   -0.018450\n",
      "\n",
      "Slowest (most positive):\n",
      "RacingNumber_20    0.146861\n",
      "RacingNumber_43    0.180506\n",
      "RacingNumber_18    0.190522\n",
      "RacingNumber_11    0.223951\n",
      "RacingNumber_24    0.278876\n",
      "RacingNumber_77    0.377668\n",
      "RacingNumber_10    0.461743\n",
      "RacingNumber_31    0.554814\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "374ebfb8-5bb4-4cec-b2f5-06f2d4d16fee",
       "rows": [
        [
         "RacingNumber_16",
         "-0.4583799017962847"
        ],
        [
         "RacingNumber_4",
         "-0.4029708098045891"
        ],
        [
         "RacingNumber_44",
         "-0.28826736244504697"
        ],
        [
         "RacingNumber_81",
         "-0.2330221894108037"
        ],
        [
         "RacingNumber_55",
         "-0.17722554932350126"
        ],
        [
         "RacingNumber_27",
         "-0.03534571007145919"
        ],
        [
         "RacingNumber_63",
         "-0.026489695843028974"
        ],
        [
         "RacingNumber_14",
         "-0.018449660721629922"
        ],
        [
         "RacingNumber_23",
         "0.04761683101870225"
        ],
        [
         "RacingNumber_3",
         "0.133857798687282"
        ],
        [
         "RacingNumber_20",
         "0.1468613225449279"
        ],
        [
         "RacingNumber_43",
         "0.18050636454211536"
        ],
        [
         "RacingNumber_18",
         "0.19052161230729053"
        ],
        [
         "RacingNumber_11",
         "0.2239507087942015"
        ],
        [
         "RacingNumber_24",
         "0.2788760585647902"
        ],
        [
         "RacingNumber_77",
         "0.3776676958344031"
        ],
        [
         "RacingNumber_10",
         "0.4617432946675569"
        ],
        [
         "RacingNumber_31",
         "0.5548141899889392"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 18
       }
      },
      "text/plain": [
       "RacingNumber_16   -0.458380\n",
       "RacingNumber_4    -0.402971\n",
       "RacingNumber_44   -0.288267\n",
       "RacingNumber_81   -0.233022\n",
       "RacingNumber_55   -0.177226\n",
       "RacingNumber_27   -0.035346\n",
       "RacingNumber_63   -0.026490\n",
       "RacingNumber_14   -0.018450\n",
       "RacingNumber_23    0.047617\n",
       "RacingNumber_3     0.133858\n",
       "RacingNumber_20    0.146861\n",
       "RacingNumber_43    0.180506\n",
       "RacingNumber_18    0.190522\n",
       "RacingNumber_11    0.223951\n",
       "RacingNumber_24    0.278876\n",
       "RacingNumber_77    0.377668\n",
       "RacingNumber_10    0.461743\n",
       "RacingNumber_31    0.554814\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DRIVER EFFECTS: SEASON AVERAGE\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "def driver_effects_season_average(year, feature_set=\"Full (Driver+Team+Compound)\", model_type=\"Linear\", top=10):\n",
    "    \"\"\"\n",
    "    Calculate AVERAGE driver effects across all races in a season.\n",
    "    \n",
    "    Aggregates driver coefficients across all races in the season,\n",
    "    providing a season-wide measure of driver performance advantage/disadvantage.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    year : int\n",
    "        Race year (e.g., 2023)\n",
    "    feature_set : str\n",
    "        Feature set name (e.g., \"Full (Driver+Team+Compound)\")\n",
    "    model_type : str\n",
    "        Model type (e.g., \"Linear\" or \"Ridge (α=1.0)\")\n",
    "    top : int\n",
    "        Number of top/bottom drivers to show\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Driver coefficients averaged across season\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    driver_effects_season_average(2023, \n",
    "                                 feature_set=\"Full (Driver+Team+Compound)\", \n",
    "                                 model_type=\"Linear\", \n",
    "                                 top=10)\n",
    "    \"\"\"\n",
    "    model_key = f\"{feature_set} + {model_type}\"\n",
    "    \n",
    "    if model_key not in all_models_all:\n",
    "        available = [k for k in all_models_all.keys() if feature_set in k]\n",
    "        print(f\"Model key '{model_key}' not found.\")\n",
    "        print(f\"Available for {feature_set}: {available}\")\n",
    "        return None\n",
    "    \n",
    "    models = all_models_all[model_key]\n",
    "    \n",
    "    # Aggregate driver coefficients across all races of the season\n",
    "    driver_coefs = {}\n",
    "    driver_counts = {}\n",
    "    races_found = 0\n",
    "    \n",
    "    for (model_year, round_num), model_info in models.items():\n",
    "        if int(model_year) != int(year):\n",
    "            continue\n",
    "        \n",
    "        races_found += 1\n",
    "        model = model_info[\"model\"]\n",
    "        cols = model_info[\"cols\"]\n",
    "        \n",
    "        # Get coefficients\n",
    "        coefs = pd.Series(model.coef_, index=cols)\n",
    "        \n",
    "        # Extract driver coefficients\n",
    "        driver_coefs_race = coefs[coefs.index.str.startswith(\"RacingNumber_\")]\n",
    "        \n",
    "        for driver_feat, coef in driver_coefs_race.items():\n",
    "            if driver_feat not in driver_coefs:\n",
    "                driver_coefs[driver_feat] = 0\n",
    "                driver_counts[driver_feat] = 0\n",
    "            driver_coefs[driver_feat] += coef\n",
    "            driver_counts[driver_feat] += 1\n",
    "    \n",
    "    if races_found == 0:\n",
    "        print(f\"No races found for year {year} in {model_key}\")\n",
    "        return None\n",
    "    \n",
    "    # Average across races\n",
    "    avg_driver_coefs = pd.Series({driver: driver_coefs[driver] / driver_counts[driver] \n",
    "                                   for driver in driver_coefs})\n",
    "    \n",
    "    # Sort by coefficient (negative = faster)\n",
    "    avg_driver_coefs = avg_driver_coefs.sort_values()\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"SEASON AVERAGE DRIVER EFFECTS - {year}\")\n",
    "    print(f\"Model: {model_key}\")\n",
    "    print(f\"Races analyzed: {races_found}\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    print(\"Interpretation: negative = faster than reference driver, positive = slower\\n\")\n",
    "    \n",
    "    print(f\"TOP {top} FASTEST DRIVERS:\\n\")\n",
    "    print(f\"{'Rank':<6} {'Driver':<30} {'Avg Coef':<15} {'Interpretation'}\")\n",
    "    print(\"─\" * 100)\n",
    "    for i, (driver_feat, coef) in enumerate(avg_driver_coefs.head(top).items(), 1):\n",
    "        driver_num = driver_feat.replace(\"RacingNumber_\", \"\")\n",
    "        print(f\"{i:<6} {driver_feat:<30} {coef:>14.6f}  {abs(coef):.4f}s faster than ref\")\n",
    "    \n",
    "    print(f\"\\n\\nTOP {top} SLOWEST DRIVERS:\\n\")\n",
    "    print(f\"{'Rank':<6} {'Driver':<30} {'Avg Coef':<15} {'Interpretation'}\")\n",
    "    print(\"─\" * 100)\n",
    "    for i, (driver_feat, coef) in enumerate(avg_driver_coefs.tail(top).items(), 1):\n",
    "        driver_num = driver_feat.replace(\"RacingNumber_\", \"\")\n",
    "        print(f\"{i:<6} {driver_feat:<30} {coef:>14.6f}  {abs(coef):.4f}s slower than ref\")\n",
    "    \n",
    "    print(f\"\\n{'─'*100}\")\n",
    "    print(f\"Statistics:\")\n",
    "    print(f\"  Mean driver effect:     {avg_driver_coefs.mean():>10.6f}s\")\n",
    "    print(f\"  Median driver effect:   {avg_driver_coefs.median():>10.6f}s\")\n",
    "    print(f\"  Std dev:                {avg_driver_coefs.std():>10.6f}s\")\n",
    "    print(f\"  Range (fastest-slowest): {(avg_driver_coefs.max() - avg_driver_coefs.min()):>10.6f}s\")\n",
    "    \n",
    "    return avg_driver_coefs\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "driver_effects_for_race(2024, 16, feature_set=\"Full (Driver+Team+Compound)\", model_type=\"Linear\", top=8)\n",
    "#driver_effects_season_average(2025, feature_set=\"Full (Driver+Team+Compound)\", model_type=\"Linear\", top=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411106a",
   "metadata": {},
   "source": [
    "Why Option C is the most interesting\n",
    "\n",
    "What Option C really tests\n",
    "\n",
    "A circuit-based split asks:\n",
    "\n",
    "“Given everything I’ve learned about cars, drivers, tyres, weather, and track geometry, can I predict lap times on a circuit I have never seen before?”\n",
    "\n",
    "That is real generalization.\n",
    "Not “later laps of the same race”, not “another race I half-recognize”.\n",
    "\n",
    "If you can show:\n",
    "\t•\ttrain on Bahrain, Melbourne, Suzuka, Austin, etc.\n",
    "\t•\ttest on Monaco, Silverstone, Monza\n",
    "\n",
    "…that’s a strong claim. Much stronger than race-level splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f23261",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Formula1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
